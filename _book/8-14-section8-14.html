<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="A Second Semester Statistics Course with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A Second Semester Statistics Course with R">

<title>A Second Semester Statistics Course with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Beanplots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Chapter summary</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Summary of important R code</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and table plots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient (Optional section)</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomizing inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-14" class="section level2">
<h2><span class="header-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</h2>
<p>Researchers were interested in studying the effects of smoking by children on their lung development by measuring the forced expiratory volume (<em>FEV</em>, measured in Liters) in a representative sample of children (<span class="math inline">\(n=654\)</span>) between the ages of 3 and 19; this data set is available in the <code>FEV</code> data set in the <code>coneproj</code> package (<span class="citation">M. C. Meyer and Liao (<a href="#ref-R-coneproj">2017</a>)</span>, <span class="citation">Liao and Meyer (<a href="#ref-Liao2014">2014</a>)</span>). Measurements on the <em>age</em> (in years) and <em>height</em> (in inches) as well as the <em>sex</em> and <em>smoking status</em> of the children were made. We would expect both the <em>age</em> and <em>height</em> to have positive relationships with <em>FEV</em> (lung capacity) and that smoking might decrease the lung capacity but also that older children would be more likely to smoke. So the <em>height</em> and <em>age</em> might be <strong><em>confounded</em></strong> with smoking status and smoking might diminish lung development for older kids – resulting in a potential interaction between <em>age</em> and <em>smoking</em>. The <em>sex</em> of the child might also matter and should be considered or at least controlled for since the response is a size-based measure. This creates the potential for including up to four variables (<em>age</em>, <em>height</em>, <em>sex</em>, and <em>smoking status</em>) and possibly the interaction between <em>age</em> and <em>smoking status</em>. Initial explorations suggested that modeling the log-FEV would be more successful than trying to model the responses on the original scale. Figure <a href="8-14-section8-14.html#fig:Figure8-34">2.172</a> shows the suggestion of different slopes for the smokers than non-smokers and that there aren’t very many smokers under 9 years old in the data set.</p>
<p>So we will start with a model that contains an <em>age</em> by <em>smoking</em> interaction and include <em>height</em> and <em>sex</em> as additive terms. We are not sure if any of these model components will be needed, so the simplest candidate model will be to remove all the predictors and just have a mean-only model (<code>FEV~1</code>). In between the mean-only and most complicated model are many different options where we can drop the interaction or drop the additive terms or drop the terms involved in the interaction if we don’t need the interaction.</p>

<div class="figure"><span id="fig:Figure8-34"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-34-1.png" alt="Scatterplot of log(FEV) vs Age by smoking status." width="672" />
<p class="caption">
Figure 2.172: Scatterplot of log(FEV) vs Age by smoking status.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(coneproj)
<span class="kw">data</span>(FEV)
FEV &lt;-<span class="st"> </span><span class="kw">as.tibble</span>(FEV)
FEV<span class="op">$</span>sex &lt;-<span class="st"> </span><span class="kw">factor</span>(FEV<span class="op">$</span>sex) <span class="co">#Make sex a factor</span>
<span class="kw">levels</span>(FEV<span class="op">$</span>sex) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Female&quot;</span>,<span class="st">&quot;Male&quot;</span>)  <span class="co">#Make sex labels explicit</span>
FEV<span class="op">$</span>smoke &lt;-<span class="st"> </span><span class="kw">factor</span>(FEV<span class="op">$</span>smoke) <span class="co">#Make smoking status a factor</span>
<span class="kw">levels</span>(FEV<span class="op">$</span>smoke) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Nonsmoker&quot;</span>,<span class="st">&quot;Smoker&quot;</span>) <span class="co">#Make smoking status labels explicit</span>
<span class="kw">require</span>(car)
<span class="kw">scatterplot</span>(<span class="kw">log</span>(FEV)<span class="op">~</span>age<span class="op">|</span>smoke, <span class="dt">data=</span>FEV, <span class="dt">smooth=</span>F,
            <span class="dt">main=</span><span class="st">&quot;Plot of log(FEV) vs Age of children by smoking  status&quot;</span>,
            <span class="dt">legend.coords=</span><span class="st">&quot;topleft&quot;</span>)</code></pre></div>
<p>To get the needed results, start with the <strong><em>full model</em></strong> – the most complicated model you want to consider. It is good to check assumptions before considering reducing the model as they rarely get better in simpler models and the <strong>AIC is only appropriate to use if the model assumptions are reasonably well-met</strong>. As suggested above, our “fullish” model for the <em>log(FEV)</em> values is specified as <code>log(FEV)~height+age*smoke+sex</code>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(FEV)<span class="op">~</span>height<span class="op">+</span>age<span class="op">*</span>smoke<span class="op">+</span>sex, <span class="dt">data=</span>FEV)
<span class="kw">summary</span>(fm1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(FEV) ~ height + age * smoke + sex, data = FEV)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.62926 -0.08783  0.01136  0.09658  0.40751 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)     -1.919494   0.080571 -23.824  &lt; 2e-16
## height           0.042066   0.001759  23.911  &lt; 2e-16
## age              0.025368   0.003642   6.966 8.03e-12
## smokeSmoker      0.107884   0.113646   0.949  0.34282
## sexMale          0.030871   0.011764   2.624  0.00889
## age:smokeSmoker -0.011666   0.008465  -1.378  0.16863
## 
## Residual standard error: 0.1454 on 648 degrees of freedom
## Multiple R-squared:  0.8112, Adjusted R-squared:  0.8097 
## F-statistic: 556.8 on 5 and 648 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))
<span class="kw">plot</span>(fm1, <span class="dt">sub.caption=</span><span class="st">&quot;Diagnostics for full FEV model&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure8-35"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-35-1.png" alt="Diagnostics for the log(FEV) model that includes height, sex, and an interaction between age and smoking status (the full model)." width="960" />
<p class="caption">
Figure 2.173: Diagnostics for the log(FEV) model that includes height, sex, and an interaction between age and smoking status (the full model).
</p>
</div>
<p>The diagnostic plots suggest that there are a few outlying points (Figure <a href="8-14-section8-14.html#fig:Figure8-35">2.173</a>) but they are not influential and there is no evidence of violations of the normality and constant variance assumptions. If we select a different model(s), we would want to check its diagnostics and make sure that the results do not look noticeably worse than these do.</p>
<p>The <code>AIC</code> function can be used to generate the AIC values for a single or set of candidate models. It will also provide the model degrees of freedom used for each model. For example, suppose that the want to compare <code>fm1</code> to a model without the interaction term in the model, called <code>fm1R</code>. You need to fit both models and then apply the <code>AIC</code> function to them with commas between the model names:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm1R &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(FEV)<span class="op">~</span>height<span class="op">+</span>age<span class="op">+</span>smoke<span class="op">+</span>sex, <span class="dt">data=</span>FEV)
<span class="kw">AIC</span>(fm1, fm1R)</code></pre></div>
<pre><code>##      df       AIC
## fm1   7 -658.5178
## fm1R  6 -658.6037</code></pre>
<p>These results tells us that the <code>fm1R</code> model (the one without the interaction) is better on the AIC by 0.09 AIC units. Note that this model does not “fit” as well as the full model, it is just the top AIC model – the AIC results suggest that it is slightly closer to the truth than the more complicated model. But this provides only an assessment of the difference between including or excluding the interaction between <em>age</em> and <em>smoking</em> in a model with two other predictors. We are probably also interested in whether the other terms are needed in the model. The full suite of results from dredge provide model comparisons that help us to assess the presence/absence of each model component including the interaction.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(MuMIn)
<span class="kw">options</span>(<span class="dt">na.action =</span> <span class="st">&quot;na.fail&quot;</span>) <span class="co">#Must run this code once to use dredge</span>
<span class="kw">dredge</span>(fm1, <span class="dt">rank=</span><span class="st">&quot;AIC&quot;</span>, 
       <span class="dt">extra =</span> <span class="kw">c</span>(<span class="st">&quot;R^2&quot;</span>, <span class="dt">adjRsq=</span><span class="cf">function</span>(x) <span class="kw">summary</span>(x)<span class="op">$</span>adj.r.squared))</code></pre></div>
<pre><code>## Global model call: lm(formula = log(FEV) ~ height + age * smoke + sex, data = FEV)
## ---
## Model selection table 
##        (Int)     age     hgh sex smk age:smk     R^2  adjRsq df   logLik
## 16 -1.944000 0.02339 0.04280   +   +         0.81060 0.80950  6  335.302
## 32 -1.919000 0.02537 0.04207   +   +       + 0.81120 0.80970  7  336.259
## 8  -1.940000 0.02120 0.04299   +             0.80920 0.80830  5  332.865
## 12 -1.974000 0.02231 0.04371       +         0.80880 0.80790  5  332.163
## 28 -1.955000 0.02388 0.04315       +       + 0.80920 0.80800  6  332.802
## 4  -1.971000 0.01982 0.04399                 0.80710 0.80650  4  329.262
## 7  -2.265000         0.05185   +             0.79640 0.79580  4  311.594
## 3  -2.271000         0.05212                 0.79560 0.79530  3  310.322
## 15 -2.267000         0.05190   +   +         0.79640 0.79550  5  311.602
## 11 -2.277000         0.05222       +         0.79560 0.79500  4  310.378
## 30 -0.067780 0.09493           +   +       + 0.64460 0.64240  6  129.430
## 26 -0.026590 0.09596               +       + 0.62360 0.62190  5  110.667
## 14 -0.015820 0.08963           +   +         0.62110 0.61930  5  108.465
## 6   0.004991 0.08660           +             0.61750 0.61630  4  105.363
## 10  0.022940 0.09077               +         0.60120 0.60000  4   91.790
## 2   0.050600 0.08708                         0.59580 0.59520  3   87.342
## 13  0.822000                   +   +         0.09535 0.09257  4 -176.092
## 9   0.888400                       +         0.05975 0.05831  3 -188.712
## 5   0.857400                   +             0.02878 0.02729  3 -199.310
## 1   0.915400                                 0.00000 0.00000  2 -208.859
##       AIC   delta weight
## 16 -658.6    0.00  0.414
## 32 -658.5    0.09  0.397
## 8  -655.7    2.87  0.099
## 12 -654.3    4.28  0.049
## 28 -653.6    5.00  0.034
## 4  -650.5    8.08  0.007
## 7  -615.2   43.42  0.000
## 3  -614.6   43.96  0.000
## 15 -613.2   45.40  0.000
## 11 -612.8   45.85  0.000
## 30 -246.9  411.74  0.000
## 26 -211.3  447.27  0.000
## 14 -206.9  451.67  0.000
## 6  -202.7  455.88  0.000
## 10 -175.6  483.02  0.000
## 2  -168.7  489.92  0.000
## 13  360.2 1018.79  0.000
## 9   383.4 1042.03  0.000
## 5   404.6 1063.22  0.000
## 1   421.7 1080.32  0.000
## Models ranked by AIC(x)</code></pre>
<p>There is a lot of information in the output and some of the needed information in the second set of rows, so we will try to point out some useful features to consider. The left columns describe the models being estimated. For example, the first row of results is for a model with an intercept (<code>Int</code>), <em>age</em> (<code>age</code>) , <em>height</em> (<code>hgh</code>), <em>sex</em> (<code>sex</code>), and <em>smoking</em>(<code>smk</code>). For <em>sex</em> and <em>smoking</em>, there are “<code>+</code>”s in the output row when they are included in that model but no coefficient since they are categorical variables. There is no interaction between <em>age</em> and <em>smoking</em> in the top ranked model. The top AIC model has an <span class="math inline">\(\boldsymbol{R}^2=0.8106\)</span>, adjusted <strong><em>R</em></strong><sup>2</sup> of 0.8095, <em>model df</em>=6 (from an intercept, four slopes, and the residual variance), log-likelihood (<code>logLik</code>)=335.302, an AIC=-658.6 and <span class="math inline">\(\Delta\text{AIC}\)</span> of 0.00. The next best model adds the interaction between <em>age</em> and <em>smoking</em>, resulting in increases in the <strong><em>R</em></strong><sup>2</sup>, adjusted <strong><em>R</em></strong><sup>2</sup>, and <em>model df</em>, but increasing the AIC by 0.09 units <span class="math inline">\((\Delta\text{AIC}=0.09)\)</span>. This suggests that these two models are essentially equivalent on the AIC because the difference is so small. The simpler model is a little bit better on AIC so you could focus on it or on the slightly more complicated model – but you should probably note that the evidence is equivocal for these two models.</p>
<p>The comparison to other potential models shows the strength of evidence in support of all the other model components. The intercept-only model is again the last in the list with the least support on AICs with a <span class="math inline">\(\Delta\text{AIC}\)</span> of 1080.32, suggesting it is not worth considering in comparison with the top model. <strong>Comparing the mean-only model to our favorite model on AICs is a bit like the overall <span class="math inline">\(\boldsymbol{F}\)</span>-test we considered in Section</strong> <a href="8-7-section8-7.html#section8-7">8.7</a> <strong>because it compares a model with no predictors to a complicated model.</strong> Each model with just one predictor included is available in the table as well, with the top single predictor model based on <em>height</em> having a <span class="math inline">\(\Delta\text{AIC}\)</span> of 43.96. So we certainly need to pursue something more complicated than SLR based on the AIC results. Closer to the top model is the third-ranked model that includes <em>age</em>, <em>height</em>, and <em>sex</em>. It has a <span class="math inline">\(\Delta\text{AIC}\)</span> of 2.87 so we would say that these results present marginal support for the top two models over this model. It is the simplest model of the top three but not close enough to be considered in detail.</p>
<p>This table also provides the opportunity to compare the model selection results from the adjusted <strong><em>R</em></strong><sup>2</sup> compared to the AIC. The AIC favors the model without an interaction between <em>age</em> and <em>smoking</em> whereas the adjusted <em>R</em><sup>2</sup> favors the most complicated model considered here that included an <em>age</em> and <em>smoking</em> interaction. The AIC provides units that are more interpretable than adjusted <em>R</em><sup>2</sup> even though the scale for the AIC is a bit mysterious as <strong>distances from the unknown true model</strong>.</p>
<p>The top AIC model (and possibly the other similar models) can then be explored in more detail. You should not then focus on hypothesis testing in this model<a href="#fn119" class="footnoteRef" id="fnref119"><sup>119</sup></a>. Confidence intervals and term-plots are useful for describing the different model components and making inferences for the estimated sizes of differences in the population. These results should not be used for deciding if terms are “significant” when the models are selected using measures like the AIC or adjusted <em>R</em><sup>2</sup>. But you can discuss the estimated model components to go with how you arrived at having them in the model.</p>
<p>In this situation, the top model is estimated to be</p>
<p><span class="math display">\[\log(\widehat{\text{FEV}})_i = -1.94 + 0.043\cdot\text{Height}_i+ 0.0234\cdot\text{Age}_i
-0.046I_{\text{Smoker},i}+0.0293I_{\text{Male},i}\]</span></p>
<p>based on the estimated coefficients provided below. Using these results and the term-plots (Figure <a href="8-14-section8-14.html#fig:Figure8-36">2.174</a>) we see that in this model there are positive slopes for <em>Age</em> and <em>Height</em> on <em>log-FEV</em>, a negative coefficient for <em>smoking</em> (<em>Smoker</em>), and a positive coefficient for <em>sex</em> (<em>Males</em>). We could go further with interpretations such as for the <em>age</em> term: For a 1 year increase in <em>age</em>, we expect, on average, a 0.0234 log-liter increase in <em>FEV</em>, after controlling for the <em>height</em>, <em>smoking status</em>, and <em>sex</em> of the children. We can even interpret this on the original scale since this was a <em>log(y)</em> response model using the same techniques as in Section <a href="7-6-section7-6.html#section7-6">7.6</a>. If we exponentiate the slope coefficient of the quantitative variable, <span class="math inline">\(\exp(0.0234)=1.0237\)</span>. This provides the interpretation on the original <em>FEV</em> scale, for a 1 year increase in <em>age</em>, we expect 2.4% increase in the median <em>FEV</em>, after controlling for the <em>height</em>, <em>smoking status</em>, and <em>sex</em> of the children. <strong>The only difference from Section</strong> <a href="7-6-section7-6.html#section7-6">7.6</a> <strong>when working with a log(y) model now is that we have to note that the model used to generate the slope coefficient had other components and so this estimate is after adjusting for them.</strong></p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fm1R<span class="op">$</span>coefficients</code></pre></div>
<pre><code>## (Intercept)      height         age smokeSmoker     sexMale 
## -1.94399818  0.04279579  0.02338721 -0.04606754  0.02931936</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(fm1R)</code></pre></div>
<pre><code>##                    2.5 %       97.5 %
## (Intercept) -2.098414941 -1.789581413
## height       0.039498923  0.046092655
## age          0.016812109  0.029962319
## smokeSmoker -0.087127344 -0.005007728
## sexMale      0.006308481  0.052330236</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(fm1R))</code></pre></div>
<div class="figure"><span id="fig:Figure8-36"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-36-1.png" alt="Term-plots for the top AIC model for log(FEV) that includes height, age, smoking status and sex in the model." width="672" />
<p class="caption">
Figure 2.174: Term-plots for the top AIC model for log(FEV) that includes height, age, smoking status and sex in the model.
</p>
</div>
<p>Like any statistical method, the AIC works better with larger sample sizes and when the assumptions are met. It also will detect important variables in models more easily when the effects of the predictor variables are strong. Along with the AIC results, it is good to report the coefficients for your top estimated model(s), confidence intervals for the coefficients and/or term-plots, and <em>R</em><sup>2</sup>. This provides a useful summary of the reasons for selecting the model(s), information on the importance of the terms within the model, and a measure of the variability explained by the model. The <em>R</em><sup>2</sup> is not used to select the model, but after selection can be a nice summary of model quality. For <code>fm1R</code> , the <span class="math inline">\(R^2=0.8106\)</span> suggesting that the selected model explains 81% of the variation in log-<em>FEV</em> values.</p>
<p>The AICs are a preferred modeling strategy in some areas such as Ecology. As with this and many other methods discussed in this book, it is sometimes as easy to find journal articles with mistakes in using statistical methods as it is to find papers doing it correctly. After completing this material, you have the potential to have the knowledge and experience of two statistics classes and now are better trained than some researchers that frequently use these methods. This set of tools can be easily mis-applied. Try to make sure that you are thinking carefully through your problem before jumping to the statistical results. Make a graph first, think carefully about your study design and variables collected and what your models of interest might be, what assumptions might be violated based on the data collection story, and then start fitting models. Then check your assumptions and only proceed on with any inference if those conditions are reasonably well-met. The AIC provides an alternative method for selecting among different potential models and they do not need to be nested (a requirement of hypothesis testing methods used to sequentially simplify models). The automated consideration of all possible models in the <code>dredge</code> function should not be considered in all situations but can be useful in a preliminary model exploration study where no clear knowledge exists about useful models to consider. Reporting the summary of AIC results beyond just reporting the top model(s) selected for focused exploration provides the evidence to support that selection.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-coneproj">
<p>Meyer, Mary C., and Xiyue Liao. 2017. <em>Coneproj: Primal or Dual Cone Projections with Routines for Constrained Regression</em>. <a href="https://CRAN.R-project.org/package=coneproj" class="uri">https://CRAN.R-project.org/package=coneproj</a>.</p>
</div>
<div id="ref-Liao2014">
<p>Liao, Xiyue, and Mary C. Meyer. 2014. “Coneproj: An R Package for the Primal or Dual Cone Projections with Routines for Constrained Regression.” <em>Journal of Statistical Software</em> 61 (12): 1–22. <a href="http://www.jstatsoft.org/v61/i12/" class="uri">http://www.jstatsoft.org/v61/i12/</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="119">
<li id="fn119"><p>Hypothesis testing so permeates the use of statistics that even after using AICs many researchers are pressured to report p-values for model components. Some of this could be confusion caused when people first learned these statistical methods because when we teach you statistics we show you how to use various methods, one after another, and forget to mention that you should not use <strong>every</strong> method we taught you in <strong>every</strong> analysis.<a href="8-14-section8-14.html#fnref119">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="8-13-section8-13.html"><button class="btn btn-default">Previous</button></a>
<a href="8-15-section8-15.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
