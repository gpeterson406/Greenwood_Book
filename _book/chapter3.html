<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>A Second Semester Statistics Course with R</title>
  <meta name="description" content="A Second Semester Statistics Course with R">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="A Second Semester Statistics Course with R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="gpeterson406/Greenwood_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="A Second Semester Statistics Course with R" />
  
  
  

<meta name="author" content="Mark C Greenwood">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="chapter2.html">
<link rel="next" href="chapter4.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#section1-1"><i class="fa fa-check"></i><b>1.1</b> Overview of methods</a></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#section1-2"><i class="fa fa-check"></i><b>1.2</b> Getting started in R</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#section1-3"><i class="fa fa-check"></i><b>1.3</b> Basic summary statistics, histograms, and boxplots using R</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#section1-4"><i class="fa fa-check"></i><b>1.4</b> Chapter summary</a></li>
<li class="chapter" data-level="1.5" data-path="chapter1.html"><a href="chapter1.html#section1-5"><i class="fa fa-check"></i><b>1.5</b> Summary of important R code</a></li>
<li class="chapter" data-level="1.6" data-path="chapter1.html"><a href="chapter1.html#section1-6"><i class="fa fa-check"></i><b>1.6</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> (R)e-Introduction to statistics</a><ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#section2-1"><i class="fa fa-check"></i><b>2.1</b> Histograms, boxplots, and density curves</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#section2-2"><i class="fa fa-check"></i><b>2.2</b> Beanplots</a></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#section2-3"><i class="fa fa-check"></i><b>2.3</b> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#section2-4"><i class="fa fa-check"></i><b>2.4</b> Permutation testing for the two sample mean situation</a></li>
<li class="chapter" data-level="2.5" data-path="chapter2.html"><a href="chapter2.html#section2-5"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing (general)</a></li>
<li class="chapter" data-level="2.6" data-path="chapter2.html"><a href="chapter2.html#section2-6"><i class="fa fa-check"></i><b>2.6</b> Connecting randomization (nonparametric) and parametric tests</a></li>
<li class="chapter" data-level="2.7" data-path="chapter2.html"><a href="chapter2.html#section2-7"><i class="fa fa-check"></i><b>2.7</b> Second example of permutation tests</a></li>
<li class="chapter" data-level="2.8" data-path="chapter2.html"><a href="chapter2.html#section2-8"><i class="fa fa-check"></i><b>2.8</b> Confidence intervals and bootstrapping</a></li>
<li class="chapter" data-level="2.9" data-path="chapter2.html"><a href="chapter2.html#section2-9"><i class="fa fa-check"></i><b>2.9</b> Bootstrap confidence intervals for difference in GPAs</a></li>
<li class="chapter" data-level="2.10" data-path="chapter2.html"><a href="chapter2.html#section2-10"><i class="fa fa-check"></i><b>2.10</b> Chapter summary</a></li>
<li class="chapter" data-level="2.11" data-path="chapter2.html"><a href="chapter2.html#section2-11"><i class="fa fa-check"></i><b>2.11</b> Summary of important R code</a></li>
<li class="chapter" data-level="2.12" data-path="chapter2.html"><a href="chapter2.html#section2-12"><i class="fa fa-check"></i><b>2.12</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> One-Way ANOVA</a><ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#section3-1"><i class="fa fa-check"></i><b>3.1</b> Situation</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#section3-2"><i class="fa fa-check"></i><b>3.2</b> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#section3-3"><i class="fa fa-check"></i><b>3.3</b> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#section3-4"><i class="fa fa-check"></i><b>3.4</b> ANOVA model diagnostics including QQ-plots</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#section3-5"><i class="fa fa-check"></i><b>3.5</b> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#section3-6"><i class="fa fa-check"></i><b>3.6</b> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li class="chapter" data-level="3.7" data-path="chapter3.html"><a href="chapter3.html#section3-7"><i class="fa fa-check"></i><b>3.7</b> Pair-wise comparisons for Prisoner Rating data</a></li>
<li class="chapter" data-level="3.8" data-path="chapter3.html"><a href="chapter3.html#section3-8"><i class="fa fa-check"></i><b>3.8</b> Chapter summary</a></li>
<li class="chapter" data-level="3.9" data-path="chapter3.html"><a href="chapter3.html#section3-9"><i class="fa fa-check"></i><b>3.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="3.10" data-path="chapter3.html"><a href="chapter3.html#section3-10"><i class="fa fa-check"></i><b>3.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Two-Way ANOVA</a><ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#section4-1"><i class="fa fa-check"></i><b>4.1</b> Situation</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#section4-2"><i class="fa fa-check"></i><b>4.2</b> Designing a two-way experiment and visualizing results</a></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#section4-3"><i class="fa fa-check"></i><b>4.3</b> Two-Way ANOVA models and hypothesis tests</a></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#section4-4"><i class="fa fa-check"></i><b>4.4</b> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li class="chapter" data-level="4.5" data-path="chapter4.html"><a href="chapter4.html#section4-5"><i class="fa fa-check"></i><b>4.5</b> Observational study example: The Psychology of Debt</a></li>
<li class="chapter" data-level="4.6" data-path="chapter4.html"><a href="chapter4.html#section4-6"><i class="fa fa-check"></i><b>4.6</b> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li class="chapter" data-level="4.7" data-path="chapter4.html"><a href="chapter4.html#section4-7"><i class="fa fa-check"></i><b>4.7</b> Chapter summary</a></li>
<li class="chapter" data-level="4.8" data-path="chapter4.html"><a href="chapter4.html#section4-8"><i class="fa fa-check"></i><b>4.8</b> Summary of important R code</a></li>
<li class="chapter" data-level="4.9" data-path="chapter4.html"><a href="chapter4.html#section4-9"><i class="fa fa-check"></i><b>4.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Chi-square tests</a><ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#section5-1"><i class="fa fa-check"></i><b>5.1</b> Situation, contingency tables, and table plots</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#section5-2"><i class="fa fa-check"></i><b>5.2</b> Homogeneity test hypotheses</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#section5-3"><i class="fa fa-check"></i><b>5.3</b> Independence test hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#section5-4"><i class="fa fa-check"></i><b>5.4</b> Models for R by C tables</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#section5-5"><i class="fa fa-check"></i><b>5.5</b> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#section5-6"><i class="fa fa-check"></i><b>5.6</b> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#section5-7"><i class="fa fa-check"></i><b>5.7</b> Examining residuals for the source of differences</a></li>
<li class="chapter" data-level="5.8" data-path="chapter5.html"><a href="chapter5.html#section5-8"><i class="fa fa-check"></i><b>5.8</b> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li class="chapter" data-level="5.9" data-path="chapter5.html"><a href="chapter5.html#section5-9"><i class="fa fa-check"></i><b>5.9</b> Political party and voting results: Complete analysis</a></li>
<li class="chapter" data-level="5.10" data-path="chapter5.html"><a href="chapter5.html#section5-10"><i class="fa fa-check"></i><b>5.10</b> Is cheating and lying related in students?</a></li>
<li class="chapter" data-level="5.11" data-path="chapter5.html"><a href="chapter5.html#section5-11"><i class="fa fa-check"></i><b>5.11</b> Analyzing a stratified random sample of California schools</a></li>
<li class="chapter" data-level="5.12" data-path="chapter5.html"><a href="chapter5.html#section5-12"><i class="fa fa-check"></i><b>5.12</b> Chapter summary</a></li>
<li class="chapter" data-level="5.13" data-path="chapter5.html"><a href="chapter5.html#section5-13"><i class="fa fa-check"></i><b>5.13</b> Summary of important R commands</a></li>
<li class="chapter" data-level="5.14" data-path="chapter5.html"><a href="chapter5.html#section5-14"><i class="fa fa-check"></i><b>5.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Correlation and Simple Linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#section6-1"><i class="fa fa-check"></i><b>6.1</b> Relationships between two quantitative variables</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#section6-2"><i class="fa fa-check"></i><b>6.2</b> Estimating the correlation coefficient</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#section6-3"><i class="fa fa-check"></i><b>6.3</b> Relationships between variables by groups</a></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#section6-4"><i class="fa fa-check"></i><b>6.4</b> Inference for the correlation coefficient (Optional section)</a></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#section6-5"><i class="fa fa-check"></i><b>6.5</b> Are tree diameters related to tree heights?</a></li>
<li class="chapter" data-level="6.6" data-path="chapter6.html"><a href="chapter6.html#section6-6"><i class="fa fa-check"></i><b>6.6</b> Describing relationships with a regression model</a></li>
<li class="chapter" data-level="6.7" data-path="chapter6.html"><a href="chapter6.html#section6-7"><i class="fa fa-check"></i><b>6.7</b> Least Squares Estimation</a></li>
<li class="chapter" data-level="6.8" data-path="chapter6.html"><a href="chapter6.html#section6-8"><i class="fa fa-check"></i><b>6.8</b> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li class="chapter" data-level="6.9" data-path="chapter6.html"><a href="chapter6.html#section6-9"><i class="fa fa-check"></i><b>6.9</b> Outliers: leverage and influence</a></li>
<li class="chapter" data-level="6.10" data-path="chapter6.html"><a href="chapter6.html#section6-10"><i class="fa fa-check"></i><b>6.10</b> Residual diagnostics – setting the stage for inference</a></li>
<li class="chapter" data-level="6.11" data-path="chapter6.html"><a href="chapter6.html#section6-11"><i class="fa fa-check"></i><b>6.11</b> Old Faithful discharge and waiting times</a></li>
<li class="chapter" data-level="6.12" data-path="chapter6.html"><a href="chapter6.html#section6-12"><i class="fa fa-check"></i><b>6.12</b> Chapter summary</a></li>
<li class="chapter" data-level="6.13" data-path="chapter6.html"><a href="chapter6.html#section6-13"><i class="fa fa-check"></i><b>6.13</b> Summary of important R code</a></li>
<li class="chapter" data-level="6.14" data-path="chapter6.html"><a href="chapter6.html#section6-14"><i class="fa fa-check"></i><b>6.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression inference</a><ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#section7-1"><i class="fa fa-check"></i><b>7.1</b> Model</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#section7-2"><i class="fa fa-check"></i><b>7.2</b> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#section7-3"><i class="fa fa-check"></i><b>7.3</b> Bozeman temperature trend</a></li>
<li class="chapter" data-level="7.4" data-path="chapter7.html"><a href="chapter7.html#section7-4"><i class="fa fa-check"></i><b>7.4</b> Randomizing inferences for the slope coefficient</a></li>
<li class="chapter" data-level="7.5" data-path="chapter7.html"><a href="chapter7.html#section7-5"><i class="fa fa-check"></i><b>7.5</b> Transformations part I: Linearizing relationships</a></li>
<li class="chapter" data-level="7.6" data-path="chapter7.html"><a href="chapter7.html#section7-6"><i class="fa fa-check"></i><b>7.6</b> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li class="chapter" data-level="7.7" data-path="chapter7.html"><a href="chapter7.html#section7-7"><i class="fa fa-check"></i><b>7.7</b> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li class="chapter" data-level="7.8" data-path="chapter7.html"><a href="chapter7.html#section7-8"><i class="fa fa-check"></i><b>7.8</b> Chapter summary</a></li>
<li class="chapter" data-level="7.9" data-path="chapter7.html"><a href="chapter7.html#section7-9"><i class="fa fa-check"></i><b>7.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="7.10" data-path="chapter7.html"><a href="chapter7.html#section7-10"><i class="fa fa-check"></i><b>7.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Multiple linear regression</a><ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#section8-1"><i class="fa fa-check"></i><b>8.1</b> Going from SLR to MLR</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#section8-2"><i class="fa fa-check"></i><b>8.2</b> Validity conditions in MLR</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#section8-3"><i class="fa fa-check"></i><b>8.3</b> Interpretation of MLR terms</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#section8-4"><i class="fa fa-check"></i><b>8.4</b> Comparing multiple regression models</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#section8-5"><i class="fa fa-check"></i><b>8.5</b> General recommendations for MLR interpretations and VIFs</a></li>
<li class="chapter" data-level="8.6" data-path="chapter8.html"><a href="chapter8.html#section8-6"><i class="fa fa-check"></i><b>8.6</b> MLR inference: Parameter inferences using the t-distribution</a></li>
<li class="chapter" data-level="8.7" data-path="chapter8.html"><a href="chapter8.html#section8-7"><i class="fa fa-check"></i><b>8.7</b> Overall F-test in multiple linear regression</a></li>
<li class="chapter" data-level="8.8" data-path="chapter8.html"><a href="chapter8.html#section8-8"><i class="fa fa-check"></i><b>8.8</b> Case study: First year college GPA and SATs</a></li>
<li class="chapter" data-level="8.9" data-path="chapter8.html"><a href="chapter8.html#section8-9"><i class="fa fa-check"></i><b>8.9</b> Different intercepts for different groups: MLR with indicator variables</a></li>
<li class="chapter" data-level="8.10" data-path="chapter8.html"><a href="chapter8.html#section8-10"><i class="fa fa-check"></i><b>8.10</b> Additive MLR with more than two groups: Headache example</a></li>
<li class="chapter" data-level="8.11" data-path="chapter8.html"><a href="chapter8.html#section8-11"><i class="fa fa-check"></i><b>8.11</b> Different slopes and different intercepts</a></li>
<li class="chapter" data-level="8.12" data-path="chapter8.html"><a href="chapter8.html#section8-12"><i class="fa fa-check"></i><b>8.12</b> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li class="chapter" data-level="8.13" data-path="chapter8.html"><a href="chapter8.html#section8-13"><i class="fa fa-check"></i><b>8.13</b> AICs for model selection</a></li>
<li class="chapter" data-level="8.14" data-path="chapter8.html"><a href="chapter8.html#section8-14"><i class="fa fa-check"></i><b>8.14</b> Case study: Forced expiratory volume model selection using AICs</a></li>
<li class="chapter" data-level="8.15" data-path="chapter8.html"><a href="chapter8.html#section8-15"><i class="fa fa-check"></i><b>8.15</b> Chapter summary</a></li>
<li class="chapter" data-level="8.16" data-path="chapter8.html"><a href="chapter8.html#section8-16"><i class="fa fa-check"></i><b>8.16</b> Summary of important R code</a></li>
<li class="chapter" data-level="8.17" data-path="chapter8.html"><a href="chapter8.html#section8-17"><i class="fa fa-check"></i><b>8.17</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Case studies</a><ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#section9-1"><i class="fa fa-check"></i><b>9.1</b> Overview of material covered</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#section9-2"><i class="fa fa-check"></i><b>9.2</b> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#section9-3"><i class="fa fa-check"></i><b>9.3</b> Ants learn to rely on more informative attributes during decision-making</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#section9-4"><i class="fa fa-check"></i><b>9.4</b> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#section9-5"><i class="fa fa-check"></i><b>9.5</b> General summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Second Semester Statistics Course with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter3" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> One-Way ANOVA</h1>
<div id="section3-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Situation</h2>
<p>In Chapter <a href="chapter2.html#chapter2">2</a>, tools for comparing the means of two groups were considered. More generally, these methods are used for a quantitative response and a categorical explanatory variable (group) which had two and only two levels. The full prisoner rating data set actually contained three groups (Figure <a href="chapter3.html#fig:Figure3-1">3.1</a>) with <em>Beautiful</em>, <em>Average</em>, and <em>Unattractive</em> rated pictures randomly assigned to the subjects for sentence ratings. In a situation with more than two groups, we have two choices. First, we could rely on our two group comparisons, performing tests for every possible pair (<em>Beautiful</em> vs <em>Average</em>, <em>Beautiful</em> vs <em>Unattractive</em>, and <em>Average</em> vs <em>Unattractive</em>). We spent Chapter <a href="chapter2.html#chapter2">2</a> doing inferences for differences between <em>Average</em> and <em>Unattractive</em>. The other two comparisons would lead us to initially end up with three p-values and no direct answer about our initial question of interest – is there some overall difference in the average sentences provided across the groups? In this chapter, we will learn a new method, called <strong><em>Analysis of Variance</em></strong>, <strong><em>ANOVA</em></strong>, or sometimes <strong><em>AOV</em></strong> that directly assesses whether there is evidence of some overall difference in the means among the groups. This version of an ANOVA is called a <strong><em>One-Way ANOVA</em></strong> since there is just one<a href="#fn37" class="footnoteRef" id="fnref37"><sup>37</sup></a> grouping variable. After we perform our One-Way ANOVA test for overall evidence of a difference, we will revisit the comparisons similar to those considered in Chapter <a href="chapter2.html#chapter2">2</a> to get more details on specific differences among <em>all</em> the pairs of groups – what we call <strong><em>pair-wise comparisons</em></strong>. An issue is created when you perform many tests simultaneously and we will augment our previous methods with an adjusted method for pairwise comparisons to make our results valid called <strong><em>Tukey’s Honest Significant Difference</em></strong>.</p>
<p>To make this more concrete, we return to the original MockJury data, making side-by-side boxplots and beanplots (Figure <a href="chapter3.html#fig:Figure3-1">3.1</a>) as well as summarizing the suggested sentence lengths by the three groups using <code>favstats</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(heplots)
<span class="kw">require</span>(mosaic)
<span class="kw">data</span>(MockJury)
<span class="kw">favstats</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>##           Attr min Q1 median   Q3 max     mean       sd  n missing
## 1    Beautiful   1  2      3  6.5  15 4.333333 3.405362 39       0
## 2      Average   1  2      3  5.0  12 3.973684 2.823519 38       0
## 3 Unattractive   1  2      5 10.0  15 5.810811 4.364235 37       0</code></pre>

<div class="figure"><span id="fig:Figure3-1"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-1-1.png" alt="Boxplot and beanplot of the sentences (years) for the three treatment groups." width="960" />
<p class="caption">
Figure 3.1: Boxplot and beanplot of the sentences (years) for the three treatment groups.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">boxplot</span>(Years<span class="op">~</span>Attr,<span class="dt">data=</span>MockJury)
<span class="kw">require</span>(beanplot)
<span class="kw">beanplot</span>(Years<span class="op">~</span>Attr,<span class="dt">data=</span>MockJury,<span class="dt">log=</span><span class="st">&quot;&quot;</span>,<span class="dt">col=</span><span class="st">&quot;bisque&quot;</span>,<span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>)</code></pre></div>
<p>There are slight differences in the sample sizes in the three groups with <span class="math inline">\(37\)</span> <em>Unattractive</em>, <span class="math inline">\(38\)</span> <em>Average</em> and <span class="math inline">\(39\)</span> <em>Beautiful</em> group responses, providing a data set has a total sample size of <span class="math inline">\(N=114\)</span>. The <em>Beautiful</em> and <em>Average</em> groups do not appear to be very different with means of 4.33 and 3.97 years. In Chapter <a href="chapter2.html#chapter2">2</a>, we found moderate evidence regarding the difference in <em>Average</em> and <em>Unattractive</em>. It is less clear whether we might find evidence of a difference between <em>Beautiful</em> and <em>Unattractive</em> groups since we are comparing means of 5.81 and 4.33 years. All the distributions appear to be right skewed with relatively similar shapes. The variability in <em>Average</em> and <em>Unattractive</em> groups seems like it could be slightly different leading to an overall concern of whether the variability is the same in all the groups.</p>
</div>
<div id="section3-2" class="section level2">
<h2><span class="header-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</h2>
<p>We introduced the statistical model <span class="math inline">\(y_{ij} = \mu_j+\varepsilon_{ij}\)</span> in Chapter <a href="chapter2.html#chapter2">2</a> for the situation with <span class="math inline">\(j = 1 \text{ or } 2\)</span> to denote a situation where there were two groups and, for the model that is consistent with the alternative hypothesis, the means differed. Now we have three groups and the previous model can be extended to this new situation by allowing <span class="math inline">\(j\)</span> to be 1, 2, or 3. Now that we have more than two groups, we need to admit that what we were doing in Chapter <a href="chapter2.html#chapter2">2</a> was actually fitting what is called a <strong><em>linear model</em></strong>. The linear model assumes that the responses follow a normal distribution with the linear model defining the mean, all observations have the same variance, and the parameters for the mean in the model enter linearly. This last condition is hard to explain at this level of material – it is sufficient to know that there are models where the parameters enter the model nonlinearly and that they are beyond the scope of this function and this material. By employing a general modeling methodology, we will be able to use the same general modeling framework for the methods in Chapters <a href="chapter3.html#chapter3">3</a>, <a href="chapter4.html#chapter4">4</a>, <a href="chapter6.html#chapter6">6</a>, <a href="chapter7.html#chapter7">7</a>, and <a href="chapter8.html#chapter8">8</a>.</p>
<p>As in Chapter <a href="chapter2.html#chapter2">2</a>, we have a null hypothesis that defines a situation (and model) where all the groups have the same mean. Specifically, the <strong><em>null hypothesis</em></strong> in the general situation with <span class="math inline">\(J\)</span> groups (<span class="math inline">\(J\ge 2\)</span>) is to have all the <span class="math inline">\(\underline{\text{true}}\)</span> group means equal,</p>
<p><span class="math display">\[H_0:\mu_1 = \ldots \mu_J.\]</span></p>
<p>This defines a model where all the groups have the same mean so it can be defined in terms of a single mean, <span class="math inline">\(\mu\)</span>, for the <span class="math inline">\(i^{th}\)</span> observation from the <span class="math inline">\(j^{th}\)</span> group as <span class="math inline">\(y_{ij} = \mu+\varepsilon_{ij}\)</span>. This is not the model that most researchers want to be the final description of their study as it implies no difference in the groups. There is more caution required to specify the alternative hypothesis with more than two groups. The <strong><em>alternative hypothesis</em></strong> needs to be the logical negation of this null hypothesis of all groups having equal means; to make the null hypothesis false, we only need one group to differ but more than one group could differ from the others. Essentially, there are many ways to “violate” the null hypothesis so we choose some delicate wording for the alternative hypothesis when there are more than 2 groups. Specifically, we state the alternative as</p>
<p><span class="math display">\[H_A: \text{ Not all } \mu_j \text{ are equal}\]</span></p>
<p>or, in words, <strong>at least one of the true means differs among the J groups</strong>. You will be attracted to trying to say that all means are different in the alternative but we do not put this strict a requirement in place to reject the null hypothesis. The alternative model allows all the true group means to differ but does require that they differ with</p>
<p><span class="math display">\[y_{ij} = {\color{red}{\mu_j}}+\varepsilon_{ij}.\]</span></p>
<p>This linear model states that the response for the <span class="math inline">\(i^{th}\)</span> observation in the <span class="math inline">\(j^{th}\)</span> group, <span class="math inline">\(\mathbf{y_{ij}}\)</span>, is modeled with a group <span class="math inline">\(j\)</span> (<span class="math inline">\(j=1, \ldots, J\)</span>) population mean, <span class="math inline">\(\mu_j\)</span>, and a random error for each subject in each group <span class="math inline">\(\varepsilon_{ij}\)</span>, that we assume follows a normal distribution and that all the random errors have the same variance, <span class="math inline">\(\sigma^2\)</span>. We can write the assumption about the random errors, often called the <strong><em>normality assumption</em></strong>, as <span class="math inline">\(\varepsilon_{ij} \sim N(0,\sigma^2)\)</span>. There is a second way to write out this model that allows extension to more complex models discussed below, so we need a name for this version of the model. The model written in terms of the <span class="math inline">\({\color{red}{\mu_j}}\text{&#39;s}\)</span> is called the <b><font color='red'>cell means model</font></b> and is the easier version of this model to understand.</p>
<p>One of the reasons we learned about beanplots is that it helps us visually consider all the aspects of this model. In the right panel of Figure <a href="chapter3.html#fig:Figure3-1">3.1</a>, we can see the wider, bold horizontal lines that provide the estimated group means. The bigger the differences in the sample means, the more likely we are to find evidence against the null hypothesis. You can also see the null model on the plot that assumes all the groups have the same mean as displayed in the dashed horizontal line at 4.7 years (the R code below shows the overall mean of <em>Years</em> is 4.7). While the hypotheses focus on the means, the model also contains assumptions about the distribution of the responses – specifically that the distributions are normal and that all the groups have the same variability. As discussed previously, it appears that the distributions are right skewed and the variability might not be the same for all the groups. The boxplot provides the information about the skew and variability but since it doesn’t display the means it is not directly related to the linear model and hypotheses we are considering.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(MockJury<span class="op">$</span>Years)</code></pre></div>
<pre><code>## [1] 4.692982</code></pre>
<p>There is a second way to write out the One-Way ANOVA model that provides a framework for extensions to more complex models described in Chapter <a href="chapter4.html#chapter4">4</a> and beyond. The other <strong><em>parameterization</em></strong> (way of writing out or defining) of the model is called the <b><font color='purple'>reference-coded model</font></b> since it writes out the model in terms of a <strong><em>baseline group</em></strong> and deviations from that baseline or reference level. The reference-coded model for the <span class="math inline">\(i^{th}\)</span> subject in the <span class="math inline">\(j^{th}\)</span> group is <span class="math inline">\(y_{ij} ={\color{purple}{\boldsymbol{\alpha + \tau_j}}}+\varepsilon_{ij}\)</span> where <span class="math inline">\(\color{purple}{\boldsymbol{\alpha}}\)</span> (alpha) is the true mean for the baseline group (first alphabetically) and the <span class="math inline">\(\color{purple}{\boldsymbol{\tau_j}}\)</span> (tau <span class="math inline">\(j\)</span>) are the deviations from the baseline group for group <span class="math inline">\(j\)</span>. The deviation for the baseline group, <span class="math inline">\(\color{purple}{\boldsymbol{\tau_1}}\)</span>, is always set to 0 so there are really just deviations for groups 2 through <span class="math inline">\(J\)</span>. The equivalence between the two models can be seen by considering the mean for the first, second, and <span class="math inline">\(J^{th}\)</span> groups in both models:</p>
<p><span class="math display">\[\begin{array}{lccc}
&amp; \textbf{Cell means:} &amp;&amp; \textbf{Reference-coded:}\\
\textbf{Group } 1: &amp; \color{red}{\mu_1} &amp;&amp; \color{purple}{\boldsymbol{\alpha}} \\
\textbf{Group } 2: &amp; \color{red}{\mu_2} &amp;&amp; \color{purple}{\boldsymbol{\alpha + \tau_2}} \\
\ldots &amp; \ldots &amp;&amp; \ldots \\
\textbf{Group } J: &amp; \color{red}{\mu_J} &amp;&amp; \color{purple}{\boldsymbol{\alpha +\tau_J}}
\end{array}\]</span></p>
<p>The hypotheses for the reference-coded model are similar to those in the cell-means coding except that they are defined in terms of the deviations, <span class="math inline">\({\color{purple}{\boldsymbol{\tau_j}}}\)</span>. The null hypothesis is that there is no deviation from the baseline for any group – that all the <span class="math inline">\({\color{purple}{\boldsymbol{\tau_j\text{&#39;s}}}}=0\)</span>,</p>
<p><span class="math display">\[\boldsymbol{H_0: \tau_2=\ldots=\tau_J=0}.\]</span></p>
<p>The alternative hypothesis is that at least one of the deviations is not 0,</p>
<p><span class="math display">\[\boldsymbol{H_A:} \textbf{ Not all } \boldsymbol{\tau_j} \textbf{ equal } \bf{0}.\]</span></p>
<p>In this chapter, you are welcome to use either version (unless we instruct you otherwise) but we have to use the reference-coding in subsequent chapters. The next task is to learn how to use R’s linear model, <code>lm</code>, function to get estimates of the parameters in each model, but first a quick review of these new ideas:</p>
<p><b><font color='red'>Cell Means Version</font></b></p>
<ul>
<li><p><span class="math inline">\(H_0: {\color{red}{\mu_1=\ldots\mu_J}}\)</span>             <span class="math inline">\(H_A: {\color{red}{\text{ Not all } \mu_j \text{ equal}}}\)</span></p></li>
<li><p>Null hypothesis in words: No difference in the true means between the groups.</p></li>
<li><p>Null model: <span class="math inline">\(y_{ij} = \mu_j+\varepsilon_{ij}\)</span></p></li>
<li><p>Alternative hypothesis in words: At least one of the true means differs between the groups.</p></li>
<li><p>Alternative model: <span class="math inline">\(y_{ij} = \color{red}{\mu_j}+\varepsilon_{ij}.\)</span></p></li>
</ul>
<p><b><font color='purple'>Reference-coded Version</font></b></p>
<ul>
<li><p><span class="math inline">\(H_0: \color{purple}{\boldsymbol{\tau_2 \ldots \tau_J = 0}}\)</span>          <span class="math inline">\(H_A: \color{purple}{\text{ Not all } \tau_j \text{ equal 0}}\)</span></p></li>
<li><p>Null hypothesis in words: No deviation of the true mean for any groups from the baseline group.</p></li>
<li><p>Null model: <span class="math inline">\(y_{ij} =\boldsymbol{\alpha} +\varepsilon_{ij}\)</span></p></li>
<li><p>Alternative hypothesis in words: At least one of the true deviations is different from 0 or that at least one group has a different true mean than the baseline group.</p></li>
<li><p>Alternative model: <span class="math inline">\(y_{ij} =\color{purple}{\boldsymbol{\alpha + \tau_j}}+\varepsilon_{ij}\)</span></p></li>
</ul>
<p>In order to estimate the models discussed above, the <code>lm</code> function is used<a href="#fn38" class="footnoteRef" id="fnref38"><sup>38</sup></a>. The <code>lm</code> function continues to use the same format as previous functions, <code>lm(Y~X, data=datasetname)</code>. It ends up that this code will give you the reference-coded version of the model by default (The developers of R thought it was that important!). We want to start with the cell-means version of the model, so we have to override the standard technique and add a “<code>-1</code>” to the formula interface to tell R that we want to the cell-means coding. Generally, this looks like <code>lm(Y~X-1, data=datasetname).</code> Once we fit a model in R, the <code>summary</code> function run on the model provides a useful “summary” of the model coefficients and a suite of other potentially interesting information. For the moment, we will focus on the estimated model coefficients, so only those lines are output. When fitting this version of the One-Way ANOVA model, you will find a row of output for each group relating the <span class="math inline">\(\mu_j\text{&#39;s}\)</span>. The output contains columns for an estimate (<code>Estimate</code>), standard error (<code>Std. Error</code>), <span class="math inline">\(t\)</span>-value (<code>t value</code>), and p-value (<code>Pr(&gt;|t|)</code>). We’ll learn to use all the output in the following material, but for now just focus on the estimates of the parameters that the function provides in the first column (“Estimate”) of the coefficient table.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm1 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span>Attr<span class="op">-</span><span class="dv">1</span>, <span class="dt">data=</span>MockJury)
<span class="kw">summary</span>(lm1)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##                  Estimate Std. Error  t value     Pr(&gt;|t|)
## AttrBeautiful    4.333333  0.5729959 7.562590 1.225982e-11
## AttrAverage      3.973684  0.5804864 6.845439 4.412410e-10
## AttrUnattractive 5.810811  0.5882785 9.877653 6.857681e-17</code></pre>
<p>In general, we denote estimated parameters with a hat over the parameter of interest to show that it is an estimate. For the true mean of group <span class="math inline">\(j\)</span>, <span class="math inline">\(\mu_j\)</span>, we estimate it with <span class="math inline">\(\hat{\mu}_j\)</span>, which is just the sample mean for group <span class="math inline">\(j\)</span>, <span class="math inline">\(\bar{x}_j\)</span>. The model suggests an estimate for each observation that we denote as <span class="math inline">\(\hat{y}_{ij}\)</span> that we will also call a <strong><em>fitted value</em></strong> based on the model being considered. The same estimate is used for all observations in the each group. R tries to help you to sort out which row of output corresponds to which group by appending the group name with the variable name. Here, the variable name was <code>Attr</code> and the first group alphabetically was <em>Beautiful</em>, so R provides a row labeled <code>AttrBeautiful</code> with an estimate of 4.3333. The sample means from the three groups can be seen to directly match for that group and the other two.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##     4.333333     3.973684     5.810811</code></pre>
<p>The reference-coded version of the same model is more complicated but ends up giving the same results once we understand what it is doing. It uses a different parameterization to accomplish this, so has different model output. Here is the model summary:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)
<span class="kw">summary</span>(lm2)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##                    Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept)       4.3333333  0.5729959  7.5625901 1.225982e-11
## AttrAverage      -0.3596491  0.8156524 -0.4409343 6.601182e-01
## AttrUnattractive  1.4774775  0.8212161  1.7991335 7.471470e-02</code></pre>
<p>The estimated model coefficients are <span class="math inline">\(\hat{\alpha} = 4.333\)</span> years, <span class="math inline">\(\hat{\tau}_2 =-0.3596\)</span> years, <span class="math inline">\(\hat{\tau}_3=1.4775\)</span> years where R selected group 1 for <em>Beautiful</em>, 2 for <em>Average</em>, and 3 for <em>Unattractive</em>. The way you can figure out the baseline group (group 1 is <em>Beautiful</em> here) is to see which category label is <em>not present</em> in the output. <strong>The baseline level is typically the first group label alphabetically</strong>, but you should always check this. Based on these definitions, there are interpretations available for each coefficient. For <span class="math inline">\(\hat{\alpha} = 4.333\)</span> years, this is an estimate of the mean sentencing time for the <em>Beautiful</em> group. <span class="math inline">\(\hat{\tau}_2 =-0.3596\)</span> years is the deviation of the <em>Average</em> group’s mean from the <em>Beautiful</em> group’s mean (specifically, it is <span class="math inline">\(0.36\)</span> years lower). Finally, <span class="math inline">\(\hat{\tau}_3=1.4775\)</span> years tells us that the <em>Unattractive</em> group mean sentencing time is 1.48 years higher than the <em>Beautiful</em> group mean sentencing time. These interpretations lead directly to reconstructing the estimated means for each group by combining the baseline and pertinent deviations as shown in Table <a href="chapter3.html#tab:Table3-1">3.1</a>.</p>

<table>
<caption><span id="tab:Table3-1">Table 3.1: </span> Constructing group mean estimates from the reference-coded linear model estimates.</caption>
<colgroup>
<col width="20%" />
<col width="40%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Group</th>
<th align="left">Formula</th>
<th align="left">Estimates</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Beautiful</td>
<td align="left"><span class="math inline">\(\hat{\alpha}\)</span></td>
<td align="left"><strong>4.3333</strong> years</td>
</tr>
<tr class="even">
<td align="left">Average</td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_2\)</span></td>
<td align="left">4.3333 - 0.3596 = <strong>3.974</strong> years</td>
</tr>
<tr class="odd">
<td align="left">Unattractive</td>
<td align="left"><span class="math inline">\(\hat{\alpha}+\hat{\tau}_3\)</span></td>
<td align="left">4.3333 + 1.4775 = <strong>5.811</strong> years</td>
</tr>
</tbody>
</table>
<p>We can also visualize the results of our linear models using what are called <strong><em>term-plots</em></strong> or <strong><em>effect-plots</em></strong> (from the <code>effects</code> package; <span class="citation">(Fox et al. <a href="#ref-R-effects">2018</a>)</span>) as displayed in Figure <a href="chapter3.html#fig:Figure3-2">3.2</a>. We don’t want to use the word “effect” for these model components unless we have random assignment in the study design so we generically call these <strong><em>term-plots</em></strong> as they display terms or components from the model in hopefully useful ways to aid in model interpretation even in the presence of complicated model parameterizations. Specifically, these plots take an estimated model and show you its estimates along with 95% confidence intervals generated by the linear model. To make this plot, you need to install and load the <code>effects</code> package and then use <code>plot(allEffects(...))</code> functions together on the <code>lm</code> object called <code>lm2</code> that was estimated above. You can find the correspondence between the displayed means and the estimates that were constructed in Table <a href="chapter3.html#tab:Table3-1">3.1</a>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(lm2))</code></pre></div>
<div class="figure"><span id="fig:Figure3-2"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-2-1.png" alt="Plot of the estimated group mean sentences from the reference-coded model for the MockJury data from the effects package." width="384" />
<p class="caption">
Figure 3.2: Plot of the estimated group mean sentences from the reference-coded model for the MockJury data from the <code>effects</code> package.
</p>
</div>
<p>In order to assess evidence for having different means for the groups, we will compare either of the previous models (cell-means or reference-coded) to a null model based on the null hypothesis (<span class="math inline">\(H_0: \mu_1 = \ldots = \mu_J\)</span>) which implies a model of <span class="math inline">\(\color{red}{y_{ij} = \mu_j}+\varepsilon_{ij}\)</span> in the cell-means version where <span class="math inline">\({\color{red}{\mu}}\)</span> is a common mean for all the observations. We will call this the <b><font color='red'>mean-only</font></b> model since it only has a single mean in it. In the reference-coded version of the model, we have a null hypothesis that <span class="math inline">\(H_0: \tau_2 = \ldots = \tau_J = 0\)</span>, so the “mean-only” model is <span class="math inline">\(\color{purple}{y_{ij} =\boldsymbol{\alpha}+\varepsilon_{ij}}\)</span> with <span class="math inline">\(\color{purple}{\boldsymbol{\alpha}}\)</span> having the same definition as <span class="math inline">\(\color{red}{\mu}\)</span> for the cell means model – it forces a common value for the mean for all the groups. Moving from the <em>reference-coded</em> model to the <em>mean-only</em> model is also an example of a situation where we move from a “full” model to a “reduced” model by setting some coefficients in the “full” model to 0 and, by doing this, get a simpler or “reduced” model. Simple models can be good as they are easier to interpret, but having a model for <span class="math inline">\(J\)</span> groups that suggests no difference in the groups is not a very exciting result in most, but not all, situations<a href="#fn39" class="footnoteRef" id="fnref39"><sup>39</sup></a>. In order for R to provide results for the mean-only model, we remove the grouping variable, <code>Attr</code>, from the model formula and just include a “1”. The <code>(Intercept)</code> row of the output provides the estimate for the mean-only model as a reduced model from either the cell-means or reference-coded models when we assume that the mean is the same for all groups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm3 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span><span class="dv">1</span>, <span class="dt">data=</span>MockJury)
<span class="kw">summary</span>(lm3)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##             Estimate Std. Error  t value     Pr(&gt;|t|)
## (Intercept) 4.692982  0.3403532 13.78857 5.765681e-26</code></pre>
<p>This model provides an estimate of the common mean for all observations of <span class="math inline">\(4.693 = \hat{\mu} = \hat{\alpha}\)</span> years. This value also is the dashed, horizontal line in the beanplot in Figure <a href="chapter3.html#fig:Figure3-1">3.1</a>. Some people call this mean-only model estimate the grand or overall mean.</p>
</div>
<div id="section3-3" class="section level2">
<h2><span class="header-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</h2>
<p>The previous discussion showed two ways of parameterizing models for the One-Way ANOVA model and getting estimates from output but still hasn’t addressed how to assess evidence related to whether the observed differences in the means among the groups is “real”. In this section, we develop what is called the <strong><em>ANOVA F-test</em></strong> that provides a method of aggregating the differences among the means of 2 or more groups and testing our null hypothesis of no difference in the means vs the alternative. In order to develop the test, some additional notation is needed. The sample size in each group is denoted <span class="math inline">\(n_j\)</span> and the total sample size is <span class="math inline">\(\boldsymbol{N=\Sigma n_j = n_1 + n_2 + \ldots + n_J}\)</span> where <span class="math inline">\(\Sigma\)</span> (capital sigma) means “add up over whatever follows”. An estimated <strong><em>residual</em></strong> (<span class="math inline">\(e_{ij}\)</span>) is the difference between an observation, <span class="math inline">\(y_{ij}\)</span>, and the model estimate, <span class="math inline">\(\hat{y}_{ij} = \hat{\mu}_j\)</span>, for that observation, <span class="math inline">\(y_{ij}-\hat{y}_{ij} = e_{ij}\)</span>. It is basically what is left over that the mean part of the model (<span class="math inline">\(\hat{\mu}_{j}\)</span>) does not explain. It is also a window into how “good” the model might be because it reflects what the model was unable to explain.</p>
<p>Consider the four different fake results for a situation with four groups (<span class="math inline">\(J=4\)</span>) displayed in Figure <a href="chapter3.html#fig:Figure3-3">3.3</a>. Which of the different results shows the most and least evidence of differences in the means? In trying to answer this, think about both how different the means are (obviously important) and how variable the results are around the mean. These situations were created to have the same means in Scenarios 1 and 2 as well as matching means in Scenarios 3 and 4. The variability around the means matches by shading (lighter or darker). In Scenarios 1 and 2, the differences in the means is smaller than in the other two results. But Scenario 2 should provide more evidence of what little difference in present than Scenario 1 because it has less variability around the means. The best situation for finding group differences here is Scenario 4 since it has the largest difference in the means and the least variability around those means. Our test statistic somehow needs to allow a comparison of the variability in the means to the overall variability to help us get results that reflect that Scenario 4 has the strongest evidence of a difference and Scenario 1 would have the least.</p>

<div class="figure"><span id="fig:Figure3-3"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-3-1.png" alt="Demonstration of different amounts of difference in means relative to variability. Scenarios have same means in rows and same variance around means in columns of plot." width="576" />
<p class="caption">
Figure 3.3: Demonstration of different amounts of difference in means relative to variability. Scenarios have same means in rows and same variance around means in columns of plot.
</p>
</div>
<p>The statistic that allows the comparison of relative amounts of variation is called the <strong><em>ANOVA F-statistic</em></strong>. It is developed using <strong><em>sums of squares</em></strong> which are measures of total variation like those that are used in the numerator of the standard deviation (<span class="math inline">\(\Sigma_1^N(y_i-\bar{y})^2\)</span>) that took all the observations, subtracted the mean, squared the differences, and then added up the results over all the observations to generate a measure of total variability. With multiple groups, we will focus on decomposing that total variability (<strong><em>Total Sums of Squares</em></strong>) into variability among the means (we’ll call this <strong><em>Explanatory Variable</em></strong> <span class="math inline">\(\mathbf{A}\textbf{&#39;s}\)</span> <strong><em>Sums of Squares</em></strong>) and variability in the residuals or errors (<strong><em>Error Sums of Squares</em></strong>). We define each of these quantities in the One-Way ANOVA situation as follows:</p>
<ul>
<li><p><span class="math inline">\(\textbf{SS}_{\textbf{Total}} =\)</span> Total Sums of Squares <span class="math inline">\(= \Sigma^J_{j=1}\Sigma^{n_j}_{i=1}(y_{ij}-\bar{\bar{y}})^2\)</span></p>
<ul>
<li><p>This is the total variation in the responses around the overall or <strong><em>grand mean</em></strong> (<span class="math inline">\(\bar{\bar{y}}\)</span>, the estimated mean for all the observations and available from the mean-only model).</p></li>
<li><p>By summing over all <span class="math inline">\(n_j\)</span> observations in each group, <span class="math inline">\(\Sigma^{n_j}_{i=1}(\ )\)</span>, and then adding those results up across the groups, <span class="math inline">\(\Sigma^J_{j=1}(\ )\)</span>, we accumulate the variation across all <span class="math inline">\(N\)</span> observations.</p></li>
<li><p>Note: this is the residual variation if the null model is used, so there is no further decomposition possible for that model.</p></li>
<li><p>This is also equivalent to the numerator of the sample variance, <span class="math inline">\(\Sigma^{N}_{1}(y_{i}-\bar{y})^2\)</span> which is what you get when you ignore the information on the potential differences in the groups.</p></li>
</ul></li>
<li><p><span class="math inline">\(\textbf{SS}_{\textbf{A}} =\)</span> Explanatory Variable <em>A</em>’s Sums of Squares <span class="math inline">\(=\Sigma^J_{j=1}\Sigma^{n_j}_{i=1}(\bar{y}_{j}-\bar{\bar{y}})^2 =\Sigma^J_{j=1}n_j(\bar{y}_{j}-\bar{\bar{y}})^2\)</span></p>
<ul>
<li><p>This is the variation in the group means around the grand mean based on the explanatory variable <span class="math inline">\(A\)</span>.</p></li>
<li><p>Also called sums of squares for the treatment, regression, or model.</p></li>
</ul></li>
<li><p><span class="math inline">\(\textbf{SS}_\textbf{E} =\)</span> Error (Residual) Sums of Squares <span class="math inline">\(=\Sigma^J_{j=1}\Sigma^{n_j}_{i=1}(y_{ij}-\bar{y}_j)^2 =\Sigma^J_{j=1}\Sigma^{n_j}_{i=1}(e_{ij})^2\)</span></p>
<ul>
<li><p>This is the variation in the responses around the group means.</p></li>
<li><p>Also called the sums of squares for the residuals, with the second version of the formula showing that it is just the squared residuals added up across all the observations.</p></li>
</ul></li>
</ul>
<p>The possibly surprising result given the mass of notation just presented is that the total sums of squares is <strong>ALWAYS</strong> equal to the sum of explanatory variable <span class="math inline">\(A\text{&#39;s}\)</span> sum of squares and the error sums of squares,</p>
<p><span class="math display">\[\textbf{SS}_{\textbf{Total}} \mathbf{=} \textbf{SS}_\textbf{A} \mathbf{+} \textbf{SS}_\textbf{E}.\]</span></p>
<p>This result is called the <strong><em>sums of squares decomposition formula</em></strong>. The equality means that if the <span class="math inline">\(\textbf{SS}_\textbf{A}\)</span> goes up, then the <span class="math inline">\(\textbf{SS}_\textbf{E}\)</span> must go down if <span class="math inline">\(\textbf{SS}_{\textbf{Total}}\)</span> remains the same. We use these results to build our test statistic and organize this information in what is called an <strong><em>ANOVA table</em></strong>. The ANOVA table is generated using the <code>anova</code> function applied to the reference-coded model, <code>lm2</code> :</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)
<span class="kw">anova</span>(lm2)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Years
##            Df  Sum Sq Mean Sq F value Pr(&gt;F)
## Attr        2   70.94  35.469    2.77  0.067
## Residuals 111 1421.32  12.805</code></pre>
<p>Note that the ANOVA table has a row labelled <code>Attr</code>, which contains information for the grouping variable (we’ll generally refer to this as explanatory variable <span class="math inline">\(A\)</span> but here it is the picture group that was randomly assigned), and a row labeled <code>Residuals</code>, which is synonymous with “Error”. The Sums of Squares (SS) are available in the <code>Sum Sq</code> column. It doesn’t show a row for “Total” but the <span class="math inline">\(\textbf{SS}_{\textbf{Total}} \mathbf{=} \textbf{SS}_\textbf{A} \mathbf{+} \textbf{SS}_\textbf{E} = 1492.26\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="fl">70.94</span> <span class="op">+</span><span class="st"> </span><span class="fl">1421.32</span></code></pre></div>
<pre><code>## [1] 1492.26</code></pre>
<div class="figure"><span id="fig:Figure3-4"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-4-1.png" alt="Plot of means and 95% confidence intervals for the three groups for the real Mock Jury data (a) and three different permutations of the treatment labels to the same responses in (b), (c), and (d). Note that SSTotal is always the same but the different amounts of variation associated with the means (SSA) or the errors (SSE) changes in permutation." width="576" />
<p class="caption">
Figure 3.4: Plot of means and 95% confidence intervals for the three groups for the real Mock Jury data (a) and three different permutations of the treatment labels to the same responses in (b), (c), and (d). Note that <code>SSTotal</code> is always the same but the different amounts of variation associated with the means (<code>SSA</code>) or the errors (<code>SSE</code>) changes in permutation.
</p>
</div>
<p>It may be easiest to understand the <em>sums of squares decomposition</em> by connecting it to our permutation ideas. In a permutation situation, the total variation (<span class="math inline">\(SS_\text{Total}\)</span>) cannot change – it is the same responses varying around the grand mean. However, the amount of variation attributed to variation among the means and in the residuals can change if we change which observations go with which group. In Figure <a href="chapter3.html#fig:Figure3-4">3.4</a> (panel a), the means, sums of squares, and 95% confidence intervals for each mean are displayed for the three treatment levels from the original prisoner rating data. Three permuted versions of the data set are summarized in panels (b), (c), and (d). The <span class="math inline">\(\text{SS}_A\)</span> is 70.9 in the real data set and between 6.5 and 40.5 in the permuted data sets. If you had to pick among the plots for the one with the most evidence of a difference in the means, you hopefully would pick panel (a). This visual “unusualness” suggests that this observed result is unusual relative to the possibilities under permutations, which are, again, the possibilities tied to having the null hypothesis being true. But note that the differences here are not that great between these three permuted data sets and the real one. It is likely that at least some might have selected panel (d) as also looking like it shows some evidence of differences (maybe not the most?) as it looks like it shows some evidence differences.</p>
<p>One way to think about <span class="math inline">\(\textbf{SS}_\textbf{A}\)</span> is that it is a function that converts the variation in the group means into a single value. This makes it a reasonable test statistic in a permutation testing context. By comparing the observed <span class="math inline">\(\text{SS}_A =\)</span> 70.9 to the permutation results of 6.5, 9.7, and 40.5 we see that the observed result is much more extreme than the three alternate versions. In contrast to our previous test statistics where positive and negative differences were possible, <span class="math inline">\(\text{SS}_A\)</span> is always positive with a value of 0 corresponding to no variation in the means. The larger the <span class="math inline">\(\text{SS}_A\)</span>, the more variation there is in the means. The permutation p-value for the alternative hypothesis of <strong>some</strong> (not of greater or less than!) difference in the true means of the groups will involve counting the number of permuted <span class="math inline">\(SS_A^*\)</span> results that are as large or larger than what we observed.</p>

<p>To do a permutation test, we need to be able to calculate and extract the <span class="math inline">\(\text{SS}_A\)</span> value. In the ANOVA table, it is the second number in the first row; we can use the bracket, <code>[,]</code>, referencing to extract that number from the ANOVA table that <code>anova</code> produces with <code>anova(lm(Years~Attr, data=MockJury))[1, 2]</code>. We’ll store the observed value of <span class="math inline">\(\text{SS}_A\)</span> in <code>Tobs</code>, reusing some ideas from Chapter <a href="chapter2.html#chapter2">2</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Tobs &lt;-<span class="st"> </span><span class="kw">anova</span>(<span class="kw">lm</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury))[<span class="dv">1</span>,<span class="dv">2</span>]; Tobs</code></pre></div>
<pre><code>## [1] 70.93836</code></pre>
<p>The following code performs the permutations <code>B=1,000</code> times using the <code>shuffle</code> function, builds up a vector of results in <code>Tobs</code>, and then makes a plot of the resulting permutation distribution:</p>

<div class="figure"><span id="fig:Figure3-5"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-5-1.png" alt="Histogram and density curve of permutation distribution of \(\text{SS}_A\) with the observed value of \(\text{SS}_A\) displayed as a bold, vertical line. The proportion of results that are as large or larger than the observed value of \(\text{SS}_A\) provides an estimate of the p-value." width="960" />
<p class="caption">
Figure 3.5: Histogram and density curve of permutation distribution of <span class="math inline">\(\text{SS}_A\)</span> with the observed value of <span class="math inline">\(\text{SS}_A\)</span> displayed as a bold, vertical line. The proportion of results that are as large or larger than the observed value of <span class="math inline">\(\text{SS}_A\)</span> provides an estimate of the p-value.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">1000</span>
Tstar &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>B)
<span class="cf">for</span> (b <span class="cf">in</span> (<span class="dv">1</span><span class="op">:</span>B)){
  Tstar[b] &lt;-<span class="st"> </span><span class="kw">anova</span>(<span class="kw">lm</span>(Years<span class="op">~</span><span class="kw">shuffle</span>(Attr), <span class="dt">data=</span>MockJury))[<span class="dv">1</span>,<span class="dv">2</span>]
  }
<span class="kw">hist</span>(Tstar, <span class="dt">labels=</span>T, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">550</span>))
<span class="kw">abline</span>(<span class="dt">v=</span>Tobs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">plot</span>(<span class="kw">density</span>(Tstar), <span class="dt">main=</span><span class="st">&quot;Density curve of Tstar&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>Tobs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>
<p>The right-skewed distribution (Figure <a href="chapter3.html#fig:Figure3-5">3.5</a>) contains the distribution of <span class="math inline">\(\text{SS}^*_A\text{&#39;s}\)</span> under permutations (where all the groups are assumed to be equivalent under the null hypothesis). While the observed result is larger than many of the <span class="math inline">\(\text{SS}^*_A\text{&#39;s}\)</span>, there are also many permuted results that are much larger than observed. The proportion of permuted results that exceed the observed value is found using <code>pdata</code> as before, except only for the area to the right of the observed result. We know that <code>Tobs</code> will always be positive so no absolute values are required here.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pdata</span>(Tstar, Tobs, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 0.072</code></pre>
<p>This provides a permutation-based p-value of 0.072 and suggests marginal evidence against the null hypothesis of no difference in the true means. We would interpret this p-value as saying that there is a 7.2% chance of getting a <span class="math inline">\(\text{SS}_A\)</span> as large or larger than we observed, given that the null hypothesis is true.</p>
<p>It ends up that some nice parametric statistical results are available (if our assumptions are met) for the ratio of estimated variances, the estimated variances are called <strong><em>Mean Squares</em></strong>. To turn sums of squares into mean square (variance) estimates, we divide the sums of squares by the amount of free information available. For example, remember the typical variance estimator introductory statistics, <span class="math inline">\(\Sigma^N_1(y_i-\bar{y})^2/(N-1)\)</span>? Your instructor spent some time trying various approaches to explaining why we have a denominator of <span class="math inline">\(N-1\)</span>. The most useful for our purposes moving forward is that we “lose” one piece of information to estimate the mean and there are <span class="math inline">\(N\)</span> deviations around the single mean so we divide by <span class="math inline">\(N-1\)</span>. The main point is that the sums of squares were divided by something and we got an estimator for the variance, here of the observations overall.</p>
<p>Now consider <span class="math inline">\(\text{SS}_E = \Sigma^J_{j=1}\Sigma^{n_j}_{i=1}(y_{ij}-\bar{y}_j)^2\)</span> which still has <span class="math inline">\(N\)</span> deviations but it varies around the <span class="math inline">\(J\)</span> means, so the</p>
<p><span class="math display">\[\textbf{Mean Square Error} = \text{MS}_E = \text{SS}_E/(N-J).\]</span></p>
<p>Basically, we lose <span class="math inline">\(J\)</span> pieces of information in this calculation because we have to estimate <span class="math inline">\(J\)</span> means. The similar calculation of the <strong><em>Mean Square for variable</em></strong> <span class="math inline">\(\mathbf{A}\)</span> (<span class="math inline">\(\text{MS}_A\)</span>) is harder to see in the formula (<span class="math inline">\(\text{SS}_A = \Sigma^J_{j=1}n_j(\bar{y}_i-\bar{\bar{y}})^2\)</span>), but the same reasoning can be used to understand the denominator for forming <span class="math inline">\(\text{MS}_A\)</span>: there are <span class="math inline">\(J\)</span> means that vary around the grand mean so</p>
<p><span class="math display">\[\text{MS}_A = \text{SS}_A/(J-1).\]</span></p>
<p>In summary, the two mean squares are simply:</p>
<ul>
<li><p><span class="math inline">\(\text{MS}_A = \text{SS}_A/(J-1)\)</span>, which estimates the variance of the group means around the grand mean.</p></li>
<li><p><span class="math inline">\(\text{MS}_{\text{Error}} = \text{SS}_{\text{Error}}/(N-J)\)</span>, which estimates the variation of the errors around the group means.</p></li>
</ul>
<p>These results are put together using a ratio to define the <strong><em>ANOVA F-statistic</em></strong> (also called the <strong><em>F-ratio</em></strong>) as:</p>
<p><span class="math display">\[F=\text{MS}_A/\text{MS}_{\text{Error}}.\]</span></p>
<p>If the variability in the means is “similar” to the variability in the residuals, the statistic would have a value around 1. If that variability is similar then there would be no evidence of a difference in the means. If the <span class="math inline">\(\text{MS}_A\)</span> is much larger than the <span class="math inline">\(\text{MS}_E\)</span>, the <span class="math inline">\(F\)</span>-statistic will provide evidence against the null hypothesis. The “size” of the <span class="math inline">\(F\)</span>-statistic is formalized by finding the p-value. The <span class="math inline">\(F\)</span>-statistic, if assumptions discussed below are met and we assume the null hypothesis is true, follows what is called an <span class="math inline">\(F\)</span>-distribution. The <strong><em>F-distribution</em></strong> is a right-skewed distribution whose shape is defined by what are called the <strong><em>numerator degrees of freedom</em></strong> (<span class="math inline">\(J-1\)</span>) and the <strong><em>denominator degrees of freedom</em></strong> (<span class="math inline">\(N-J\)</span>). These names correspond to the values that we used to calculate the mean squares and where in the <span class="math inline">\(F\)</span>-ratio each mean square was used; <span class="math inline">\(F\)</span>-distributions are denoted by their degrees of freedom using the convention of <span class="math inline">\(F\)</span> (<em>numerator df</em>, <em>denominator df</em>). Some examples of different <span class="math inline">\(F\)</span>-distributions are displayed for you in Figure <a href="chapter3.html#fig:Figure3-6">3.6</a>.</p>
<p>The characteristics of the F-distribution can be summarized as:</p>
<ul>
<li><p>Right skewed,</p></li>
<li><p>Nonzero probabilities for values greater than 0,</p></li>
<li><p>Its shape changes depending on the <strong>numerator</strong> and <strong>denominator DF</strong>, and</p></li>
<li><p><strong>Always use the right-tailed area for p-values.</strong></p></li>
</ul>

<div class="figure"><span id="fig:Figure3-6"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-6-1.png" alt="Density curves of four different \(F\)-distributions. Upper left is an \(F(2, 111)\), upper right is \(F(2, 10)\), lower left is \(F(6, 10)\), and lower right is \(F(6, 111)\). P-values are found using the areas to the right of the observed \(F\)-statistic value in all F-distributions." width="480" />
<p class="caption">
Figure 3.6: Density curves of four different <span class="math inline">\(F\)</span>-distributions. Upper left is an <span class="math inline">\(F(2, 111)\)</span>, upper right is <span class="math inline">\(F(2, 10)\)</span>, lower left is <span class="math inline">\(F(6, 10)\)</span>, and lower right is <span class="math inline">\(F(6, 111)\)</span>. P-values are found using the areas to the right of the observed <span class="math inline">\(F\)</span>-statistic value in all F-distributions.
</p>
</div>
<p>Now we are ready to discuss an ANOVA table since we know about each of its components. Note the general format of the ANOVA table is in Table <a href="chapter3.html#tab:Table3-2">3.2</a><a href="#fn40" class="footnoteRef" id="fnref40"><sup>40</sup></a>:</p>

<table>
<caption><span id="tab:Table3-2">Table 3.2: </span> General One-Way ANOVA table.</caption>
<colgroup>
<col width="13%" />
<col width="7%" />
<col width="18%" />
<col width="21%" />
<col width="19%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Source  </th>
<th align="left">DF </th>
<th align="left">Sums of<br />
Squares</th>
<th align="left">Mean Squares</th>
<th align="left">F-ratio</th>
<th align="left">P-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Variable A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/(J-1)\)</span></td>
<td align="left"><span class="math inline">\(F=\text{MS}_A/\text{MS}_E\)</span></td>
<td align="left">Right tail of <span class="math inline">\(F(J-1,N-J)\)</span></td>
</tr>
<tr class="even">
<td align="left">Residuals</td>
<td align="left"><span class="math inline">\(N-J\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E = \text{SS}_E/(N-J)\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="left"><span class="math inline">\(N-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_{\text{Total}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>The table is oriented to help you reconstruct the <span class="math inline">\(F\)</span>-ratio from each of its components. The output from R is similar although it does not provide the last row and sometimes switches the order of columns in different functions we will use. The R version of the table for the type of picture effect (<code>Attr</code>) with <span class="math inline">\(J=3\)</span> levels and <span class="math inline">\(N=114\)</span> observations, repeated from above, is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(lm2)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Years
##            Df  Sum Sq Mean Sq F value Pr(&gt;F)
## Attr        2   70.94  35.469    2.77  0.067
## Residuals 111 1421.32  12.805</code></pre>
<p>The p-value from the <span class="math inline">\(F\)</span>-distribution is 0.067. We can verify this result using the observed <span class="math inline">\(F\)</span>-statistic of 2.77 (which came from taking the ratio of the two mean squares, F=35.47/12.8) which follows an <span class="math inline">\(F(2, 111)\)</span> distribution if the null hypothesis is true and some other assumptions are met.</p>
<p>Using the <code>pf</code> function provides us with areas in the specified <span class="math inline">\(F\)</span>-distribution with the <code>df1</code> provided to the function as the numerator <em>df</em> and <code>df2</code> as the denominator <em>df</em> and <code>lower.tail=F</code> reflecting our desire for a right tailed area.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="fl">2.77</span>, <span class="dt">df1=</span><span class="dv">2</span>, <span class="dt">df2=</span><span class="dv">111</span>, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 0.06699803</code></pre>
<p>The result from the <span class="math inline">\(F\)</span>-distribution using this parametric procedure is similar to the p-value obtained using permutations with the test statistic of the <span class="math inline">\(\text{SS}_A\)</span>, which was 0.067. The <span class="math inline">\(F\)</span>-statistic obviously is another potential test statistic to use as a test statistic in a permutation approach, now that we know about it. We should check that we get similar results from it with permutations as we did from using <span class="math inline">\(\text{SS}_A\)</span> as a permutation-test test statistic. The following code generates the permutation distribution for the <span class="math inline">\(F\)</span>-statistic (Figure <a href="chapter3.html#fig:Figure3-7">3.7</a>) and assesses how unusual the observed <span class="math inline">\(F\)</span>-statistic of 2.77 was in this permutation distribution. The only change in the code involves moving from extracting <span class="math inline">\(\text{SS}_A\)</span> to extracting the <span class="math inline">\(F\)</span>-ratio which is in the 4<sup>th</sup> column of the <code>anova</code> output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Tobs &lt;-<span class="st"> </span><span class="kw">anova</span>(<span class="kw">lm</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury))[<span class="dv">1</span>,<span class="dv">4</span>]; Tobs</code></pre></div>
<pre><code>## [1] 2.770024</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">B &lt;-<span class="st"> </span><span class="dv">1000</span>
Tstar &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>B)
<span class="cf">for</span> (b <span class="cf">in</span> (<span class="dv">1</span><span class="op">:</span>B)){
  Tstar[b] &lt;-<span class="st"> </span><span class="kw">anova</span>(<span class="kw">lm</span>(Years<span class="op">~</span><span class="kw">shuffle</span>(Attr), <span class="dt">data=</span>MockJury))[<span class="dv">1</span>,<span class="dv">4</span>]
}

<span class="kw">pdata</span>(Tstar, Tobs, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 0.064</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(Tstar, <span class="dt">labels=</span>T)
<span class="kw">abline</span>(<span class="dt">v=</span>Tobs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">plot</span>(<span class="kw">density</span>(Tstar), <span class="dt">main=</span><span class="st">&quot;Density curve of Tstar&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>Tobs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>

<div class="figure"><span id="fig:Figure3-7"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-7-1.png" alt="Histogram and density curve of the permutation distribution of the F-statistic with bold, vertical line for the observed value of the test statistic of 2.77." width="960" />
<p class="caption">
Figure 3.7: Histogram and density curve of the permutation distribution of the F-statistic with bold, vertical line for the observed value of the test statistic of 2.77.
</p>
</div>
<p>The permutation-based p-value is 0.064 which, again, matches the other results closely. The first conclusion is that using a test statistic of either the <span class="math inline">\(F\)</span>-statistic or the <span class="math inline">\(\text{SS}_A\)</span> provide similar permutation results. However, we tend to favor using the <span class="math inline">\(F\)</span>-statistic because it is more commonly used in reporting ANOVA results, not because it is any better in a permutation context.</p>
<p>It is also interesting to compare the permutation distribution for the <span class="math inline">\(F\)</span>-statistic and the parametric <span class="math inline">\(F(2, 111)\)</span> distribution (Figure <a href="chapter3.html#fig:Figure3-8">3.8</a>). They do not match perfectly but are quite similar. Some the differences around 0 are due to the behavior of the method used to create the density curve and are not really a problem for the methods. The similarity in the two curves explains why both methods give similar results. In some situations, the correspondence will not be quite so close.</p>

<div class="figure"><span id="fig:Figure3-8"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-8-1.png" alt="Comparison of \(F(2, 111)\) (dashed line) and permutation distribution (solid line)." width="480" />
<p class="caption">
Figure 3.8: Comparison of <span class="math inline">\(F(2, 111)\)</span> (dashed line) and permutation distribution (solid line).
</p>
</div>
<p>So how can we rectify this result (<span class="math inline">\(\text{p-value}\approx 0.06\)</span>) and the Chapter <a href="chapter2.html#chapter2">2</a> result that detected a difference between <em>Average</em> and <em>Unattractive</em> with a <span class="math inline">\(\text{p-value}\approx 0.03\)</span>? I selected the two groups to compare in Chapter <a href="chapter2.html#chapter2">2</a> because they were furthest apart. “Cherry-picking” the comparison that is likely to be most different creates a false sense of the real situation and inflates the Type I error rate because of the selection<a href="#fn41" class="footnoteRef" id="fnref41"><sup>41</sup></a>. If the entire suite of pairwise comparisons are considered, this result may lose some of its luster. In other words, if we consider the suite of three pair-wise differences (and the tests) implicit in comparing all of them, we may need stronger evidence in the most different pair than a p-value of 0.033 to suggest overall differences. In this situation, the <em>Beautiful</em> and <em>Average</em> groups are not that different from each other so their difference does not contribute much to the overall <span class="math inline">\(F\)</span>-test. In Section <a href="chapter3.html#section3-6">3.6</a>, we will revisit this topic and consider a method that is statistically valid for performing all possible pair-wise comparisons that is also consistent with our overall test results.</p>
</div>
<div id="section3-4" class="section level2">
<h2><span class="header-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</h2>
<p>The requirements for a One-Way ANOVA <span class="math inline">\(F\)</span>-test are similar to those discussed in Chapter <a href="chapter2.html#chapter2">2</a>, except that there are now <span class="math inline">\(J\)</span> groups instead of only 2. Specifically, the linear model assumes:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Independent observations</strong>,</p></li>
<li><p><strong>Equal variances</strong>, and</p></li>
<li><p><strong>Normal distributions</strong>.</p></li>
</ol>
<p>For assessing equal variances across the groups, it is best to use plots to assess this. We can use boxplots and beanplots to compare the spreads of the groups, which were provided in Figure <a href="chapter3.html#fig:Figure3-1">3.1</a>. The range and IQRs should be relatively similar across the groups if you do not find evidence of a problem with this assumption. You should start with noting how clear or big the violation of the assumption might be but remember that there will always be some differences in the variation among groups even if the true variability is exactly equal in the populations. In addition to our direct plotting, there are some diagnostic plots available from the <code>lm</code> function that can help us more clearly assess potential violations of the previous assumptions.</p>
<p>We can obtain a suite of four diagnostic plots by using the <code>plot</code> function on any linear model object that we have fit. To get all the plots together in four panels we need to add the <code>par(mfrow=c(2,2))</code> command to tell R to make a graph with 4 panels<a href="#fn42" class="footnoteRef" id="fnref42"><sup>42</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(lm2, <span class="dt">pch=</span><span class="dv">16</span>)</code></pre></div>
<p>There are two plots in Figure <a href="chapter3.html#fig:Figure3-9">3.9</a> with useful information for assessing the equal variance assumption. The “Residuals vs Fitted” panel in the top left panel displays the residuals <span class="math inline">\((e_{ij} = y_{ij}-\hat{y}_{ij})\)</span> on the y-axis and the fitted values <span class="math inline">\((\hat{y}_{ij})\)</span> on the x-axis. This allows you to see if the variability of the observations differs across the groups as a function of the mean of the groups, because all the observations in the same group get the same fitted value – the mean of the group. In this plot, the points seem to have fairly similar spreads at the fitted values for the three groups with fitted values of 4, 4.3, and 6. The “Scale-Location” plot in the lower left panel has the same x-axis but the y-axis contains the square-root of the absolute value of the standardized residuals. The absolute value transforms all the residuals into a magnitude scale (removing direction) and the square-root helps you see differences in variability more accurately. The standardization scales the residuals to have a variance of 1 so help you in other displays to get a sense of how many standard deviations you are away from the mean in the residual distribution. The visual assessment is similar in the two plots – you want to consider whether it appears that the groups have somewhat similar or noticeably different amounts of variability. If you see a clear funnel shape in the Residuals vs Fitted or an increase or decrease in the upper edge of points in the Scale-Location plot that may indicate a violation of the constant variance assumption. Remember that some variation across the groups is expected and is OK, but large differences in spreads are problematic for all the procedures that involve linear models. When discussing these results, you want to discuss how clearly the differences in variation are and whether that <em>shows a clear violation of the assumption</em> of equal variance for all observations. Like in hypothesis testing, you can never prove that you’ve met assumptions based on a plot “looking OK”, but you can say that there is no clear evidence that the assumption is violated!</p>

<div class="figure"><span id="fig:Figure3-9"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-9-1.png" alt="Default diagnostic plots for the Mock Jury full linear model." width="960" />
<p class="caption">
Figure 3.9: Default diagnostic plots for the Mock Jury full linear model.
</p>
</div>
<p>The linear model also assumes that all the random errors (<span class="math inline">\(\varepsilon_{ij}\)</span>) follow a normal distribution. To gain insight into the validity of this assumption, we can explore the original observations as displayed in the beanplots, mentally subtracting off the differences in the means and focusing on the shapes of the distributions of observations in each group. These plots are especially good for assessing whether there is a skew or outliers present in each group. If so, by definition, the normality assumption is violated. But our assumption is about the distribution of all the errors after removing the differences in the means and so we want an overall assessment technique to understand how reasonable our assumption is overall for our model. The residuals from the entire model provide us with estimates of the random errors and if the normality assumption is met, then the residuals all-together should approximately follow a normal distribution. The <strong><em>Normal Q-Q Plot</em></strong> in the upper right panel of Figure <a href="chapter3.html#fig:Figure3-9">3.9</a> is a direct visual assessment of how well our residuals match what we would expect from a normal distribution. Outliers, skew, heavy and light-tailed aspects of distributions (all violations of normality) show up in this plot once you learn to read it – which is our next task. To make it easier to read QQ-plots, it is nice to start with just considering histograms and/or density plots of the residuals and to see how that maps into this new display. We can obtain the residuals from the linear model using the <code>residuals</code> function on any linear model object.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
eij &lt;-<span class="st"> </span><span class="kw">residuals</span>(lm2)
<span class="kw">hist</span>(eij, <span class="dt">main=</span><span class="st">&quot;Histogram of residuals&quot;</span>)
<span class="kw">plot</span>(<span class="kw">density</span>(eij), <span class="dt">main=</span><span class="st">&quot;Density plot of residuals&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;Residuals&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure3-10"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-10-1.png" alt="Histogram and density curve of the linear model raw residuals from the Mock Jury linear model." width="960" />
<p class="caption">
Figure 3.10: Histogram and density curve of the linear model raw residuals from the Mock Jury linear model.
</p>
</div>
<p>Figure <a href="chapter3.html#fig:Figure3-10">3.10</a> shows that there is a right skew present in the residuals for the model for the prisoner ratings that accounted for different means in the three picture groups, which is consistent with the initial assessment of some right skew in the plots of observations in each group.</p>
<p>A Quantile-Quantile plot (<strong><em>QQ-plot</em></strong>) shows the “match” of an observed distribution with a theoretical distribution, almost always the normal distribution. They are also known as Quantile Comparison, Normal Probability, or Normal Q-Q plots, with the last two names being specific to comparing results to a normal distribution. In this version<a href="#fn43" class="footnoteRef" id="fnref43"><sup>43</sup></a>, the QQ-plots display the value of observed percentiles in the residual distribution on the y-axis versus the percentiles of a theoretical normal distribution on the x-axis. If the observed <strong>distribution of the residuals matches the shape of the normal distribution, then the plotted points should follow a 1-1 relationship.</strong> If the points follow the displayed straight line then that suggests that the residuals have a similar shape to a normal distribution. Some variation is expected around the line and some patterns of deviation are worse than others for our models, so you need to go beyond saying “it does not match a normal distribution”. It is best to be specific about the type of deviation you are detecting. And to do that, we need to practice interpreting some QQ-plots.</p>
<p>The QQ-plot of the linear model residuals from Figure <a href="chapter3.html#fig:Figure3-9">3.9</a> is extracted and enhanced it a little to make Figure <a href="chapter3.html#fig:Figure3-11">3.11</a> so we can just focus on it. We know from looking at the histogram that this is a slightly right skewed distribution. The QQ-plot places the observed <strong><em>standardized</em></strong><a href="#fn44" class="footnoteRef" id="fnref44"><sup>44</sup></a> <strong><em>residuals</em></strong> on the y-axis and the theoretical normal values on the x-axis. The most noticeable deviation from the 1-1 line is in the lower left corner of the plot. These are for the negative residuals (left tail) and there are many residuals at around the same value that are a little smaller than -1. If the distribution had followed the normal distribution here, the points would be on the 1-1 line and there would be some standardized residuals much smaller than -1.5. So we are not getting as much spread in the smaller residuals as we would expect in a normal distribution. If you go back to the histogram you can see that the smallest residuals are all stacked up and do not spread out like the left tail of a normal distribution should. In the right tail (positive) residuals, there is also a systematic lifting from the 1-1 line to larger values in the residuals than the normal would generate. For example, the point labeled as “82” in Figure <a href="chapter3.html#fig:Figure3-9">3.9</a> (the 82<sup>nd</sup> observation in the data set) has a value of 3 in residuals but should actually be smaller (maybe 2.5) if the distribution was normal. Put together, this pattern in the QQ-plot suggests that the left tail is too compacted (too short) and the right tail is too spread out – this is the right skew we identified from the histogram and density curve!</p>

<pre><code>## [1] 82 48</code></pre>
<div class="figure"><span id="fig:Figure3-11"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-11-1.png" alt="QQ-plot of residuals from Mock Jury linear model." width="576" />
<p class="caption">
Figure 3.11: QQ-plot of residuals from Mock Jury linear model.
</p>
</div>
<p>Generally, when both tails deviate on the same side of the line (forming a sort of quadratic curve, especially in more extreme cases), that is evidence of a skew. To see some different potential shapes in QQ-plots, six different data sets are displayed in Figures <a href="chapter3.html#fig:Figure3-12">3.12</a> and <a href="chapter3.html#fig:Figure3-13">3.13</a>. In each row, a QQ-plot and associated density curve are displayed. If the points are both above the 1-1 line in the lower and upper tails as in Figure <a href="chapter3.html#fig:Figure3-12">3.12</a>(a), then the pattern is a right skew, here even more extreme than in the previous real data set. If the points are below the 1-1 line in both tails as in Figure <a href="chapter3.html#fig:Figure3-12">3.12</a>(c), then the pattern is identified as a left skew. Skewed residual distributions (either direction) are problematic for models that assume normally distributed responses but not necessarily for our permutation approaches if all the groups have similar skewed shapes. The other problematic pattern is to have more spread than a normal curve as in Figure <a href="chapter3.html#fig:Figure3-12">3.12</a>(e) and (f). This shows up with the points being below the line in the left tail (more extreme negative than expected by the normal) and the points being above the line for the right tail (more extreme positive than the normal predicts). We call these distributions <strong><em>heavy-tailed</em></strong> which can manifest as distributions with outliers in both tails or just a bit more spread out than a normal distribution. Heavy-tailed residual distributions can be problematic for our models as the variation is greater than what the normal distribution can account for and our methods might under-estimate the variability in the results. The opposite pattern with the left tail above the line and the right tail below the line suggests less spread (<strong><em>lighter-tailed</em></strong>) than a normal as in Figure <a href="chapter3.html#fig:Figure3-12">3.12</a>(g) and (h). This pattern is relatively harmless and you can proceed with methods that assume normality safely as they will just be a little conservative. For any of the patterns, you would note a potential violation of the normality assumption and then proceed to describe the type of violation and how clear or extreme it seems to be.</p>

<pre><code>## [1] 47  4</code></pre>
<pre><code>## [1] 34 40</code></pre>
<pre><code>## [1]  7 48</code></pre>
<pre><code>## [1] 63  8</code></pre>
<div class="figure"><span id="fig:Figure3-12"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-12-1.png" alt="QQ-plots and density curves of four simulated distributions with different shapes." width="576" />
<p class="caption">
Figure 3.12: QQ-plots and density curves of four simulated distributions with different shapes.
</p>
</div>
<p>Finally, to help you calibrate expectations for data that are actually normally distributed, two data sets simulated from normal distributions are displayed in Figure <a href="chapter3.html#fig:Figure3-13">3.13</a>. Note how neither follows the line exactly but that the overall pattern matches fairly well. <strong>You have to allow for some variation from the line in real data sets</strong> and focus on when there are really noticeable issues in the distribution of the residuals such as those displayed above. Again, you will never be able to prove that you have normally distributed residuals even if the residuals are all exactly on the line, but if you see QQ-plots as in Figure <a href="chapter3.html#fig:Figure3-12">3.12</a> you can determine that there is clear evidence of violations of the normality assumption.</p>

<pre><code>## [1] 26 35</code></pre>
<pre><code>## [1] 12 50</code></pre>
<div class="figure"><span id="fig:Figure3-13"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-13-1.png" alt="Two more simulated data sets, both generated from normal distributions." width="576" />
<p class="caption">
Figure 3.13: Two more simulated data sets, both generated from normal distributions.
</p>
</div>
<p>The last issues with assessing the assumptions in an ANOVA relates to situations where the methods are more or less <strong><em>resistant</em></strong><a href="#fn45" class="footnoteRef" id="fnref45"><sup>45</sup></a> to violations of assumptions. In simulation studies of the performance of the <span class="math inline">\(F\)</span>-test, researchers have found that the parametric ANOVA <span class="math inline">\(F\)</span>-test is more resistant to violations of the assumptions of the normality and equal variance assumptions if the design is balanced. A <strong><em>balanced design</em></strong> occurs when each group is measured the same number of times. The resistance decreases as the data set becomes less balanced, as the sample sizes in the groups are more different, so having close to balance is preferred to a more imbalanced situation if there is a choice available. There is some intuition available here – it makes some sense that you would have better results in comparing groups if the information available is similar in all the groups and none are relatively under-represented. We can check the number of observations in each group to see if they are equal or similar using the <code>tally</code> function from the <code>mosaic</code> package. This function is useful for being able to get counts of observations, especially for cross-classifying observations on two variables that is used in Chapter <a href="chapter5.html#chapter5">5</a>. For just a single variable, we use <code>tally(~x, data=...)</code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(mosaic)
<span class="kw">tally</span>(<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)</code></pre></div>
<pre><code>## Attr
##    Beautiful      Average Unattractive 
##           39           38           37</code></pre>
<p>So the sample sizes do vary among the groups and the design is technically not balanced, but it is also very close to being balanced with only two more observations in the largest group compared to the smallest group size. This tells us that the <span class="math inline">\(F\)</span>-test should have some resistance to violations of assumptions. This nearly balanced design, and the moderate sample size (over 37 per group is considered a good but not large sample), make the parametric and nonparametric approaches provide similar results in this data set even in the presence of the skewed residual error distribution that presents a violation to the assumptions of the parametric procedure.</p>
</div>
<div id="section3-5" class="section level2">
<h2><span class="header-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</h2>
<p>A second example of the One-way ANOVA methods involves a study of length of odontoblasts (cells that are responsible for tooth growth) in 60 Guinea Pigs (measured in microns) from <span class="citation">Crampton (<a href="#ref-Crampton1947">1947</a>)</span>. <span class="math inline">\(N=60\)</span> Guinea Pigs were obtained from a local breeder and each received one of three dosages (0.5, 1, or 2 mg/day) of Vitamin C via one of two delivery methods, Orange Juice (<em>OJ</em>) or ascorbic acid (the stuff in vitamin C capsules, called <span class="math inline">\(\text{VC}\)</span> below) as the source of Vitamin C in their diets. Each guinea pig was randomly assigned to receive one of the six different treatment combinations possible (OJ at 0.5 mg, OJ at 1 mg, OJ at 2 mg, VC at 0.5 mg, VC at 1 mg, and VC at 2 mg). The animals were treated similarly otherwise and we can assume lived in separate cages and only one observation was taken for each guinea pig, so we can assume the observations are independent<a href="#fn46" class="footnoteRef" id="fnref46"><sup>46</sup></a>. We need to create a variable that combines the levels of delivery type (OJ, VC) and the dosages (0.5, 1, and 2) to use our One-Way ANOVA on the six levels. The <code>interaction</code> function can be used create a new variable that is based on combinations of the levels of other variables. Here a new variable is created in the <code>ToothGrowth</code> tibble that we called <code>Treat</code> using the <code>interaction</code> function that provides a six-level grouping variable for our One-Way ANOVA to compare the combinations of treatments. To get a sense of the pattern of observations in the data set, the counts in <code>supp</code> (supplement type) and <code>dose</code> are provided and then the counts in the new categorical explanatory variable, <code>Treat</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(ToothGrowth) <span class="co">#Available in Base R</span>
<span class="kw">require</span>(tibble)
ToothGrowth &lt;-<span class="st"> </span><span class="kw">as.tibble</span>(ToothGrowth) <span class="co">#Convert data.frame to tibble</span>
<span class="kw">require</span>(mosaic)
<span class="kw">tally</span>(<span class="op">~</span>supp, <span class="dt">data=</span>ToothGrowth) <span class="co">#Supplement Type (VC or OJ)</span></code></pre></div>
<pre><code>## supp
## OJ VC 
## 30 30</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tally</span>(<span class="op">~</span>dose, <span class="dt">data=</span>ToothGrowth) <span class="co">#Dosage level</span></code></pre></div>
<pre><code>## dose
## 0.5   1   2 
##  20  20  20</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Creates a new variable Treat with 6 levels</span>
ToothGrowth<span class="op">$</span>Treat &lt;-<span class="st"> </span><span class="kw">with</span>(ToothGrowth, <span class="kw">interaction</span>(supp, dose)) 

<span class="co">#New variable that combines supplement type and dosage</span>
<span class="kw">tally</span>(<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth) </code></pre></div>
<pre><code>## Treat
## OJ.0.5 VC.0.5   OJ.1   VC.1   OJ.2   VC.2 
##     10     10     10     10     10     10</code></pre>
<p>The <code>tally</code> function helps us to check for balance; this is a balanced design because the same number of guinea pigs (<span class="math inline">\(n_j=10 \text{ for } j=1, 2,\ldots, 6\)</span>) were measured in each treatment combination.</p>
<p>With the variable <code>Treat</code> prepared, the first task is to visualize the results using boxplots and beanplots<a href="#fn47" class="footnoteRef" id="fnref47"><sup>47</sup></a> (Figure <a href="chapter3.html#fig:Figure3-14">3.14</a>) and generate some summary statistics for each group using <code>favstats</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">favstats</span>(len<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth)</code></pre></div>
<pre><code>##    Treat  min     Q1 median     Q3  max  mean       sd  n missing
## 1 OJ.0.5  8.2  9.700  12.25 16.175 21.5 13.23 4.459709 10       0
## 2 VC.0.5  4.2  5.950   7.15 10.900 11.5  7.98 2.746634 10       0
## 3   OJ.1 14.5 20.300  23.45 25.650 27.3 22.70 3.910953 10       0
## 4   VC.1 13.6 15.275  16.50 17.300 22.5 16.77 2.515309 10       0
## 5   OJ.2 22.4 24.575  25.95 27.075 30.9 26.06 2.655058 10       0
## 6   VC.2 18.5 23.375  25.95 28.800 33.9 26.14 4.797731 10       0</code></pre>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">boxplot</span>(len<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth, <span class="dt">ylab=</span><span class="st">&quot;Odontoblast Growth in microns&quot;</span>)
<span class="kw">beanplot</span>(len<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth, <span class="dt">log=</span><span class="st">&quot;&quot;</span>, <span class="dt">col=</span><span class="st">&quot;yellow&quot;</span>,
         <span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Odontoblast Growth in microns&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure3-14"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-14-1.png" alt="Boxplot and beanplot of odontoblast growth responses for the six treatment level combinations." width="1152" />
<p class="caption">
Figure 3.14: Boxplot and beanplot of odontoblast growth responses for the six treatment level combinations.
</p>
</div>
<p>Figure <a href="chapter3.html#fig:Figure3-14">3.14</a> suggests that the mean tooth growth increases with the dosage level and that OJ might lead to higher growth rates than VC except at a dosage of 2 mg/day. The variability around the means looks to be small relative to the differences among the means, so we should expect a small p-value from our <span class="math inline">\(F\)</span>-test. The design is balanced as noted above (<span class="math inline">\(n_j=10\)</span> for all six groups) so the methods are some what resistant to impacts from non-normality and non-constant variance but we should still assess the patterns in the plots. There is some suggestion of non-constant variance in the plots but this will be explored further below when we can remove the difference in the means and combine all the residuals together. There might be some skew in the responses in some of the groups but there are only 10 observations per group so visual evidence of skew in the boxplots and beanplots could be generated by impacts of very few of the observations.</p>
<p>Now we can apply our 6+ steps for performing a hypothesis test with these observations. The initial step is deciding on the claim to be assessed and the test statistic to use. This is a six group situation with a quantitative response, identifying it as a One-Way ANOVA where we want to test a null hypothesis that all the groups have the same population mean, at least to start. We will use a 5% significance level.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Hypotheses</strong>: <span class="math inline">\(\boldsymbol{H_0: \mu_{\text{OJ}0.5} = \mu_{\text{VC}0.5} = \mu_{\text{OJ}1} = \mu_{\text{VC}1} = \mu_{\text{OJ}2} = \mu_{\text{VC}2}} \textbf{ vs }\)</span> <span class="math inline">\(\boldsymbol{H_A:}\textbf{ Not all } \boldsymbol{\mu_j} \textbf{ equal}\)</span></p>
<ul>
<li><p>The null hypothesis could also be written in reference-coding as below since OJ.0.5 is chosen as the baseline group (discussed below).</p>
<ul>
<li><span class="math inline">\(\boldsymbol{H_0:\tau_{\text{VC}0.5}=\tau_{\text{OJ}1}=\tau_{\text{VC}1}=\tau_{\text{OJ}2}=\tau_{\text{VC}2}=0}\)</span></li>
</ul></li>
<li><p>The alternative hypothesis can be left a bit less specific:</p>
<ul>
<li><span class="math inline">\(\boldsymbol{H_A:} \textbf{ Not all } \boldsymbol{\tau_j} \textbf{ equal 0}\)</span></li>
</ul></li>
</ul></li>
<li><p><strong>Validity conditions</strong>:</p>
<ul>
<li><p>Independence:</p>
<ul>
<li>This is where the separate cages note above is important. Suppose that there were cages that contained multiple animals and they competed for food or could share illness or levels of activity. The animals in one cage might be systematically different from the others and this “clustering” of observations would present a potential violation of the independence assumption. If the experiment had the animals in separate cages, there is no clear dependency in the design of the study and we can assume<a href="#fn48" class="footnoteRef" id="fnref48"><sup>48</sup></a> that there is no problem with this assumption.</li>
</ul></li>
<li><p>Constant variance:</p>
<ul>
<li>As noted above, there is some indication of a difference in the variability among the groups in the boxplots and beanplots but the sample size was small in each group. We need to fit the linear model to get the other diagnostic plots to make an overall assessment.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(len<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(m2,<span class="dt">pch=</span><span class="dv">16</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure3-15"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-15-1.png" alt="Diagnostic plots for the odontoblast growth model." width="960" />
<p class="caption">
Figure 3.15: Diagnostic plots for the odontoblast growth model.
</p>
</div>
<ul>
<li><p>The Residuals vs Fitted panel in Figure <a href="chapter3.html#fig:Figure3-15">3.15</a> shows some difference in the spreads but the spread is not that different between the groups.</p></li>
<li><p>The Scale-Location plot also shows just a little less variability in the group with the smallest fitted value but the spread of the groups looks fairly similar in this alternative scaling.</p></li>
<li><p>Put together, the evidence for non-constant variance is not that strong and we can proceed comfortably that there is at least not a major problem with this assumption.</p></li>
</ul></li>
<li><p>Normality of residuals:</p>
<ul>
<li>The Normal Q-Q plot shows a small deviation in the lower tail but nothing that we wouldn’t expect from a normal distribution. So there is no evidence of a problem with the normality assumption in the upper right panel of Figure <a href="chapter3.html#fig:Figure3-15">3.15</a>.</li>
</ul></li>
</ul></li>
<li><p><strong>Calculate the test statistic</strong>:</p>
<ul>
<li>The ANOVA table for our model follows, providing an <span class="math inline">\(F\)</span>-statistic of 41.557:</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(m2)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: len
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)
## Treat      5 2740.10  548.02  41.557 &lt; 2.2e-16
## Residuals 54  712.11   13.19</code></pre></li>
</ol>

<ol start="4" style="list-style-type: decimal">
<li><p><strong>Find the p-value</strong>:</p>
<ul>
<li><p>There are two options here, especially since it seems that our assumptions about variance and normality are not violated (note that we do not say “met” – we just have no clear evidence against them). The parametric and nonparametric approaches should provide similar results here.</p></li>
<li><p>The parametric approach is easiest – the p-value comes from the previous ANOVA table as <code>&lt; 2e-16</code>. First, note that this is in scientific notation that is a compact way of saying that the p-value here is <span class="math inline">\(2.2*10^{-16}\)</span> or 0.00000000000000022. When you see <code>2.2e-16</code> in R output, it also means that the calculation is at the numerical precision limits of the computer. What R is really trying to report is that this is a very small number. <strong>When you encounter p-values that are smaller than 0.0001, you should just report that the p-value &lt; 0.0001.</strong> Do not report that it is 0 as this gives the false impression that there is no chance of the result occurring when it is just a really small probability. This p-value came from an <span class="math inline">\(F(5,54)\)</span> distribution (this is the distribution of the test statistic if the null hypothesis is true).</p></li>
<li><p>The nonparametric approach is not too hard so we can compare the two approaches here as well:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Tobs &lt;-<span class="st"> </span><span class="kw">anova</span>(<span class="kw">lm</span>(len<span class="op">~</span>Treat, <span class="dt">data=</span>ToothGrowth))[<span class="dv">1</span>,<span class="dv">4</span>]; Tobs</code></pre></div>
<pre><code>## [1] 41.55718</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
B &lt;-<span class="st"> </span><span class="dv">1000</span>
Tstar &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>B)
<span class="cf">for</span> (b <span class="cf">in</span> (<span class="dv">1</span><span class="op">:</span>B)){
  Tstar[b] &lt;-<span class="st"> </span><span class="kw">anova</span>(<span class="kw">lm</span>(len<span class="op">~</span><span class="kw">shuffle</span>(Treat), <span class="dt">data=</span>ToothGrowth))[<span class="dv">1</span>,<span class="dv">4</span>]
}
<span class="kw">pdata</span>(Tstar, Tobs, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(Tstar, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,Tobs<span class="op">+</span><span class="dv">3</span>))
<span class="kw">abline</span>(<span class="dt">v=</span>Tobs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
<span class="kw">plot</span>(<span class="kw">density</span>(Tstar), <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,Tobs<span class="op">+</span><span class="dv">3</span>), <span class="dt">main=</span><span class="st">&quot;Density curve of Tstar&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v=</span>Tobs, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure3-16"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-16-1.png" alt="Histogram and density curve of permutation distribution for $F$-statistic for odontoblast growth data. Observed test statistic in bold, vertical line at 41.56." width="480" />
<p class="caption">
Figure 3.16: Histogram and density curve of permutation distribution for <span class="math inline">\(F\)</span>-statistic for odontoblast growth data. Observed test statistic in bold, vertical line at 41.56.
</p>
</div>
<ul>
<li><strong>The permutation p-value was reported as 0. This should be reported as p-value &lt; 0.001</strong> since we did 1,000 permutations and found that none of the permuted <span class="math inline">\(F\)</span>-statistics, <span class="math inline">\(F^*\)</span>, were larger than the observed <span class="math inline">\(F\)</span>-statistic of 41.56. The permuted results do not exceed 6 as seen in Figure <a href="chapter3.html#fig:Figure3-16">3.16</a>, so the observed result is <em>really unusual</em> relative to the null hypothesis. As suggested previously, the parametric and nonparametric approaches should be similar here and they were.</li>
</ul></li>
<li><p><strong>Make a decision</strong>:</p>
<ul>
<li>Reject <span class="math inline">\(H_0\)</span> since the p-value is very small.</li>
</ul></li>
<li><p><strong>Write a conclusion and do scope of inference</strong>:</p>
<ul>
<li><p>There is strong evidence that the different treatments (combinations of OJ/VC and dosage levels) <strong>cause some</strong> difference in the <strong>true</strong> mean odontoblast growth for <strong>these</strong> guinea pigs.</p>
<ul>
<li><p>We can make the causal statement of the treatment causing differences because the treatments were randomly assigned but these inferences only apply to these guinea pigs since they were not randomly selected from a larger population.</p></li>
<li><p>Remember that we are making inferences to the population or true means and not the sample means and want to make that clear in any conclusion. When there is not a random sample from a population it is more natural to discuss the true means since we can’t extend to the population values.</p></li>
<li><p>The alternative is that there is some difference in the true means – be sure to make the wording clear that you aren’t saying that all the means differ. In fact, if you look back at Figure <a href="chapter3.html#fig:Figure3-14">3.14</a>, the means for the 2 mg dosages look almost the same so we will have a tough time arguing that all groups differ. The <span class="math inline">\(F\)</span>-test is about finding evidence of some difference <em>somewhere</em> among the true means. The next section will provide some additional tools to get more specific about the source of those detected differences and allow us to get at estimates of the differences we observed to complete our interpretation.</p></li>
</ul></li>
</ul></li>
</ol>
<p>Before we leave this example, we should revisit our model estimates and interpretations. The default model parameterization uses reference-coding. Running the model <code>summary</code> function on <code>m2</code> provides the estimated coefficients:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(m2)<span class="op">$</span>coefficients</code></pre></div>
<pre><code>##             Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept)    13.23   1.148353 11.520847 3.602548e-16
## TreatVC.0.5    -5.25   1.624017 -3.232726 2.092470e-03
## TreatOJ.1       9.47   1.624017  5.831222 3.175641e-07
## TreatVC.1       3.54   1.624017  2.179781 3.365317e-02
## TreatOJ.2      12.83   1.624017  7.900166 1.429712e-10
## TreatVC.2      12.91   1.624017  7.949427 1.190410e-10</code></pre>
<p>For some practice with the reference coding used in these models, let’s find the estimates for observations for a couple of the groups. To work with the parameters, you need to start with determining the baseline category that was used by considering which level is not displayed in the output. The <code>levels</code> function can list the groups in a categorical variable and their coding in the data set. The first level is usually the baseline category but you should check this in the model summary as well.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">levels</span>(ToothGrowth<span class="op">$</span>Treat)</code></pre></div>
<pre><code>## [1] &quot;OJ.0.5&quot; &quot;VC.0.5&quot; &quot;OJ.1&quot;   &quot;VC.1&quot;   &quot;OJ.2&quot;   &quot;VC.2&quot;</code></pre>
<p>There is a <code>VC.0.5</code> in the second row of the model summary, but there is no row for <code>0J.0.5</code> and so this must be the baseline category. That means that the fitted value or model estimate for the OJ at 0.5 mg/day group is the same as the <code>(Intercept)</code> row or <span class="math inline">\(\hat{\alpha}\)</span>, estimating a mean tooth growth of 13.23 microns when the pigs get OJ at a 0.5 mg/day dosage level. You should always start with working on the baseline level in a reference-coded model. To get estimates for any other group, then you can use the <code>(Intercept)</code> estimate and add the deviation for the group of interest. For <code>VC.0.5</code>, the estimated mean tooth growth is <span class="math inline">\(\hat{\alpha} + \hat{\tau}_2 = \hat{\alpha} + \hat{\tau}_{\text{VC}0.5}=13.23 + (-5.25)=7.98\)</span> microns. It is also potentially interesting to directly interpret the estimated difference (or deviation) between <code>OJ.0.5</code> (the baseline) and <code>VC.0.5</code> (group 2) that is <span class="math inline">\(\hat{\tau}_{\text{VC}0.5}= -5.25\)</span>: we estimate that the mean tooth growth in <code>VC.0.5</code> is 5.25 microns shorter than it is in <code>OJ.0.5</code>. This and many other direct comparisons of groups are likely of interest to researchers involved in studying the impacts of these supplements on tooth growth and the next section will show us how to do that (correctly!).</p>
<p>The reference-coding is still going to feel a little uncomfortable so the comparison to the cell-means model and exploring the effect plot can help to reinforce that both models patch together the same estimated means for each group. For example, we can find our estimate of 7.98 microns for the VC0.5 group in the output and Figure <a href="chapter3.html#fig:Figure3-17">3.17</a>. Also note that Figure <a href="chapter3.html#fig:Figure3-17">3.17</a> is the same whether you plot the results from <code>m2</code> or <code>m3</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m3 &lt;-<span class="st"> </span><span class="kw">lm</span>(len<span class="op">~</span>Treat<span class="op">-</span><span class="dv">1</span>, <span class="dt">data=</span>ToothGrowth)
<span class="kw">summary</span>(m3)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = len ~ Treat - 1, data = ToothGrowth)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -8.20  -2.72  -0.27   2.65   8.27 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## TreatOJ.0.5   13.230      1.148  11.521 3.60e-16
## TreatVC.0.5    7.980      1.148   6.949 4.98e-09
## TreatOJ.1     22.700      1.148  19.767  &lt; 2e-16
## TreatVC.1     16.770      1.148  14.604  &lt; 2e-16
## TreatOJ.2     26.060      1.148  22.693  &lt; 2e-16
## TreatVC.2     26.140      1.148  22.763  &lt; 2e-16
## 
## Residual standard error: 3.631 on 54 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.968 
## F-statistic:   303 on 6 and 54 DF,  p-value: &lt; 2.2e-16</code></pre>

<div class="figure"><span id="fig:Figure3-17"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-17-1.png" alt="Effect plot of the One-Way ANOVA model for the odontoblast growth data." width="384" />
<p class="caption">
Figure 3.17: Effect plot of the One-Way ANOVA model for the odontoblast growth data.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">allEffects</span>(m2))</code></pre></div>

</div>
<div id="section3-6" class="section level2">
<h2><span class="header-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</h2>

<p>With evidence that the true means are likely not all equal, many researchers want to know which groups show evidence of differing from one another. This provides information on the source of the overall difference that was detected and detailed information on which groups differed from one another. Because this is a shot-gun/unfocused sort of approach, some people think it is an over-used procedure. Others feel that it is an important method of addressing detailed questions about group comparisons in a valid and safe way. For example, we might want to know if OJ is different from VC <em>at the 0.5 mg/day</em> dosage level and these methods will allow us to get an answer to this sort of question. It also will test for differences between the OJ.0.5 and VC.2 groups and every other pair of levels that you can construct. This method actually takes us back to the methods in Chapter <a href="chapter2.html#chapter2">2</a> where we compared the means of two groups except that we need to deal with potentially many pair-wise comparisons, making an adjustment to account for that inflation in Type I errors that occurs due to many tests being performed at the same time. There are many different statistical methods to make all the pair-wise comparisons, but we will employ the most commonly used one, called <strong><em>Tukey’s Honest Significant Difference</em></strong> (Tukey’s HSD) method<a href="#fn49" class="footnoteRef" id="fnref49"><sup>49</sup></a>. The name suggests that not using it could lead to a dishonest answer and that it will give you an honest result. It is more that if you don’t do some sort of correction for all the tests you are performing, you might find some <strong><em>spurious</em></strong><a href="#fn50" class="footnoteRef" id="fnref50"><sup>50</sup></a> results. There are other methods that could be used to do a similar correction and also provide “honest” inferences; we are just going to learn one of them.</p>
<p>Generally, the challenge in this situation is that if you perform many tests at the same time (instead of just one test), you inflate the Type I error rate. We can define the <strong><em>family-wise error rate</em></strong> as the probability that at least one error is made on a set of tests or, more compactly, Pr(At least 1 error is made) where Pr() is the probability of an event occurring. The family-wise error is meant to capture the overall situation in terms of measuring the likelihood of making a mistake if we consider many tests, each with some chance of making their own mistake, and focus on how often we make at least one error when we do many tests. A quick probability calculation shows the magnitude of the problem. If we start with a 5% significance level test, then Pr(Type I error on one test) =0.05 and the Pr(no errors made on one test) =0.95, by definition. This is our standard hypothesis testing situation. Now, suppose we have <span class="math inline">\(m\)</span> independent tests, then</p>
<p><span class="math display">\[\begin{array}{ll}
&amp; \text{Pr(make at least 1 Type I error given all null hypotheses are true)} \\
&amp; = 1 - \text{Pr(no errors made)} \\
&amp; = 1 - 0.95^m.
\end{array}\]</span></p>
<p>Figure <a href="chapter3.html#fig:Figure3-18">3.18</a> shows how the probability of having at least one false detection grows rapidly with the number of tests, <span class="math inline">\(m\)</span>. The plot stops at 100 tests since it is effectively a 100% chance of at least one false detection. It might seem like doing 100 tests is a lot, but in Genetics research it is possible to consider situations where millions of tests are considered so these are real issues to be concerned about in many situations. Researchers want to make sure that when they report a “significant” result that it is really likely to be a real result and will show up as a difference in the next data set they collect.<a href="#fn51" class="footnoteRef" id="fnref51"><sup>51</sup></a></p>

<div class="figure"><span id="fig:Figure3-18"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-18-1.png" alt="Plot of family-wise error rate as the number of tests performed increases. Dashed line indicates 0.05." width="480" />
<p class="caption">
Figure 3.18: Plot of family-wise error rate as the number of tests performed increases. Dashed line indicates 0.05.
</p>
</div>
<p>In pair-wise comparisons between all the pairs of means in a One-Way ANOVA, the number of tests is based on the number of pairs. We can calculate the number of tests using <span class="math inline">\(J\)</span> choose 2, <span class="math inline">\(\begin{pmatrix}J\\2\end{pmatrix}\)</span>, to get the number of unique pairs of size 2 that we can make out of <span class="math inline">\(J\)</span> individual treatment levels. We don’t need to explore the combinatorics formula for this, as the <code>choose</code> function in R can give us the answers:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">choose</span>(<span class="dv">3</span>,<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">choose</span>(<span class="dv">4</span>,<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 6</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">choose</span>(<span class="dv">5</span>,<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 10</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">choose</span>(<span class="dv">6</span>,<span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 15</code></pre>
<p>So if you have three groups (prisoner rating study), there are 3 unique pairs to compare. For six groups, like in the guinea pig study, we have to consider 15 tests to compare all the unique pairs of groups. 15 tests seems like enough that we should be worried about inflated family-wise error rates. Fortunately, the Tukey’s HSD method controls the family-wise error rate at your specified level (say 0.05) across any number of pair-wise comparisons. This means that the overall rate of at least one Type I error is controlled at the specified significance level, often 5%. To do this, each test must use a slightly more conservative cut-off than if just one test is performed and the procedure helps us figure out how much more conservative we need to be.</p>
<p>Tukey’s HSD starts with focusing on the difference between the groups with the largest and smallest means (<span class="math inline">\(\bar{y}_{max}-\bar{y}_{min}\)</span>). If <span class="math inline">\((\bar{y}_{max}-\bar{y}_{min}) \le \text{Margin of Error}\)</span> for the difference in the means, then all other pairwise differences, say <span class="math inline">\(\vert \bar{y}_j - \bar{y}_{j&#39;}\vert\)</span>, for two groups <span class="math inline">\(j\)</span> and <span class="math inline">\(j&#39;\)</span>, will be less than or equal to that margin of error. This also means that any confidence intervals for any difference in the means will contain 0. Tukey’s HSD selects a critical value so that (<span class="math inline">\(\bar{y}_{max}-\bar{y}_{min}\)</span>) will be less than the margin of error in 95% of data sets drawn from populations with a common mean. This implies that in 95% of data sets in which all the population means are the same, all confidence intervals for differences in pairs of means will contain 0. Tukey’s HSD provides confidence intervals for the difference in true means between groups <span class="math inline">\(j\)</span> and <span class="math inline">\(j&#39;\)</span>, <span class="math inline">\(\mu_j-\mu_{j&#39;}\)</span>, for all pairs where <span class="math inline">\(j \ne j&#39;\)</span>, using</p>
<p><span class="math display">\[(\bar{y}_j - \bar{y}_{j&#39;}) \mp \frac{q^*}{\sqrt{2}}\sqrt{\text{MS}_E\left(\frac{1}{n_j}+
\frac{1}{n_{j&#39;}}\right)}\]</span></p>
<p>where <span class="math inline">\(\frac{q^*}{\sqrt{2}}\sqrt{\text{MS}_E\left(\frac{1}{n_j}+\frac{1}{n_{j&#39;}}\right)}\)</span> is the margin of error for the intervals. The distribution used to find the multiplier, <span class="math inline">\(q^*\)</span>, for the confidence intervals is available in the <code>qtukey</code> function and generally provides a slightly larger multiplier than the regular <span class="math inline">\(t^*\)</span> from our two-sample <span class="math inline">\(t\)</span>-based confidence interval discussed in Chapter <a href="chapter2.html#chapter2">2</a>. The formula otherwise is very similar to the one used in Chapter <a href="chapter2.html#chapter2">2</a> with the SE for the difference in the means based on a measure of residual variance (here <span class="math inline">\(MS_E\)</span>) times <span class="math inline">\(\left(\frac{1}{n_j}+\frac{1}{n_{j&#39;}}\right)\)</span> which weights the results based on the relative sample sizes in the groups.</p>
<p>We will use the <code>confint</code>, <code>cld</code>, and <code>plot</code> functions applied to output from the <code>glht</code> function (all from the <code>multcomp</code> package; <span class="citation">Hothorn, Bretz, and Westfall (<a href="#ref-Hothorn2008">2008</a>)</span>, <span class="citation">(Hothorn, Bretz, and Westfall <a href="#ref-R-multcomp">2017</a>)</span>) to easily get the required comparisons from our ANOVA model. Unfortunately, its code format is a little complicated – but there are just two places to modify the code, by including the model name and after <code>mcp</code> (stands for <em>multiple comparisons</em>) in the <code>linfct</code> option, you need to include the explanatory variable name as <code>VARIABLENAME=&quot;Tukey&quot;</code>. The last part is to get the Tukey HSD multiple comparisons run on our explanatory variable. Once we obtain the intervals, we can use them to test <span class="math inline">\(H_0: \mu_j = \mu_{j&#39;} \text{ vs } H_A: \mu_j \ne \mu_{j&#39;}\)</span> by assessing whether 0 is in the confidence interval for each pair. If 0 is in the interval, then there is no evidence of a difference for that pair. If 0 is not in the interval, then we reject <span class="math inline">\(H_0\)</span> and have evidence <em>at the specified family-wise significance level</em> of a difference for that pair. You will see a switch to using the word “detection” to describe rejected null hypotheses of no difference as it can help to compactly write up these results. The following code provides the numerical and graphical<a href="#fn52" class="footnoteRef" id="fnref52"><sup>52</sup></a> results of applying Tukey’s HSD to the linear model for the Guinea Pig data:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(multcomp)
Tm2 &lt;-<span class="st"> </span><span class="kw">glht</span>(m2, <span class="dt">linfct =</span> <span class="kw">mcp</span>(<span class="dt">Treat =</span> <span class="st">&quot;Tukey&quot;</span>))
<span class="kw">confint</span>(Tm2)</code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = len ~ Treat, data = ToothGrowth)
## 
## Quantile = 2.9545
## 95% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                      Estimate lwr      upr     
## VC.0.5 - OJ.0.5 == 0  -5.2500 -10.0482  -0.4518
## OJ.1 - OJ.0.5 == 0     9.4700   4.6718  14.2682
## VC.1 - OJ.0.5 == 0     3.5400  -1.2582   8.3382
## OJ.2 - OJ.0.5 == 0    12.8300   8.0318  17.6282
## VC.2 - OJ.0.5 == 0    12.9100   8.1118  17.7082
## OJ.1 - VC.0.5 == 0    14.7200   9.9218  19.5182
## VC.1 - VC.0.5 == 0     8.7900   3.9918  13.5882
## OJ.2 - VC.0.5 == 0    18.0800  13.2818  22.8782
## VC.2 - VC.0.5 == 0    18.1600  13.3618  22.9582
## VC.1 - OJ.1 == 0      -5.9300 -10.7282  -1.1318
## OJ.2 - OJ.1 == 0       3.3600  -1.4382   8.1582
## VC.2 - OJ.1 == 0       3.4400  -1.3582   8.2382
## OJ.2 - VC.1 == 0       9.2900   4.4918  14.0882
## VC.2 - VC.1 == 0       9.3700   4.5718  14.1682
## VC.2 - OJ.2 == 0       0.0800  -4.7182   4.8782</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co">#Makes room on the plot for the group names</span>
<span class="kw">plot</span>(Tm2)</code></pre></div>
<div class="figure"><span id="fig:Figure3-19"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-19-1.png" alt="Graphical display of pair-wise comparisons from Tukey’s HSD for the Guinea Pig data. Any confidence intervals that do not contain 0 provide evidence of a difference in the pair of groups." width="960" />
<p class="caption">
Figure 3.19: Graphical display of pair-wise comparisons from Tukey’s HSD for the Guinea Pig data. Any confidence intervals that do not contain 0 provide evidence of a difference in the pair of groups.
</p>
</div>
<p>Figure <a href="chapter3.html#fig:Figure3-19">3.19</a> contains confidence intervals for the difference in the means for all 15 pairs of groups. For example, the first row in the plot contains the confidence interval for comparing VC.0.5 and OJ.0.5 (VC.0.5 <strong>minus</strong> OJ.0.5). In the numerical output, you can find that this 95% family-wise confidence interval goes from -10.05 to -0.45 microns (<code>lwr</code> and <code>upr</code> in the numerical output provide the CI endpoints). This interval does not contain 0 since its upper end point is -0.45 microns and so we can now say that there is evidence that OJ and VC have different true mean growth rates at the 0.5 mg dosage level. We can go further and say that we are 95% confident that the difference in the true mean tooth growth between VC.0.5 and OJ.0.5 (VC.0.5-OJ.0.5) is between -10.05 and -0.45 microns, after adjusting for comparing all the pairs of groups. But there are fourteen more similar intervals…</p>
<p>If you put all these pair-wise tests together, you can generate an overall interpretation of Tukey’s HSD results that discusses sets of groups that are not detectably different from one another and those groups that were distinguished from other sets of groups. To do this, start with listing out the groups that are not detectably different (CIs contain 0), which, here, only occurs for four of the pairs. The CIs that contain 0 are for the pairs VC.1 and OJ.0.5, OJ.2 and OJ.1, VC.2 and OJ.1, and, finally, VC.2 and OJ.2. So VC.2, OJ.1, and OJ.2 are all not detectably different from each other and VC.1 and OJ.0.5 are also not detectably different. If you look carefully, VC.0.5 is detected as different from every other group. So there are basically three sets of groups that can be grouped together as “similar”: VC.2, OJ.1, and OJ.2; VC.1 and OJ.0.5; and VC.0.5. Sometimes groups overlap with some levels not being detectably different from other levels that belong to different groups and the story is not as clear as it is in this case. An example of this sort of overlap is seen in the next section.</p>
<p>There is a method that many researchers use to more efficiently generate and report these sorts of results that is called a <strong><em>compact letter display</em></strong> (CLD, <span class="citation">Piepho (<a href="#ref-Piepho2004">2004</a>)</span>)<a href="#fn53" class="footnoteRef" id="fnref53"><sup>53</sup></a>. The <code>cld</code> function can be applied to the results from <code>glht</code> to generate the CLD that we can use to provide a “simple” summary of the sets of groups. In this discussion, we define a <strong>set as a union of different groups that can contain one or more members</strong> and the member of these groups are the different treatment levels.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cld</span>(Tm2)</code></pre></div>
<pre><code>## OJ.0.5 VC.0.5   OJ.1   VC.1   OJ.2   VC.2 
##    &quot;b&quot;    &quot;a&quot;    &quot;c&quot;    &quot;b&quot;    &quot;c&quot;    &quot;c&quot;</code></pre>
<p>Groups with the same letter are not detectably different (are in the same set) and groups that are detectably different get different letters (are in different sets). Groups can have more than one letter to reflect “overlap” between the sets of groups and sometimes a set of groups contains only a single treatment level (VC.0.5 is a set of size 1). Note that if the groups have the same letter, this does not mean they are the same, just that there is <strong>no evidence of a difference for that pair</strong>. If we consider the previous output for the CLD, the “a” set contains VC.0.5, the “b” set contains OJ.0.5 and VC.1, and the “c” set contains OJ.1, OJ.2, and VC.2. These are exactly the groups of treatment levels that we obtained by going through all fifteen pairwise results.</p>
<p>One benefit of this work is that the CLD letters can be added to a plot (such as the beanplot) to help fully report the results and understand the sorts of differences Tukey’s HSD detected. The lines with <code>text</code> in them are involved in placing text on the figure but are something you could do in image editing software just as easily. Figure <a href="chapter3.html#fig:Figure3-20">3.20</a> enhances the discussion by showing that the “<b><font color='blue'>a</font></b>” group with VC.0.5 had the lowest average tooth growth, the “<b><font color='red'>b</font></b>” group had intermediate tooth growth for treatments OJ.0.5 and VC.1, and the highest growth rates came from OJ.1, OJ.2, and VC.2. Even though VC.2 had the highest average growth rate, we are not able to prove that its true mean is any higher than the other groups labeled with “<b><font color='green'>c</font></b>”. Hopefully the ease of getting to the story of the Tukey’s HSD results from a plot like this explains why it is common to report results using these methods instead of reporting 15 confidence intervals for all the pair-wise differences.</p>

<div class="figure"><span id="fig:Figure3-20"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-20-1.png" alt="Beanplot of odontoblast growth by group with Tukey’s HSD compact letter display." width="960" />
<p class="caption">
Figure 3.20: Beanplot of odontoblast growth by group with Tukey’s HSD compact letter display.
</p>
</div>
<p>There are just a couple of other details to mention on this set of methods. First, note that we interpret the set of confidence intervals simultaneously: We are 95% confident that <strong>ALL</strong> the intervals contain the respective differences in the true means (this is a <strong><em>family-wise interpretation</em></strong>). These intervals are adjusted from our regular 2 sample <span class="math inline">\(t\)</span> intervals from Chapter <a href="chapter2.html#chapter2">2</a> to allow this stronger interpretation. Specifically, they are wider. Second, if sample sizes are unequal in the groups, Tukey’s HSD is conservative and provides a family-wise error rate that is lower than the <em>nominal</em> (or specified) level. In other words, it fails less often than expected and the intervals provided are a little wider than needed, containing all the pairwise differences at higher than the nominal confidence level of (typically) 95%. Third, this is a parametric approach and violations of normality and constant variance will push the method in the other direction, potentially making the technique dangerously liberal. Nonparametric approaches to this problem are also possible, but will not be considered here.</p>
</div>
<div id="section3-7" class="section level2">
<h2><span class="header-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</h2>
<p>In our previous work with the prisoner rating data, the overall ANOVA test provided only marginal evidence of some difference in the true means across the three groups with a p-value=0.067. Tukey’s HSD does not require you to find a small p-value from your overall <span class="math inline">\(F\)</span>-test to employ the methods but if you apply it to situations with p-values larger than your <em>a priori</em> significance level, you are unlikely to find any pairs that are detected as being different. Some statisticians suggest that you shouldn’t employ follow-up tests such as Tukey’s HSD when there is not sufficient evidence to reject the overall null hypothesis and would be able to reasonably criticize the following results. But for the sake of completeness, we can find the pair-wise comparison results at our typical 95% family-wise confidence level in this situation, with the three confidence intervals displayed in Figure <a href="chapter3.html#fig:Figure3-21">3.21</a>.</p>

<div class="figure"><span id="fig:Figure3-21"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-21-1.png" alt="Tukey’s HSD confidence interval results at the 95% family-wise confidence level for the Mock Jury linear model." width="480" />
<p class="caption">
Figure 3.21: Tukey’s HSD confidence interval results at the 95% family-wise confidence level for the Mock Jury linear model.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lm2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury)
<span class="kw">require</span>(multcomp)
Tm2 &lt;-<span class="st"> </span><span class="kw">glht</span>(lm2, <span class="dt">linfct =</span> <span class="kw">mcp</span>(<span class="dt">Attr =</span> <span class="st">&quot;Tukey&quot;</span>))</code></pre></div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(Tm2)</code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = Years ~ Attr, data = MockJury)
## 
## Quantile = 2.3752
## 95% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                               Estimate lwr     upr    
## Average - Beautiful == 0      -0.3596  -2.2970  1.5777
## Unattractive - Beautiful == 0  1.4775  -0.4731  3.4281
## Unattractive - Average == 0    1.8371  -0.1259  3.8002</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cld</span>(Tm2)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##          &quot;a&quot;          &quot;a&quot;          &quot;a&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">2.5</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co">#Makes room on the plot for the group names</span>
<span class="kw">plot</span>(Tm2)</code></pre></div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(Tm2, <span class="dt">level=</span><span class="fl">0.9</span>)</code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = Years ~ Attr, data = MockJury)
## 
## Quantile = 2.0739
## 90% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                               Estimate lwr     upr    
## Average - Beautiful == 0      -0.3596  -2.0513  1.3320
## Unattractive - Beautiful == 0  1.4775  -0.2257  3.1806
## Unattractive - Average == 0    1.8371   0.1231  3.5512</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cld</span>(Tm2, <span class="dt">level=</span><span class="fl">0.1</span>)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##         &quot;ab&quot;          &quot;a&quot;          &quot;b&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">2.5</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co">#Makes room on the plot for the group names</span>
<span class="kw">plot</span>(<span class="kw">confint</span>(Tm2, <span class="dt">level=</span>.<span class="dv">9</span>))</code></pre></div>
<div class="figure"><span id="fig:Figure3-22"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-22-1.png" alt="Tukey’s HSD 90% family-wise confidence intervals for the Mock Jury linear model." width="480" />
<p class="caption">
Figure 3.22: Tukey’s HSD 90% family-wise confidence intervals for the Mock Jury linear model.
</p>
</div>
<p>At the family-wise 5% significance level, there are no pairs that are detectably different – they all get the same letter of “a”. Now we will produce results for the reader that thought a 10% significance was suitable for this application before seeing any of the results. We just need to change the confidence level or significance level that the CIs or tests are produced with inside the functions. For the <code>confint</code> function, the <code>level</code> option is the confidence level and for the <code>cld</code>, it is the family-wise significance level. Note that 90% confidence corresponds to a 10% significance level.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(Tm2, <span class="dt">level=</span><span class="fl">0.9</span>)</code></pre></div>
<pre><code>## 
##   Simultaneous Confidence Intervals
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = Years ~ Attr, data = MockJury)
## 
## Quantile = 2.0738
## 90% family-wise confidence level
##  
## 
## Linear Hypotheses:
##                               Estimate lwr     upr    
## Average - Beautiful == 0      -0.3596  -2.0511  1.3318
## Unattractive - Beautiful == 0  1.4775  -0.2255  3.1805
## Unattractive - Average == 0    1.8371   0.1232  3.5510</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cld</span>(Tm2, <span class="dt">level=</span><span class="fl">0.1</span>)</code></pre></div>
<pre><code>##    Beautiful      Average Unattractive 
##         &quot;ab&quot;          &quot;a&quot;          &quot;b&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="fl">2.5</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co">#Makes room on the plot for the group names</span>
<span class="kw">plot</span>(<span class="kw">confint</span>(Tm2, <span class="dt">level=</span>.<span class="dv">9</span>))</code></pre></div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">beanplot</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury, <span class="dt">log=</span><span class="st">&quot;&quot;</span>, <span class="dt">col=</span><span class="st">&quot;white&quot;</span>, <span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="dv">1</span>), <span class="kw">c</span>(<span class="fl">5.3</span>),<span class="st">&quot;ab&quot;</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">cex=</span><span class="fl">1.5</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="dv">2</span>), <span class="kw">c</span>(<span class="fl">5.1</span>),<span class="st">&quot;a&quot;</span>, <span class="dt">col=</span><span class="st">&quot;green&quot;</span>, <span class="dt">cex=</span><span class="fl">1.5</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="dv">3</span>), <span class="kw">c</span>(<span class="fl">6.8</span>),<span class="st">&quot;b&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">cex=</span><span class="fl">1.5</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure3-23"></span>
<img src="03-oneWayAnova_files/figure-html/Figure3-23-1.png" alt="Beanplot of sentences with compact letter display results from 10% family-wise significance level Tukey’s HSD. Average and Unattractive picture groups are detected as being different and are displayed as belonging to different groups. Beautiful picture responses are not detected as different from the other two groups." width="480" />
<p class="caption">
Figure 3.23: Beanplot of sentences with compact letter display results from 10% family-wise significance level Tukey’s HSD. <em>Average</em> and <em>Unattractive</em> picture groups are detected as being different and are displayed as belonging to different groups. <em>Beautiful</em> picture responses are not detected as different from the other two groups.
</p>
</div>
<p>With family-wise 10% significance and 90% confidence levels, the <em>Unattractive</em> and <em>Average</em> picture groups are detected as being different but the <em>Average</em> group is not detected as different from <em>Beautiful</em> and <em>Beautiful</em> is not detected to be different from <em>Unattractive</em>. This leaves the “overlap” of groups across the sets of groups that was noted earlier. The <em>Beautiful</em> level is not detected as being dissimilar from levels in two different sets and so gets two different letters.</p>
<p>The beanplot (Figure <a href="chapter3.html#fig:Figure3-23">3.23</a>) helps to clarify some of the reasons for this set of results. The detection of a difference between <em>Average</em> and <em>Unattractive</em> just barely occurs and the mean for <em>Beautiful</em> is between the other two so it ends up not being detectably different from either one. This sort of overlap is actually a fairly common occurrence in these sorts of situations so be prepared a mixed set of letters for some levels.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mai=</span><span class="kw">c</span>(<span class="fl">0.5</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>))
<span class="kw">beanplot</span>(Years<span class="op">~</span>Attr, <span class="dt">data=</span>MockJury, <span class="dt">log=</span><span class="st">&quot;&quot;</span>, <span class="dt">col=</span><span class="st">&quot;white&quot;</span>, <span class="dt">method=</span><span class="st">&quot;jitter&quot;</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="dv">1</span>), <span class="kw">c</span>(<span class="fl">5.3</span>),<span class="st">&quot;ab&quot;</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">cex=</span><span class="fl">1.5</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="dv">2</span>), <span class="kw">c</span>(<span class="fl">5.1</span>),<span class="st">&quot;a&quot;</span>, <span class="dt">col=</span><span class="st">&quot;green&quot;</span>, <span class="dt">cex=</span><span class="fl">1.5</span>)
<span class="kw">text</span>(<span class="kw">c</span>(<span class="dv">3</span>), <span class="kw">c</span>(<span class="fl">6.8</span>),<span class="st">&quot;b&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">cex=</span><span class="fl">1.5</span>)</code></pre></div>
</div>
<div id="section3-8" class="section level2">
<h2><span class="header-section-number">3.8</span> Chapter summary</h2>
<p>In this chapter, we explored methods for comparing a quantitative response across <span class="math inline">\(J\)</span> groups (<span class="math inline">\(J \ge 2\)</span>), with what is called the One-Way ANOVA procedure. The initial test is based on assessing evidence against a null hypothesis of no difference in the true means for the <span class="math inline">\(J\)</span> groups. There are two different methods for estimating these One-Way ANOVA models: the cell-means model and the reference-coded versions of the model. There are times when either model will be preferred, but for the rest of the text, the reference coding is used (sorry!). The ANOVA <span class="math inline">\(F\)</span>-statistic, often presented with underlying information in the ANOVA table, provides a method of assessing evidence against the null hypothesis either using permutations or via the <span class="math inline">\(F\)</span>-distribution. Pair-wise comparisons using Tukey’s HSD provide a method for comparing all the groups and are a nice complement to the overall ANOVA results. A compact letter display was shown that enhanced the interpretation of Tukey’s HSD result.</p>
<p>In the guinea pig example, we are left with some lingering questions based on these results. It appears that the effect of <em>dosage</em> changes as a function of the <em>delivery method</em> (OJ, VC) because the size of the differences between OJ and VC change for different dosages. These methods can’t directly assess the question of whether the effect of delivery method is the same or not across the different dosages. In Chapter <a href="chapter4.html#chapter4">4</a>, the two variables, <em>Dosage</em> and <em>Delivery method</em> are modeled as two separate variables so we can consider their effects both separately and together. This allows more refined hypotheses, such as <em>Is the effect of delivery method the same for all dosages?</em>, to be tested. This will introduce new models and methods for analyzing data where there are two factors as explanatory variables in a model for a quantitative response variable in what is called the Two-Way ANOVA.</p>
</div>
<div id="section3-9" class="section level2">
<h2><span class="header-section-number">3.9</span> Summary of important R code</h2>
<p>The main components of R code used in this chapter follow with components to modify in lighter and/or ALL CAPS text, remembering that any R packages mentioned need to be installed and loaded for this code to have a chance of working:</p>
<ul>
<li><p><strong><font color='red'>MODELNAME</font> &lt;- lm(<font color='red'>Y</font>~<font color='red'>X</font>, data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li><p>Probably the most frequently used command in R.</p></li>
<li><p>Here it is used to fit the reference-coded One-Way ANOVA model with Y as the response variable and X as the grouping variable, storing the estimated model object in MODELNAME.</p></li>
</ul></li>
<li><p><strong><font color='red'>MODELNAME</font> &lt;- lm(<font color='red'>Y</font>~<font color='red'>X</font>-1, data=<font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li>Fits the cell means version of the One-Way ANOVA model.</li>
</ul></li>
<li><p><strong>summary(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li>Generates model summary information including the estimated model coefficients, SEs, t-tests, and p-values.</li>
</ul></li>
<li><p><strong>anova(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li><p>Generates the ANOVA table but <strong>must only be run on the reference-coded version of the model</strong>.</p></li>
<li><p>Results are incorrect if run on the cell-means model since the reduced model under the null is that the mean of all the observations is 0!</p></li>
</ul></li>
<li><p><strong>pf(<font color='red'>FSTATISTIC</font>, df1=<font color='red'>NUMDF</font>, df2=<font color='red'>DENOMDF</font>, lower.tail=F)</strong></p>
<ul>
<li>Finds the p-value for an observed <span class="math inline">\(F\)</span>-statistic with NUMDF and DENOMDF degrees of freedom.</li>
</ul></li>
<li><p><strong>par(mfrow=c(2,2)); plot(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li>Generates four diagnostic plots including the Residuals vs Fitted and Normal Q-Q plot.</li>
</ul></li>
<li><p><strong>plot(allEffects(<font color='red'>MODELNAME</font>))</strong></p>
<ul>
<li><p>Requires the <code>effects</code> package be loaded.</p></li>
<li><p>Plots the estimated model component.</p></li>
</ul></li>
<li><p><strong>Tm2 &lt;- glht(<font color='red'>MODELNAME</font>, linfct=mcp(<font color='red'>X</font>=“Tukey”)); confint(Tm2); plot(Tm2); cld(Tm2)</strong></p>
<ul>
<li><p>Requires the <code>multcomp</code> package to be installed and loaded.</p></li>
<li><p>Can only be run on the reference-coded version of the model.</p></li>
<li><p>Generates the text output and plot for Tukey’s HSD as well as the compact letter display.</p></li>
</ul></li>
</ul>
</div>
<div id="section3-10" class="section level2">
<h2><span class="header-section-number">3.10</span> Practice problems</h2>
<p>For these practice problems, you will work with the cholesterol data set from the <code>multcomp</code> package that was used to generate the Tukey’s HSD results. To load the data set and learn more about the study, use the following code:</p>
<pre><code>require(multcomp)
data(cholesterol)
require(tibble)
cholesterol &lt;- as.tibble(cholesterol)
help(cholesterol)</code></pre>
<p>3.1. Graphically explore the differences in the changes in Cholesterol levels for the five levels using boxplots and beanplots.</p>
<p>3.2. Is the design balanced?</p>
<p>3.3. Complete all 6+ steps of the hypothesis test using the parametric <span class="math inline">\(F\)</span>-test, reporting the ANOVA table and the distribution of the test statistic under the null.</p>
<p>3.4. Discuss the scope of inference using the information that the treatment levels were randomly assigned to volunteers in the study.</p>
<p>3.5. Generate the permutation distribution and find the p-value. Compare the parametric p-value to the permutation test results.</p>
<p>3.6. Perform Tukey’s HSD on the data set. Discuss the results – which pairs were detected as different and which were not? Bigger reductions in cholesterol are good, so are there any levels you would recommend or that might provide similar reductions?</p>
<p>3.7. Find and interpret the CLD and compare that to your interpretation of results from 3.6.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-effects">
<p>Fox, John, Sanford Weisberg, Michael Friendly, and Jangman Hong. 2018. <em>Effects: Effect Displays for Linear, Generalized Linear, and Other Models</em>. <a href="https://CRAN.R-project.org/package=effects" class="uri">https://CRAN.R-project.org/package=effects</a>.</p>
</div>
<div id="ref-Crampton1947">
<p>Crampton, E. 1947. “The Growth of the Odontoblast of the Incisor Teeth as a Criterion of Vitamin c Intake of the Guinea Pig.” <em>The Journal of Nutrition</em> 33 (5): 491–504. <a href="http://jn.nutrition.org/content/33/5/491.full.pdf" class="uri">http://jn.nutrition.org/content/33/5/491.full.pdf</a>.</p>
</div>
<div id="ref-Hothorn2008">
<p>Hothorn, Torsten, Frank Bretz, and Peter Westfall. 2008. “Simultaneous Inference in General Parametric Models.” <em>Biometrical Journal</em> 50 (3): 346–63.</p>
</div>
<div id="ref-R-multcomp">
<p>Hothorn, Torsten, Frank Bretz, and Peter Westfall. 2017. <em>Multcomp: Simultaneous Inference in General Parametric Models</em>. <a href="https://CRAN.R-project.org/package=multcomp" class="uri">https://CRAN.R-project.org/package=multcomp</a>.</p>
</div>
<div id="ref-Piepho2004">
<p>Piepho, Hans-Peter. 2004. “An Algorithm for a Letter-Based Representation of All-Pairwise Comparisons.” <em>Journal of Computational and Graphical Statistics</em> 13 (2): 456–66.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="37">
<li id="fn37"><p>In Chapter <a href="chapter4.html#chapter4">4</a>, methods are discussed for when there are two categorical explanatory variables that is called the Two-Way ANOVA and related ANOVA tests are used in Chapter <a href="chapter8.html#chapter8">8</a> for working with extensions of these models.<a href="chapter3.html#fnref37">↩</a></p></li>
<li id="fn38"><p>If you look closely in the code for the rest of the book, any model for a quantitative response will use this function, suggesting a common thread in the most commonly used statistical models.<a href="chapter3.html#fnref38">↩</a></p></li>
<li id="fn39"><p>Suppose we were doing environmental monitoring and were studying asbestos levels in soils. We might be hoping that the mean-only model were reasonable to use if the groups being compared were in remediated areas and in areas known to have never been contaminated.<a href="chapter3.html#fnref39">↩</a></p></li>
<li id="fn40"><p>Make sure you can work from left to right and up and down to fill in the ANOVA table given just the necessary information to determine the other components – there is always a question like this on the exam…<a href="chapter3.html#fnref40">↩</a></p></li>
<li id="fn41"><p>This fits with a critique of p-value usage called p-hacking or publication bias – where researchers search across many results and only report their biggest differences. This biases the results to detecting results more than they should be and then when other researchers try to repeat the same studies, they fail to find similar results.<a href="chapter3.html#fnref41">↩</a></p></li>
<li id="fn42"><p>We have been using this function quite a bit to make multi-panel graphs but did not show you that line of code. But you need to use this command for linear model diagnostics or you won’t get the plots we want from the model. And you really just need <code>plot(lm2)</code> but the <code>pch=16</code> option makes it easier to see some of the points in the plots.<a href="chapter3.html#fnref42">↩</a></p></li>
<li id="fn43"><p>Along with multiple names, there is variation of what is plotted on the x and y axes and the scaling of the values plotted, increasing the challenge of interpreting QQ-plots. We are consistent about the x and y axis choices throughout this book but different functions that make these plots in R do switch the axes.<a href="chapter3.html#fnref43">↩</a></p></li>
<li id="fn44"><p>Here this means re-scaled so that they should have similar scaling to a standard normal with mean 0 and standard deviation 1. This does not change the shape of the distribution but can make outlier identification simpler – having a standardized residual more extreme than 5 or -5 would suggest a deviation from normality since we rarely see values that many standard deviations from the mean in a normal distribution. But mainly focus on the shape of the pattern in the QQ-plot.<a href="chapter3.html#fnref44">↩</a></p></li>
<li id="fn45"><p>A resistant procedure is one that is not severely impacted by a particular violation of an assumption. For example, the median is resistant to the impact of an outlier. But the mean is not a resistant measure as changing the value of a single point changes the mean.<a href="chapter3.html#fnref45">↩</a></p></li>
<li id="fn46"><p>A violation of the independence assumption could have easily been created if they measured cells in two locations on each guinea pig or took measurements over time on each subject.<a href="chapter3.html#fnref46">↩</a></p></li>
<li id="fn47"><p>Note that to see all the group labels in the plot when making the figure, you have to widen the plot window before copying the figure out of R. You can resize the plot window using the small vertical and horizontal “=” signs in the grey bars that separate the different panels in RStudio.<a href="chapter3.html#fnref47">↩</a></p></li>
<li id="fn48"><p>In working with researchers on hundreds of projects, our experience has been that we often require many conversations to discover all the potential sources of issues in data sets, especially related to assessing independence of the observations.<a href="chapter3.html#fnref48">↩</a></p></li>
<li id="fn49"><p>When this procedure is used with unequal group sizes it is also sometimes called Tukey-Kramer’s method.<a href="chapter3.html#fnref49">↩</a></p></li>
<li id="fn50"><p>We often use “spurious” to describe falsely rejected null hypotheses, but they are also called false detections.<a href="chapter3.html#fnref50">↩</a></p></li>
<li id="fn51"><p>Some researchers are now collecting multiple data sets to use in a single study and using one data set to identify interesting results and then using a validation or test data set that they withheld from initial analysis to try to verify that the first results are also present in that second data set. This also has problems but the only way to develop an understanding of a process is to look across a suite of studies and learn from that accumulation of evidence.<a href="chapter3.html#fnref51">↩</a></p></li>
<li id="fn52"><p>The plot of results usually contains all the labels of groups but if the labels are long or there many groups, sometimes the row labels are hard to see even with re-sizing the plot to make it taller in RStudio. The numerical output is useful as a guide to help you read the plot.<a href="chapter3.html#fnref52">↩</a></p></li>
<li id="fn53"><p>Note that this method is implemented slightly differently than we explain here in some software packages so if you see this in a journal article, read the discussion carefully.<a href="chapter3.html#fnref53">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter4.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["Greenwood_Book.pdf", "Greenwood_Book.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
