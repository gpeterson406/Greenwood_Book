<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Intermediate Statistics with R">

<title>Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Beanplots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Chapter summary</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Summary of important R code</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient (Optional section)</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomizing inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="9-6-section9-6.html#section9-6"><span class="toc-section-number">9.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section4-3" class="section level2">
<h2><span class="header-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</h2>
<p>To assess interactions with two variables, we need to fully describe models for the additive and interaction scenarios and then develop a method for assessing evidence of the need for different aspects of the models. First, we need to define the notation for these models:</p>
<ul>
<li><p><span class="math inline">\(y_{ijk}\)</span> is the <span class="math inline">\(i^{th}\)</span> response from the group for level <span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B</p>
<ul>
<li><p><span class="math inline">\(j=1,\ldots,J\)</span>     <span class="math inline">\(J\)</span> is the number of levels of A</p></li>
<li><p><span class="math inline">\(k=1,\ldots,K\)</span>     <span class="math inline">\(K\)</span> is the number of levels of B</p></li>
<li><p><span class="math inline">\(i=1,\ldots,n_{jk}\)</span>     <span class="math inline">\(n_{jk}\)</span> is the sample size for level <span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B</p></li>
<li><p><span class="math inline">\(N=\Sigma\Sigma n_{jk}\)</span> is the total sample size (sum of the number of observations across all <span class="math inline">\(JK\)</span> groups)</p></li>
</ul></li>
</ul>
<p>We need to extend our previous discussion of reference-coded models to develop a Two-Way ANOVA model. We start with the <strong><em>Two-Way ANOVA interaction model</em></strong>: </p>
<p><span class="math display">\[y_{ijk} = \alpha + \tau_j + \gamma_k + \omega_{jk} + \varepsilon_{ijk},\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is the baseline group mean (for level 1 of A <strong>and</strong> level 1 of B), <span class="math inline">\(\tau_j\)</span> is the deviation for the <strong><em>main effect</em></strong> of A from the baseline for levels <span class="math inline">\(2,\ldots,J\)</span>, <span class="math inline">\(\gamma_k\)</span> (gamma <span class="math inline">\(k\)</span>) is the deviation for the main effect of B from the baseline for levels <span class="math inline">\(2,\ldots,K\)</span>, and <span class="math inline">\(\omega_{jk}\)</span> (omega <span class="math inline">\(jk\)</span>) is the adjustment for the <strong><em>interaction effect</em></strong> for level <span class="math inline">\(j\)</span> of factor A and level <span class="math inline">\(k\)</span> of factor B for <span class="math inline">\(j=1,\ldots,J\)</span> and <span class="math inline">\(k=1,\ldots,K\)</span>. In this model, <span class="math inline">\(\tau_1\)</span>, <span class="math inline">\(\gamma_1\)</span>, and <span class="math inline">\(\omega_{11}\)</span> are all fixed at 0. As in Chapter <a href="3-chapter3.html#chapter3"><strong>??</strong></a>, R will choose the baseline categories alphabetically but now it is choosing a baseline for both variables and so our detective work will be doubled to sort this out.</p>
<p>If the interaction term is not important, based on the interaction test presented below, the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> can be dropped from the model and we get a model that corresponds to Scenario 4 above. Scenario 4 is where there are two main effects but no interaction between them. The <strong><em>additive Two-Way model</em></strong> is </p>
<p><span class="math display">\[y_{ijk} = \alpha + \tau_j + \gamma_k + \varepsilon_{ijk},\]</span></p>
<p>where each component is defined as in the interaction model. The difference between the interaction and additive models is setting all the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> to 0 that are present in the interaction model. When we set parameters to 0 in models it removes them from the model. Setting parameters to 0 is how we will develop our hypotheses to test for an interaction, by testing whether there is evidence enough to reject that all <span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p>
<p>The interaction test hypotheses are</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No interaction between A and B on response in population <span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\omega_{jk}\text{&#39;s}=0\)</span>.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Interaction between A and B on response in population <span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\omega_{jk}\ne 0\)</span>.</p></li>
</ul>
<p>To perform this test, a new ANOVA <span class="math inline">\(F\)</span>-test is required (presented below) but there are also hypotheses relating to the main effects of A (<span class="math inline">\(\tau_j\text{&#39;s}\)</span>) and B (<span class="math inline">\(\gamma_k\text{&#39;s}\)</span>).   If evidence is found to reject the null hypothesis that no interaction is present, then it is dangerous to ignore it and test for the main effects because important main effects can be masked by interactions (examples later). It is important to note that, by definition, <strong>both variables matter if an interaction is found to be important</strong> so the main effect tests may not be very interesting. If the interaction is found to be important based on the test and retained in the model, you should focus on the interaction model (also called the <strong><em>full model</em></strong>) in order to understand and describe the form of the interaction among the variables.  </p>
<p>If the interaction test does not return a small p-value and you decide that you do not have evidence to suggest that it is needed, it can be dropped from the model. In this situation, we would re-fit the model and focus on the results provided by the additive model – performing tests for the two additive main effects.  For the first, but not last time, we encounter a model with more than one variable and more than one test of potential interest. In models with multiple variables at similar levels (here both are main effects), we are interested in the results for each variable given that the other variable is in the model. In many situations, including more than one variable in a model changes the results for the other variable even if those variables do not interact. The reason for this is more clear in Chapter <a href="8-chapter8.html#chapter8"><strong>??</strong></a> and really only matters here if we have unbalanced designs, but we need to start adding a short modifier to our discussions of main effects – they are the results <em>conditional on</em> or <em>adjusting for</em> or, simply, <em>given</em>, the other variable(s) in the model. Specifically, the hypotheses for the two main effects are:</p>
<ul>
<li><p>Main effect test for A: </p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No differences in means across levels of A in population, given B in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\tau_j\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means across levels A in population, given B in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\tau_j \ne 0\)</span>, in additive model.</p></li>
</ul></li>
<li><p>Main effect test for B:</p>
<ul>
<li><p><span class="math inline">\(H_0\)</span>: No differences in means across levels of B in population, given A in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> All <span class="math inline">\(\gamma_k\text{&#39;s} = 0\)</span> in additive model.</p></li>
<li><p><span class="math inline">\(H_A\)</span>: Some difference in means across levels B in population, given A in the model</p>
<p><span class="math inline">\(\Leftrightarrow\)</span> At least one <span class="math inline">\(\gamma_k \ne 0\)</span>, in additive model.</p></li>
</ul></li>
</ul>
<p>In order to test these effects (interaction in the interaction model and main effects in the additive model), <span class="math inline">\(F\)</span>-tests are developed using Sums of Squares, Mean Squares, and degrees of freedom similar to those in Chapter <a href="3-chapter3.html#chapter3"><strong>??</strong></a>.  We won’t worry about the details of the sums of squares formulas but you should remember the sums of squares decomposition, which still applies<a href="#fn56" class="footnoteRef" id="fnref56"><sup>56</sup></a>.   Table <a href="4-3-section4-3.html#tab:Table4-1">2.6</a> summarizes the ANOVA results you will obtain for the interaction model and Table <a href="4-3-section4-3.html#tab:Table4-2">2.7</a> provides the similar general results for the additive model. As we saw in Chapter <a href="3-chapter3.html#chapter3"><strong>??</strong></a>, the degrees of freedom are the amount of information that is free to vary at a particular level and that rule generally holds here. For example, for factor A with <span class="math inline">\(J\)</span> levels, there are <span class="math inline">\(J-1\)</span> parameters that are free since the baseline is fixed. The residual degrees of freedom for both models are not as easily explained but have a simple formula. Note that the sum of the degrees of freedom from the main effects, (interaction if present), and error need to equal <span class="math inline">\(N-1\)</span>, just like in the One-Way ANOVA table.</p>

<table>
<caption><span id="tab:Table4-1">Table 2.6: </span> Interaction Model ANOVA Table.</caption>
<colgroup>
<col width="18%" />
<col width="19%" />
<col width="22%" />
<col width="24%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Source</strong>    </th>
<th align="left"><strong>DF</strong>     </th>
<th align="left"><strong>SS</strong></th>
<th align="left"><strong>MS</strong></th>
<th align="left"><strong>F-statistics</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/\text{df}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left"><span class="math inline">\(K-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B=\text{SS}_B/\text{df}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B/\text{MS}_E\)</span></td>
</tr>
<tr class="odd">
<td align="left">A:B (interaction)</td>
<td align="left"><span class="math inline">\((J-1)(K-1)\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_{AB}\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_{AB}=\text{SS}_{AB}/\text{df}_{AB}\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_{AB}/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(N-JK\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E=\text{SS}_E/\text{df}_E\)</span></td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left"><b><font
color='red'>Total</font></b></td>
<td align="left"><span class="math inline">\(\color{red}{\mathbf{N-1}}\)</span></td>
<td align="left"><span class="math inline">\(\color{red}{\textbf{SS}_{\textbf{Total}}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>

<table>
<caption><span id="tab:Table4-2">Table 2.7: </span> Additive Model ANOVA Table.</caption>
<colgroup>
<col width="19%" />
<col width="20%" />
<col width="24%" />
<col width="21%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Source</strong>    </th>
<th align="left"><strong>DF</strong>     </th>
<th align="left"><strong>SS</strong></th>
<th align="left"><strong>MS</strong></th>
<th align="left"><strong>F-statistics</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A</td>
<td align="left"><span class="math inline">\(J-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A=\text{SS}_A/\text{df}_A\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_A/\text{MS}_E\)</span></td>
</tr>
<tr class="even">
<td align="left">B</td>
<td align="left"><span class="math inline">\(K-1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B=\text{SS}_B/\text{df}_B\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_B/\text{MS}_E\)</span></td>
</tr>
<tr class="odd">
<td align="left">Error</td>
<td align="left"><span class="math inline">\(N-J-K+1\)</span></td>
<td align="left"><span class="math inline">\(\text{SS}_E\)</span></td>
<td align="left"><span class="math inline">\(\text{MS}_E=\text{SS}_E/\text{df}_E\)</span></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left"><b><font
color='red'>Total</font></b></td>
<td align="left"><span class="math inline">\(\color{red}{\mathbf{N-1}}\)</span></td>
<td align="left"><span class="math inline">\(\color{red}{\textbf{SS}_{\textbf{Total}}}\)</span></td>
<td align="left"></td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>The mean squares are formed by taking the sums of squares (we’ll let R find those for us) and dividing by the <span class="math inline">\(df\)</span> in the row.  The <span class="math inline">\(F\)</span>-ratios are found by taking the mean squares from the row and dividing by the mean squared error (<span class="math inline">\(\text{MS}_E\)</span>). They follow <span class="math inline">\(F\)</span>-distributions with numerator degrees of freedom from the row and denominator degrees of freedom from the Error row (in R output this the <code>Residuals</code> row).   It is possible to develop permutation tests for these methods but some technical issues arise in doing permutation tests for interaction model components so we will not use them here. This means we will have to place even more emphasis on meeting the assumptions since we only have the parametric method available.  </p>
<p>With some basic expectations about the ANOVA tables and <span class="math inline">\(F\)</span>-statistic construction in mind, we can get to actually estimating the models and exploring the results.  The first example involves the fake paper towel data displayed in Figure <a href="4-2-section4-2.html#fig:Figure4-1">2.46</a> and <a href="4-2-section4-2.html#fig:Figure4-2">2.47</a>. It appeared that Scenario 5 was the correct story since the lines were not parallel, but we need to know whether there is evidence to suggest that the interaction is “real” and we get that through the interaction hypothesis test. To fit the interaction model using <code>lm</code>, the general formulation is <code>lm(y~x1*x2, data=...)</code>. The order of the variables doesn’t matter and the most important part of the model, to start with, relates to the interaction of the variables. </p>
<p>The ANOVA table output shows the results for the interaction model obtained by running the <code>anova</code> function on the model called <code>m1</code>.  Specifically, the test that <span class="math inline">\(H_0: \text{ All } \omega_{jk}\text{&#39;s} = 0\)</span> has a test statistic of <span class="math inline">\(F(2,24)=1.92\)</span> (in the output from the row with brands:drops) and a p-value of 0.17. So there is weak evidence against the null hypothesis of no interaction, with a 17% chance we would observe a difference in the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> like we did or more extreme if the <span class="math inline">\(\omega_{jk}\text{&#39;s}\)</span> really were all 0. So it seems that the interaction probably is not needed. Note that for the interaction model components, R presents them with a colon, <code>:</code>, between the variable names. </p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>brand<span class="op">*</span>drops, <span class="dt">data=</span>pt)
<span class="kw">anova</span>(m1)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: responses
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)
## brand        1 4.3322  4.3322 10.5192 0.003458
## drops        2 4.8581  2.4290  5.8981 0.008251
## brand:drops  2 1.5801  0.7901  1.9184 0.168695
## Residuals   24 9.8840  0.4118</code></pre>
<p>It is useful to display the estimates from this model and we can utilize <code>plot(allEffects(MODELNAME))</code> to visualize the results for the terms in our models. If we turn on the options for <code>grid=T</code>, <code>multiline=T</code>, and <code>ci.style=&quot;bars&quot;</code> we will get a more useful version of the basic “effect plot” for Two-Way ANOVA models with interaction. The results of the estimated interaction model are displayed in Figure <a href="4-3-section4-3.html#fig:Figure4-7">2.52</a>, which looks very similar to our previous interaction plot. The only difference is that this comes from model that assumes equal variance and these plots show 95% confidence intervals for the means instead of the 1 standard error used above that was calculated using the variance of the observations at each combination of levels. </p>

<div class="figure"><span id="fig:Figure4-7"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-7-1.png" alt="Plot of estimated results of interaction model for the paper towel performance data." width="576" />
<p class="caption">
Figure 2.52: Plot of estimated results of interaction model for the paper towel performance data.
</p>
</div>
<p>In the absence of evidence to include the interaction, the model should be simplified to the additive model and the interpretation focused on each main effect, conditional on having the other variable in the model. To fit an additive model and not include an interaction, the model formula involves a “+” instead of a “<code>*</code>” between the explanatory variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m2 &lt;-<span class="st"> </span><span class="kw">lm</span>(responses<span class="op">~</span>brand<span class="op">+</span>drops, <span class="dt">data=</span>pt)</code></pre></div>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(m2)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: responses
##           Df  Sum Sq Mean Sq F value   Pr(&gt;F)
## brand      1  4.3322  4.3322  9.8251 0.004236
## drops      2  4.8581  2.4290  5.5089 0.010123
## Residuals 26 11.4641  0.4409</code></pre>
<p>The p-values for the main effects of <code>brand</code> and <code>drops</code> change slightly from the results in the interaction model due to changes in the <span class="math inline">\(\text{MS}_E\)</span> from 0.4118 to 0.4409 (more variability is left over in the simpler model) and the <span class="math inline">\(\text{DF}_{\text{error}}\)</span> that increases from 24 to 26. In both models, the <span class="math inline">\(\text{SS}_{\text{Total}}\)</span> is the same (20.6544). In the interaction model,</p>
<p><span class="math display">\[\begin{array}{rl}
\text{SS}_{\text{Total}} &amp; = \text{SS}_{\text{brand}} + \text{SS}_{\text{drops}}
+ \text{SS}_{\text{brand:drops}} + \text{SS}_{\text{E}}\\
&amp; = 4.3322 + 4.8581 + 1.5801 + 9.8840\\
&amp; = 20.6544.\\
\end{array}\]</span></p>
<p>In the additive model, the variability that was attributed to the interaction term in the interaction model (<span class="math inline">\(\text{SS}_{\text{brand:drops}} = 1.5801\)</span>) is pushed into the <span class="math inline">\(\text{SS}_{\text{E}}\)</span>, which increases from 9.884 to 11.4641. The sums of squares decomposition in the additive model is</p>
<p><span class="math display">\[\begin{array}{rl}
\text{SS}_{\text{Total}} &amp; = \text{SS}_{\text{brand}} + \text{SS}_{\text{drops}}
 + \text{SS}_{\text{E}} \\
&amp; = 4.3322 + 4.8581 + 11.4641 \\
&amp; = 20.6544. \\
\end{array}\]</span></p>
<p>This shows that the sums of squares decomposition applies in these more complicated models as it did in the One-Way ANOVA.  It also shows that if the interaction is removed from the model, that variability is lumped in with the other unexplained variability that goes in the <span class="math inline">\(\text{SS}_{\text{E}}\)</span> in any model.</p>
<p>The fact that the sums of squares decomposition can be applied here is useful, except that there is a small issue with the main effect tests in the ANOVA table results that follow this decomposition when the design is not balanced. It ends up that the tests in a typical ANOVA table are only conditional on the tests higher up in the table. For example, in the additive model ANOVA table, the <code>Brand</code> test is not conditional on the <code>Drops</code> effect, but the <code>Drops</code> effect is conditional on the <code>Brand</code> effect. To fix this issue, we have to use another type of sums of squares, called <strong><em>Type II sums of squares</em></strong>.  They will no longer always follow the rules of the sums of squares decomposition but they will test the desired hypotheses. Specifically, they provide each test conditional on any other terms at the same level of the model and match the hypotheses written out earlier in this section. To get the “correct” ANOVA results, the <code>car</code> (<span class="citation">Fox, Weisberg, and Price (<a href="#ref-R-car">2018</a><a href="#ref-R-car">a</a>)</span>, <span class="citation">Fox and Weisberg (<a href="#ref-Fox2011">2011</a>)</span>) package is required. We use the <code>Anova</code> function on our linear models from here forward to get the “right” tests in our ANOVA tables<a href="#fn57" class="footnoteRef" id="fnref57"><sup>57</sup></a>.  Note how the case-sensitive nature of R code shows up in the use of the capital-A <code>Anova</code> function instead of the <code>anova</code> function used previously. In this case, because the design was balanced, the results are the same using either function. Observational studies rarely generate balanced designs (some designed studies can result in unbalanced designs) so we will generally just use the Type II version of the sums of squares. The <code>Anova</code> results using the Type II sums of squares are slightly more conservative than the results from <code>anova</code>, which are called Type I sums of squares.  The sums of squares decomposition no longer can be applied, but it is a small sacrifice to get each test after adjusting for all other variables<a href="#fn58" class="footnoteRef" id="fnref58"><sup>58</sup></a>. </p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(car)
<span class="kw">Anova</span>(m2)</code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: responses
##            Sum Sq Df F value   Pr(&gt;F)
## brand      4.3322  1  9.8251 0.004236
## drops      4.8581  2  5.5089 0.010123
## Residuals 11.4641 26</code></pre>
<p>The new output switches the columns around and doesn’t show you the mean squares, but gives the most critical parts of the output. Here, there is no change in results because it is balanced design with equal counts of responses in each combination of the two explanatory variables.</p>
<p>The additive model, when appropriate, provides simpler interpretations for each explanatory variable compared to models with interactions because the effect of one variable is the same regardless of the levels of the other variable and vice versa.  There are two tools to aid in understanding the impacts of the two variables in the additive model. First, the model summary provides estimated coefficients with interpretations like those seen in Chapter <a href="3-chapter3.html#chapter3"><strong>??</strong></a> (deviation of group <span class="math inline">\(j\)</span> or <span class="math inline">\(k\)</span> from the baseline group’s mean), except with the additional wording of “controlling for” the other variable added to any of the discussion. Second, the term-plots now show each main effect and how the groups differ with one panel for each of the two explanatory variables in the model. These term-plots are created by holding the other variable constant at one of its levels.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(m2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = responses ~ brand + drops, data = pt)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.4561 -0.4587  0.1297  0.4434  0.9695 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   1.8454     0.2425   7.611 4.45e-08
## brandB2       0.7600     0.2425   3.134  0.00424
## drops20      -0.4680     0.2970  -1.576  0.12715
## drops30      -0.9853     0.2970  -3.318  0.00269
## 
## Residual standard error: 0.664 on 26 degrees of freedom
## Multiple R-squared:  0.445,  Adjusted R-squared:  0.3809 
## F-statistic: 6.948 on 3 and 26 DF,  p-value: 0.001381</code></pre>
<p>In the model summary, the baseline combination estimated in the <code>(Intercept)</code> row is for <code>Brand</code> <em>B1</em> and <code>Drops</code> 10 and estimates the mean failure time as 1.85 seconds for this combination. As before, the group labels that do not show up are the baseline but there are two variables’ baselines to identify. Now the “simple” aspects of the additive model show up. The interpretation of the <code>Brands</code> <em>B2</em> coefficient is as a deviation from the baseline but it applies regardless of the level of <code>Drops</code>. Any difference between <em>B1</em> and <em>B2</em> involves a shift up of 0.76 seconds in the estimated mean failure time. Similarly, going from 10 (baseline) to 20 drops results in a drop in the estimated failure mean of 0.47 seconds and going from 10 to 30 drops results in a drop of almost 1 second in the average time to failure, both estimated changes are the same regardless of the brand of paper towel being considered. Sometimes, especially in observational studies, we use the terminology “controlled for” to remind the reader that the other variable was present in the model<a href="#fn59" class="footnoteRef" id="fnref59"><sup>59</sup></a> and also explained some of the variability in the responses. The term-plots for the additive model (Figure <a href="4-3-section4-3.html#fig:Figure4-8">2.53</a>) help us visualize the impacts of changes brand and changing water levels, holding the other variable constant. The differences in heights in each panel correspond to the coefficients just discussed.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(m2))</code></pre></div>
<div class="figure"><span id="fig:Figure4-8"></span>
<img src="04-twoWayAnova_files/figure-html/Figure4-8-1.png" alt="Term-plots of additive model for paper towel data. Left panel displays results for two brands and right panel for number of drops of water, each after controlling for the other." width="480" />
<p class="caption">
Figure 2.53: Term-plots of additive model for paper towel data. Left panel displays results for two brands and right panel for number of drops of water, each after controlling for the other.
</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-car">
<p>Fox, John, Sanford Weisberg, and Brad Price. 2018a. <em>Car: Companion to Applied Regression</em>. <a href="https://CRAN.R-project.org/package=car" class="uri">https://CRAN.R-project.org/package=car</a>.</p>
</div>
<div id="ref-Fox2011">
<p>Fox, John, and Sanford Weisberg. 2011. <em>An R-Companion to Applied Regression, Second Edition</em>. Thousand Oaks, CA: SAGE Publications. <a href="http://socserv.socsci.mcmaster.ca/jfox/Books/Companion" class="uri">http://socserv.socsci.mcmaster.ca/jfox/Books/Companion</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="56">
<li id="fn56"><p>In the standard ANOVA table, <span class="math inline">\(\text{SS}_A + \text{SS}_B + \text{SS}_{AB} + \text{SS}_E = \text{SS}_{\text{Total}}\)</span>. However, to get the tests we really desire when our designs are not balanced, a slight modification of the SS is used, using what are called Type II sums of squares and this result doesn’t hold in the output you will see for additive models. This is discussed further below.<a href="4-3-section4-3.html#fnref56">↩</a></p></li>
<li id="fn57"><p>The <code>anova</code> results are not wrong, just not what we want.<a href="4-3-section4-3.html#fnref57">↩</a></p></li>
<li id="fn58"><p>Actually, the tests are only conditional on other main effects if Type II Sums of Squares are used for an interaction model.<a href="4-3-section4-3.html#fnref58">↩</a></p></li>
<li id="fn59"><p>In Multiple Linear Regression models in Chapter <a href="8-chapter8.html#chapter8"><strong>??</strong></a>, the reasons for this wording will (hopefully) become clearer.<a href="4-3-section4-3.html#fnref59">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="4-2-section4-2.html"><button class="btn btn-default">Previous</button></a>
<a href="4-4-section4-4.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
