<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="A Second Semester Statistics Course with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A Second Semester Statistics Course with R">

<title>A Second Semester Statistics Course with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Beanplots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Chapter summary</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Summary of important R code</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and table plots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient (Optional section)</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomizing inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="9-6-section9-6.html#section9-6"><span class="toc-section-number">9.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section7-3" class="section level2">
<h2><span class="header-section-number">7.3</span> Bozeman temperature trend</h2>
<p>For a new example, consider the yearly average maximum temperatures in Bozeman, MT. For over 100 years, daily measurements have been taken of the minimum and maximum temperatures at hundreds of weather stations across the US. In early years, this involved manual recording of the temperatures and resetting the thermometer to track the extremes for the following day. More recently, these measures have been replaced by digital temperature recording devices that continue to track this sort of information with much less human effort and, possibly, errors. This sort of information is often aggregated to monthly or yearly averages to be able to see “on average” changes from month-to-month or year-to-year as opposed to the day-to-day variation in the temperature - something that we are all too familiar with in our part of the country.<a href="#fn81" class="footnoteRef" id="fnref81"><sup>81</sup></a> Often the local information is aggregated further to provide regional, hemispheric, or even global average temperatures. Climate change research involves attempting to quantify the changes over time in these sorts of records.</p>
<p>These data were extracted from the National Oceanic and Atmospheric Administration’s National Centers for Environmental Information’s database (<a href="http://www.ncdc.noaa.gov/cdo-web/" class="uri">http://www.ncdc.noaa.gov/cdo-web/</a>) and we will focus on the yearly average of the monthly averages of the daily maximum temperature in Bozeman in degrees F from 1901 to 2014. We can call them yearly average maximum temperatures but note that it was a little more complicated than that to arrive at the response variable we are analyzing.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bozemantemps &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/BozemanMeanMax.csv&quot;</span>)
<span class="kw">summary</span>(bozemantemps)</code></pre></div>
<pre><code>##     meanmax           Year     
##  Min.   :49.75   Min.   :1901  
##  1st Qu.:53.97   1st Qu.:1930  
##  Median :55.43   Median :1959  
##  Mean   :55.34   Mean   :1958  
##  3rd Qu.:57.02   3rd Qu.:1986  
##  Max.   :60.05   Max.   :2014</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(bozemantemps<span class="op">$</span>Year) <span class="co">#Some years are missing (1905, 1906, 1948, 1950,1995)</span></code></pre></div>
<pre><code>## [1] 109</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(car)
<span class="kw">scatterplot</span>(meanmax<span class="op">~</span>Year, <span class="dt">data=</span>bozemantemps, 
            <span class="dt">ylab=</span><span class="st">&quot;Mean Maximum Temperature (degrees F)&quot;</span>, <span class="dt">spread=</span>F,
            <span class="dt">main=</span><span class="st">&quot;Scatterplot of Bozeman Yearly Average Max Temperatures&quot;</span>)</code></pre></div>
<div class="figure"><span id="fig:Figure7-4"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-4-1.png" alt="Scatterplot of average yearly maximum temperatures in Bozeman from 1900 to 2014 with SLR (thin, green) and smoothing (thick, red) lines." width="960" />
<p class="caption">
Figure 2.120: Scatterplot of average yearly maximum temperatures in Bozeman from 1900 to 2014 with SLR (thin, green) and smoothing (thick, red) lines.
</p>
</div>
<p>The scatterplot in Figure <a href="7-3-section7-3.html#fig:Figure7-4">2.120</a> shows the results between 1901 and 2014 based on a sample of <span class="math inline">\(n=109\)</span> years because four years had too many missing months to fairly include in the responses. Missing values occur for many reasons and in this case were likely just machine or human error<a href="#fn82" class="footnoteRef" id="fnref82"><sup>82</sup></a>. These are time series data and in time series analysis we assume that the population of interest for inference is all possible realizations from the underlying process over this time frame even though we only ever get to observe one realization. In terms of climate change research, we would want to (a) assess evidence for a trend over time (hopefully assessing whether any observed trend is clearly different from a result that could have been observed by chance if there really is no change over time in the true process) and (b) quantify the size of the change over time along with the uncertainty in that estimate relative to the underlying true mean change over time. The hypothesis test for the slope answers (a) and the confidence interval for the slope addresses (b). We also should be concerned about problematic (influential) points, changing variance, and potential nonlinearity in the trend over time causing problems for the SLR inferences. The scatterplot suggests that there is a moderate or strong positive linear relationship between <em>temperatures</em> and <em>year</em> with some difference between the smoothing and SLR lines. If the curving is real, it would suggest a slightly curving response over time – the curve is relatively minor relative to the variability in the data set. There also appears to be one potential large outlier in the late 1930s.</p>
<p>We’ll perform all 6+ steps of the hypothesis test for the slope coefficient and add a confidence interval interpretation for this example. First, we need to select our hypotheses (the 2-sided test would be a <strong><em>conservative</em></strong> choice and no one that does climate change research wants to be accused of taking a <strong><em>liberal</em></strong> approach in their analyses<a href="#fn83" class="footnoteRef" id="fnref83"><sup>83</sup></a>) and our test statistic, <span class="math inline">\(t=\frac{b_1}{\text{SE}_{b_1}}\)</span>.</p>
<ol style="list-style-type: decimal">
<li><strong>Hypotheses for the slope coefficient test:</strong></li>
</ol>
<p><span class="math display">\[H_0: \beta_1=0 \text{ vs } H_A: \beta_1 \ne 0\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Validity conditions:</strong></li>
</ol>
<ul>
<li><p><strong>Quantitative variables condition</strong></p>
<ul>
<li>Both <code>Year</code> and yearly average <code>Temperature</code> are quantitative variables so are suitable for an SLR analysis.</li>
</ul></li>
<li><p><strong>Independence of observations</strong></p>
<ul>
<li>There may be a lack of independence among years since a warm year might be followed by another warmer than average year. It would take more sophisticated models to account for this and the standard error on the slope coefficient could either get larger or smaller depending on the type of <strong><em>autocorrelation</em></strong> (correlation between neighboring time points or correlation with oneself at some time lag) present. This creates a caveat on these results but this model is often the first one researchers fit in these situations and often is reasonably correct even in the presence of some autocorrelation.</li>
</ul></li>
</ul>
<p>To assess the remaining conditions, we need to fit the regression model and use the diagnostic plots in Figure <a href="7-3-section7-3.html#fig:Figure7-5">2.121</a> to aid our assessment:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp1 &lt;-<span class="st"> </span><span class="kw">lm</span>(meanmax<span class="op">~</span>Year, <span class="dt">data=</span>bozemantemps)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(temp1, <span class="dt">add.smooth=</span>F)</code></pre></div>
<div class="figure"><span id="fig:Figure7-5"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-5-1.png" alt="Diagnostic plots of the Bozeman yearly temperature simple linear  regression model." width="960" />
<p class="caption">
Figure 2.121: Diagnostic plots of the Bozeman yearly temperature simple linear regression model.
</p>
</div>
<ul>
<li><p><strong>Linearity of relationship</strong></p>
<ul>
<li><p>Examine the Residuals vs Fitted plot:</p>
<ul>
<li>There does not appear to be a clear curve remaining in the residuals so that initial curving in the smoothing line is not clearly showing up in the diagnostics and we should be able to proceed without worrying too much about the slight nonlinearity detected in the initial scatterplot.</li>
</ul></li>
</ul></li>
<li><p><strong>Equal (constant) variance</strong></p>
<ul>
<li>Examining the Residuals vs Fitted and the “Scale-Location” plots provide little to no evidence of changing variance. The variability does decrease slightly in the middle fitted values but those changes are really minor and present no real evidence of changing variability.</li>
</ul></li>
<li><p><strong>Normality of residuals</strong></p>
<ul>
<li>Examining the Normal QQ-plot for violations of the normality assumption shows only one real problem in the outlier from the 32<sup>nd</sup> observation in the data set (1934) which was flagged as a large outlier in the original scatterplot. We should be careful about inferences that assume normality and contain this point in the analysis. We might consider running the analysis with it and without that point to see how much it impacts the results just to be sure it isn’t creating evidence of a trend because of a violation of the normality assumption. The next check reassures us that re-running the model without this point would only result in slightly changing the SEs and not the slopes.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li><p>There are no influential points displayed in the Residuals vs Leverage plot since the Cook’s D contours are not displayed.</p>
<ul>
<li>Note: by default this plot contains a smoothing line that is relatively meaningless, so ignore it if is displayed. We suppressed it using the <code>add.smooth=F</code> option in <code>plot(temp1)</code> but if you forget to do that, just ignore the smoothers in the diagnostic plots especially in the Residuals vs Leverage plot.</li>
</ul></li>
<li><p>These results tells us that the outlier was not influential. If you look back at the scatterplot, it was located near the middle of the observed <span class="math inline">\(x\text{&#39;s}\)</span> so its potential leverage is low. You can find its leverage based on the plot to be around 0.12 when there are observations in the data set with leverages over 0.3. The high leverage points occur at the beginning and the end of the record because they are at the edges of the observed <span class="math inline">\(x\text{&#39;s}\)</span> and most of these points follow the overall pattern fairly well.</p></li>
</ul></li>
</ul>
<p>So the main issues are with the assumption of independence of observations and one non-influential outlier that might be compromising our normality assumption a bit.</p>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Calculate the test statistic:</strong></p>
<p><span class="math inline">\(t=0.05244/0.00476 = 11.02\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(temp1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = meanmax ~ Year, data = bozemantemps)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3779 -0.9300  0.1078  1.1960  5.8698 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -47.35123    9.32184   -5.08 1.61e-06
## Year          0.05244    0.00476   11.02  &lt; 2e-16
## 
## Residual standard error: 1.624 on 107 degrees of freedom
## Multiple R-squared:  0.5315, Adjusted R-squared:  0.5271 
## F-statistic: 121.4 on 1 and 107 DF,  p-value: &lt; 2.2e-16</code></pre></li>
<li><p>Find the p-value:</p></li>
</ol>
<ul>
<li><p>From the model summary: p-value &lt; 2e-16 or just &lt; 0.0001</p></li>
<li><p>The test statistic is assumed to follow a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-2=109-2=107\)</span> degrees of freedom. The p-value can be calculated as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span><span class="kw">pt</span>(<span class="fl">11.02</span>, <span class="dt">df=</span><span class="dv">107</span>, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 2.498481e-19</code></pre></li>
<li><p>Which is then reported as &lt; 0.0001, which means that the chances of observing a slope coefficient as extreme or more extreme than 0.052 if the null hypothesis of no linear relationship is true is less than 0.01%.</p></li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li><p><strong>Make a decision:</strong></p>
<p>The p-value is very small so provides very strong evidence against the null hypothesis of no trend over time..</p></li>
<li><p><strong>Write a conclusion:</strong></p>
<p>There is very strong evidence against the null hypothesis of no linear relationship between <em>Year</em> and yearly mean <em>Temperature</em> so we can conclude that there is, in fact, some linear relationship between <em>Year</em> and yearly mean maximum <em>Temperature</em> in Bozeman. We can conclude that this detected trend pertains to the Bozeman area in the years 1901 to 2014 but not outside of this area or time frame. We cannot say that time caused the observed changes since it was not randomly assigned and we cannot attribute the changes to any other factors because we did not consider them. But knowing that there was a trend toward increasing temperatures is an intriguing first step in a more complete analysis of changing climate in the area.</p></li>
</ol>
<p>It is also good to report the percentage of variation that the model explains: <em>Year</em> explains 54.91% of the variation in yearly average maximum <em>Temperature</em>. If this value had been very small, we might discount the previous result. Since it is moderately large, that suggests that just by using a linear trend over time we can account for quite a bit of the variation in yearly average maximum temperatures in Bozeman. Note that the percentage of variation explained would get much worse if we tried to analyze the monthly or original daily maximum temperature data even though we might find about the same estimated change over time.</p>
<p>Interpreting a confidence interval provides more useful information than the hypothesis test here – instead of just assessing evidence against the null hypothesis, we can actually provide our best guess at the true change in the mean of <span class="math inline">\(y\)</span> for a change in <span class="math inline">\(x\)</span>. Here, the 95% CI is (0.043, 0.062). This tells us that for a 1 year increase in <em>Year</em>, we are 95% confident that the change in the true mean of the yearly average maximum <em>Temperatures</em> in Bozeman is between 0.043 and 0.062 degrees F.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(temp1)</code></pre></div>
<pre><code>##                    2.5 %       97.5 %
## (Intercept) -65.83068375 -28.87177785
## Year          0.04300681   0.06187746</code></pre>
<p>Sometimes the scale of the x-variable makes interpretation a little difficult, so we can re-scale it to make it more interpretable. One option is to re-scale the variable and re-fit the regression model and the other (easier) option is to re-scale our interpretation. The idea here is that a 100-year change might be easier and more meaningful scale to interpret than a single year change. If we have a slope in the model of 0.052 (for a 1 year change), we can also say that a 100 year change in the mean is estimated to be 0.052*100 = 0.52<span class="math inline">\(^\circ F\)</span>. Similarly, the 95% CI for the population mean 100-year change would be from 0.43<span class="math inline">\(^\circ F\)</span> to 0.62<span class="math inline">\(^\circ F\)</span>. In 2007, the IPCC (Intergovernmental Panel on Climate Change; <a href="http://www.ipcc.ch/publications_and_data/ar4/wg1/en/tssts-3-1-1.html" class="uri">http://www.ipcc.ch/publications_and_data/ar4/wg1/en/tssts-3-1-1.html</a>) estimated the global temperature change from 1906 to 2005 to be 0.74<span class="math inline">\(^\circ C\)</span> per decade or, scaled up, 7.4<span class="math inline">\(^\circ C\)</span> per century (1.33<span class="math inline">\(^\circ F\)</span>). There are many reasons why our local temperature trend might differ, including that our analysis was of average maximum temperatures and the IPCC was considering the average temperature (which was not measured locally or in most places in a good way until digital instrumentation was installed) and that local trends are likely to vary around the global average change based on localized environmental conditions.</p>
<p>One issue that arises in local studies of climate change is that researchers often consider these sorts of tests at many locations and on many response variables (if I did the maximum temperature, why not also do the same analysis of the minimum temperature time series as well? And if I did the analysis for Bozeman, what about Butte and Helena and…?). Remember our discussion of multiple testing issues in an ANOVA context when we compared lots of groups? This issue can arise when regression modeling is repeated in many similar data sets, say different sites or different response variables or both, in one study. <span class="citation">Moore, Harper, and Greenwood (<a href="#ref-Moore2007">2007</a>)</span> considered the impacts on the assessment of evidence of trends of earlier spring onset timing in the Mountain West when the number of tests across many sites is accounted for. We found that the evidence for time trends decreases substantially but does not disappear. In a related study, <span class="citation">Greenwood, Harper, and Moore (<a href="#ref-Greenwood2011">2011</a>)</span> found evidence for regional trends to earlier spring onset using more sophisticated statistical models. The main point here is to <strong>be careful when using simple statistical methods repeatedly if you are not accounting for the number of tests performed</strong><a href="#fn84" class="footnoteRef" id="fnref84"><sup>84</sup></a>.</p>
<p>Along with the confidence interval, we can also plot the estimated model (Figure <a href="7-3-section7-3.html#fig:Figure7-6">2.122</a>) using a term-plot from the <code>effects</code> package (Fox, 2003). This is the same function we used for visualizing results in the ANOVA models and in its basic application you just need <code>plot(allEffects(MODELNAME))</code> although we enhanced our version a little. In regression models, we get to see the regression line along with bounds for 95% confidence intervals for the mean at every value of <span class="math inline">\(x\)</span> that was observed (explained in the next section). Note that there is also a rugplot on the x-axis showing you where values of the explanatory variable were obtained, which is useful to understanding how much information is available for different aspects of the line. Here it provides gaps for missing years of observations as sort of broken teeth in a comb.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(temp1, <span class="dt">xlevels=</span><span class="kw">list</span>(<span class="dt">Year=</span>bozemantemps<span class="op">$</span>Year)),
     <span class="dt">grid=</span>T)</code></pre></div>
<div class="figure"><span id="fig:Figure7-6"></span>
<img src="07-simpleLinearRegressionInference_files/figure-html/Figure7-6-1.png" alt="Term-plot for the Bozeman mean yearly maximum temperature linear regression model with 95% confidence interval bands for the mean in each year." width="576" />
<p class="caption">
Figure 2.122: Term-plot for the Bozeman mean yearly maximum temperature linear regression model with 95% confidence interval bands for the mean in each year.
</p>
</div>
<p>If we extended the plot for the model to <code>Year</code> = 0, we could see the reason that the y-intercept in this model is -47.4<span class="math inline">\(^\circ F\)</span>. This is obviously a large extrapolation for these data and provides a silly result. However, in paleoclimate data that goes back thousands of years using tree rings, ice cores, or sea sediments, the estimated mean in year 0 might be interesting and within the scope of observed values. It all depends on the application.</p>
<p>To make the y-intercept more interesting for our data set, we can re-scale the <span class="math inline">\(x\text{&#39;s}\)</span> before we fit the model to have the first year in the data set (1901) be “0”. This is accomplished by calculating <span class="math inline">\(\text{Year2} = \text{Year}-1901\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bozemantemps<span class="op">$</span>Year2 &lt;-<span class="st"> </span>bozemantemps<span class="op">$</span>Year <span class="op">-</span><span class="st"> </span><span class="dv">1901</span>
<span class="kw">summary</span>(bozemantemps<span class="op">$</span>Year2)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00   29.00   58.00   57.27   85.00  113.00</code></pre>
<p>The new estimated regression equation is <span class="math inline">\(\widehat{\text{Temp}}_i = 52.34 + 0.052\cdot\text{Year2}_i\)</span>. The slope and its test statistic are the same as in the previous model. The y-intercept has changed dramatically with a 95% CI from 51.72<span class="math inline">\(^\circ F\)</span> to 52.96<span class="math inline">\(^\circ F\)</span> for <code>Year2</code>=0. But we know that <code>Year2</code> has a 0 value for 1901 because of our subtraction. That means that this CI is for the true mean in 1901 and is now at least somewhat interesting. If you revisit Figure <a href="7-3-section7-3.html#fig:Figure7-6">2.122</a> you will actually see that the displayed confidence intervals provide upper and lower bounds that match this result for 1901 – the y-intercept CI matches the 95% CI for the true mean.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">temp2 &lt;-<span class="st"> </span><span class="kw">lm</span>(meanmax<span class="op">~</span>Year2, <span class="dt">data=</span>bozemantemps)
<span class="kw">summary</span>(temp2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = meanmax ~ Year2, data = bozemantemps)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.3779 -0.9300  0.1078  1.1960  5.8698 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 52.34126    0.31383  166.78   &lt;2e-16
## Year2        0.05244    0.00476   11.02   &lt;2e-16
## 
## Residual standard error: 1.624 on 107 degrees of freedom
## Multiple R-squared:  0.5315, Adjusted R-squared:  0.5271 
## F-statistic: 121.4 on 1 and 107 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(temp2)</code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept) 51.71913822 52.96339150
## Year2        0.04300681  0.06187746</code></pre>
<p>Ideally, we want to find a regression model that does not violate any assumptions, has a high <span class="math inline">\(\mathbf{R^2}\)</span> value, and a slope coefficient with a small p-value. If any of these are not the case, then we are not completely satisfied with the regression and <strong>should be suspicious of any inference we perform</strong>. We can sometimes resolve some of the systematic issues noted above using <strong><em>transformations</em></strong>, discussed in Sections <a href="7-5-section7-5.html#section7-5">7.5</a> and <a href="7-6-section7-6.html#section7-6">7.6</a>.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Moore2007">
<p>Moore, Johnnie N., Joel T. Harper, and Mark C. Greenwood. 2007. “Significance of Trends Toward Earlier Snowmelt Runoff, Columbia and Missouri Basin Headwaters, Western United States.” <em>Geophysical Research Letters</em> 34 (16). doi:<a href="https://doi.org/10.1029/2007GL031022">10.1029/2007GL031022</a>.</p>
</div>
<div id="ref-Greenwood2011">
<p>Greenwood, Mark C., Joel Harper, and Johnnie Moore. 2011. “An Application of Statistics in Climate Change: Detection of Nonlinear Changes in a Streamflow Timing Measure in the Columbia and Missouri Headwaters.” In <em>Handbook of the Philosophy of Science, Vol. 7: Statistics</em>, edited by P.S. Bandyopadhyay and M. Forster, 1117–42. Elsevier.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="81">
<li id="fn81"><p>See <a href="http://fivethirtyeight.com/features/which-city-has-the-most-unpredictable-weather/" class="uri">http://fivethirtyeight.com/features/which-city-has-the-most-unpredictable-weather/</a> for an interesting discussion of weather variability where Great Falls, MT had a very high rating on “unpredictability”.<a href="7-3-section7-3.html#fnref81">↩</a></p></li>
<li id="fn82"><p>It is actually pretty amazing that there are hundreds of locations with nearly complete daily records for over 100 years.<a href="7-3-section7-3.html#fnref82">↩</a></p></li>
<li id="fn83"><p>All joking aside, if researchers can find evidence of climate change using <strong><em>conservative</em></strong> methods (methods that reject the null hypothesis when it is true less often than stated), then their results are even harder to ignore.<a href="7-3-section7-3.html#fnref83">↩</a></p></li>
<li id="fn84"><p>The simplest adjustment for multiple testing is using what is called a Bonferroni adjustment, where you multiply all the p-values by the number of tests performed. It controls the chances of at least one error to be same as your Type I error rate for one test.<a href="7-3-section7-3.html#fnref84">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="7-2-section7-2.html"><button class="btn btn-default">Previous</button></a>
<a href="7-4-section7-4.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
