<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="A Second Semester Statistics Course with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="A Second Semester Statistics Course with R">

<title>A Second Semester Statistics Course with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Beanplots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Chapter summary</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Summary of important R code</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for Prisoner Rating data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and table plots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient (Optional section)</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomizing inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-9" class="section level2">
<h2><span class="header-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</h2>

<p>One of the implicit assumptions up to this point was that the models were being applied to a single homogeneous population. In many cases, we take a sample from a population but that overall group is likely a combination of individuals from different sub-populations. For example, the SAT study was interested in all students at the university but that contains the obvious sub-populations based on the sex of the students. It is dangerous to fit MLR models across subpopulations but we can also use MLR models to address more sophisticated research questions by comparing groups. We will be able to compare the intercepts (mean levels) and the slopes to see if they differ between the groups. For example, does the relationship between the <em>SATV</em> and <em>FYGPA</em> differ for male and female students? We can add the grouping information to the scatterplot of <em>FYGPA</em> vs <em>SATV</em> (Figure <a href="8-9-section8-9.html#fig:Figure8-17">2.156</a>) and consider whether there is visual evidence of a difference in the slope and/or intercept between the two groups, with men coded<a href="#fn102" class="footnoteRef" id="fnref102"><sup>102</sup></a> as 1 and women coded as 2.</p>
<p>It appears that the slope for females might be larger (steeper) in this relationship than it is for males. So increases in SAT Verbal percentiles for females might have more of an impact on the average first year GPA. We’ll handle this sort of situation in Section <a href="8-11-section8-11.html#section8-11">8.11</a>, where we will formally consider how to change the slopes for different groups. In this section, we develop new methods needed to begin to handle these situations and explore creating models with the same slope coefficient for all groups but different y-intercepts. This material resembles what we did for the Two-Way ANOVA additive model.</p>
<p>These results contrast with Figure <a href="8-9-section8-9.html#fig:Figure8-18">2.157</a> for the relationship between first year college <em>GPA</em> and <em>SATM</em> percentile by sex of the students. The lines for the two groups appear to be mostly parallel and just seem to have different y-intercepts. We can use our MLR techniques to fit a model to the entire data set that allows for different y-intercepts. The real power of this idea is that we can then also test whether the different groups have different y-intercepts – whether the shift between the groups is “real”. In this example, it appears to suggest that females generally have slightly higher GPAs than males, on average, but that an increase in SATM has the same impact for both groups. If this difference in y-intercepts is not “real”, then there appears to be no difference between the sexes in their relationship between SATM and GPA and we can safely continue using a model that does not differentiate the two groups. We could also just subset the data set and do two analyses, but that approach will not allow us to assess whether things are “really” different between the two groups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(car)
<span class="kw">scatterplot</span>(FYGPA<span class="op">~</span>SATV<span class="op">|</span>sex, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">data=</span>satGPA, <span class="dt">spread=</span>F,
            <span class="dt">smooth=</span>F, <span class="dt">main=</span><span class="st">&quot;Scatterplot of GPA vs SATV by Sex&quot;</span>)
<span class="kw">scatterplot</span>(FYGPA<span class="op">~</span>SATM<span class="op">|</span>sex, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">data=</span>satGPA, <span class="dt">spread=</span>F,
            <span class="dt">smooth=</span>F, <span class="dt">main=</span><span class="st">&quot;Scatterplot of GPA vs SATM by Sex&quot;</span>)</code></pre></div>
<p>To fit one model to a data set that contain multiple groups, we need a way of entering categorical variable information in an MLR model. Regression models require quantitative predictor variables for the <span class="math inline">\(x\text{&#39;s}\)</span> so we can’t directly enter the sex of the students into the regression model since it contains categories. To be able to put in “numbers” as predictors, we create what are called <strong><em>indicator variables</em></strong><a href="#fn103" class="footnoteRef" id="fnref103"><sup>103</sup></a> that are made up of 0s and 1s, with the 0 reflecting one category and 1 the other, changing depending on the category of the individual in the data set. The <code>lm</code> function does this whenever a categorical variable is used as an explanatory variable. It sets up the indicator variables using a baseline category (gets coded as a 0) and the deviation category for the other level of the variable. We can see how this works by exploring what happens when we put <code>SEX</code> into our <code>lm</code><a href="#fn104" class="footnoteRef" id="fnref104"><sup>104</sup></a> with SATM, after first making sure it is categorical using the <code>factor</code> function and making the factor <code>levels</code> explicit instead of 1s and 2s.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">satGPA<span class="op">$</span>SEX &lt;-<span class="st"> </span><span class="kw">factor</span>(satGPA<span class="op">$</span>sex) <span class="co">#Make 1,2 coded sex into factor SEX</span>
<span class="kw">levels</span>(satGPA<span class="op">$</span>SEX) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>) <span class="co">#Make category names clear</span>
SATSex1 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATM<span class="op">+</span>SEX, <span class="dt">data=</span>satGPA) <span class="co">#Fit lm with SATM and SEX</span>
<span class="kw">summary</span>(SATSex1)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATM + SEX, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.21589    0.14858   1.453    0.147
## SATM         0.03861    0.00258  14.969  &lt; 2e-16
## SEXFEMALE    0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>

<div class="figure"><span id="fig:Figure8-17"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-17-1.png" alt="Plot of FYGPA vs SATV by Sex of students." width="576" />
<p class="caption">
Figure 2.156: Plot of FYGPA vs SATV by Sex of students.
</p>
</div>

<div class="figure"><span id="fig:Figure8-18"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-18-1.png" alt="Plot of FYGPA vs SATM by Sex of students." width="576" />
<p class="caption">
Figure 2.157: Plot of FYGPA vs SATM by Sex of students.
</p>
</div>
<p>The <code>SEX</code> row contains information that the linear model chose <em>MALE</em> as the baseline category and <em>FEMALE</em> as the deviation category since <em>MALE</em> does not show up in the output. To see what <code>lm</code> is doing for us when we give it a two-level categorical variable, we can create our own “numerical” predictor that is 0 for <em>males</em> and 1 for <em>females</em> that we called <code>SEXINDICATOR</code>, displayed for the first 10 observations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Convert logical to 0 for male, 1 for female</span>
satGPA<span class="op">$</span>SEXINDICATOR &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(satGPA<span class="op">$</span>SEX<span class="op">==</span><span class="st">&quot;FEMALE&quot;</span>) 
<span class="co"># Explore first few observations</span>
<span class="kw">head</span>(<span class="kw">tibble</span>(<span class="dt">SEX=</span>satGPA<span class="op">$</span>SEX, <span class="dt">SEXINDICATOR=</span>satGPA<span class="op">$</span>SEXINDICATOR), <span class="dv">10</span>) </code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    SEX    SEXINDICATOR
##    &lt;fct&gt;         &lt;dbl&gt;
##  1 MALE              0
##  2 FEMALE            1
##  3 FEMALE            1
##  4 MALE              0
##  5 MALE              0
##  6 FEMALE            1
##  7 MALE              0
##  8 MALE              0
##  9 FEMALE            1
## 10 MALE              0</code></pre>
<p>We can define the indicator variable more generally by calling it <span class="math inline">\(I_{\text{Female},i}\)</span> to denote that it is an indicator <span class="math inline">\((I)\)</span> that takes on a value of 1 for observations in the category <em>Female</em> and 0 otherwise (<em>Male</em>) – changing based on the observation (<span class="math inline">\(i\)</span>). Indicator variables, once created, are quantitative variables that take on values of 0 or 1 and we can put them directly into linear models with other <span class="math inline">\(x\text{&#39;s}\)</span> (quantitative or categorical). If we replace the categorical <code>SEX</code> variable with our quantitative <code>SEXINDICATOR</code> and re-fit the model, we get:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SATSex2 &lt;-<span class="st"> </span><span class="kw">lm</span>(FYGPA<span class="op">~</span>SATM<span class="op">+</span>SEXINDICATOR, <span class="dt">data=</span>satGPA)
<span class="kw">summary</span>(SATSex2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = FYGPA ~ SATM + SEXINDICATOR, data = satGPA)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.21589    0.14858   1.453    0.147
## SATM          0.03861    0.00258  14.969  &lt; 2e-16
## SEXINDICATOR  0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This matches all the previous <code>lm</code> output except that we didn’t get any information on the categories used since <code>lm</code> didn’t know that SEXINDICATOR was anything different from other quantitative predictors.</p>
<p>Now we want to think about what this model means. We can write the estimated model as</p>
<p><span class="math display">\[\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\cdot\text{SATM}_i +
0.313I_{\text{Female},i}\ .\]</span></p>
<p>When we have a <em>male</em> observation, the indicator takes on a value of 0 so the 0.313 drops out of the model, leaving an SLR just in terms of <em>SATM</em>. For a <em>female</em> student, the indicator is 1 and we add 0.313 to the previous y-intercept. The following works this out step-by-step, simplifying the MLR into two SLRs:</p>
<ul>
<li><p>Simplified model for <em>Males</em> (plug in a 0 for <span class="math inline">\(I_{\text{Female}}\)</span>):</p>
<ul>
<li><span class="math inline">\(\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\cdot\text{SATM}_i + 0.313*0 = 0.216 + 0.0386\cdot\text{SATM}_i\)</span></li>
</ul></li>
<li><p>Simplified model for <em>Females</em> (plug in a 1 for <span class="math inline">\(I_{\text{Female}}\)</span>):</p>
<ul>
<li><p><span class="math inline">\(\widehat{\text{FYGPA}}_i = 0.216 + 0.0386\cdot\text{SATM}_i + 0.313*1\)</span></p></li>
<li><p><span class="math inline">\(= 0.216 + 0.0386\cdot\text{SATM}_i + 0.313\)</span> (combine “like” terms to simplify the equation)</p></li>
<li><p><span class="math inline">\(= 0.529 + 0.0386\cdot\text{SATM}_i\)</span></p></li>
</ul></li>
</ul>
<p>In this situation, we then end up with two SLR models that relate <em>SATM</em> to <em>GPA</em>, one model for <em>males</em> <span class="math inline">\((\widehat{\text{FYGPA}}_i= 0.216 + 0.0386\cdot\text{SATM}_i)\)</span> and one for <em>females</em> <span class="math inline">\((\widehat{\text{FYGPA}}_i= 0.529 + 0.0386\cdot\text{SATM}_i)\)</span>. The only difference between these two models is in the y-intercept, with the <em>female</em> model’s y-intercept shifted up from the <em>male</em> y-intercept by 0.313. And that is what adding indicator variables into models does in general<a href="#fn105" class="footnoteRef" id="fnref105"><sup>105</sup></a> – it shifts the intercept up or down from the baseline group (here selected as <em>males</em>) to get a new intercept for the deviation group (here <em>females</em>).</p>
<p>To make this visually clearer, Figure <a href="8-9-section8-9.html#fig:Figure8-19">2.158</a> contains the regression lines that were estimated for each group. For any <em>SATM</em>, the difference in the groups is the 0.313 coefficient from the <code>SEXFEMALE</code> or <code>SEXINDICATOR</code> row of the model summaries. For example, at <em>SATM</em>=50, the difference in terms of predicted average first year GPAs between males and females is displayed as a difference between 2.15 and 2.46. This model assumes that the slope on <em>SATM</em> is the same for both groups except that they are allowed to have different y-intercepts, which is reasonable here because we saw approximately parallel relationships for the two groups in Figure <a href="8-9-section8-9.html#fig:Figure8-18">2.157</a>.</p>

<div class="figure"><span id="fig:Figure8-19"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-19-1.png" alt="Plot of estimated model for FYGPA vs SATM by SEX of students (female line is thicker red line). Dashed lines aid in seeing the consistent vertical difference of 0.313 in the two estimated lines based on the model containing a different intercept for each group." width="576" />
<p class="caption">
Figure 2.158: Plot of estimated model for <em>FYGPA</em> vs <em>SATM</em> by <em>SEX</em> of students (female line is thicker red line). Dashed lines aid in seeing the consistent vertical difference of 0.313 in the two estimated lines based on the model containing a different intercept for each group.
</p>
</div>
<p>Remember that <code>lm</code> selects baseline categories typically based on the alphabetical order of the levels of the categorical variable. Here, the <code>SEX</code> variable started with a coding of 1 and 2 and retained that order even with the recoding of levels that we created to give it more explicit names. Because we allow <code>lm</code> to create indicator variables for us, the main thing you need to do is explore the model summary and look for the hint at the baseline level that is not displayed after the name of the categorical variable.</p>
<p>We can also work out the impacts of adding an indicator variable to the model in general in the theoretical model with a single quantitative predictor <span class="math inline">\(x_i\)</span> and indicator <span class="math inline">\(I_i\)</span>. The model starts as</p>
<p><span class="math display">\[y_i=\beta_0+\beta_1x_i + \beta_2I_i + \varepsilon_i\ .\]</span></p>
<p>Again, there are two versions:</p>
<ul>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>baseline</strong> category, <span class="math inline">\(I_i=0\)</span> and the model is <span class="math inline">\(y_i=\beta_0+\beta_1x_i + \varepsilon_i\)</span>.</p></li>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>non-baseline (deviation)</strong> category, <span class="math inline">\(I_i=1\)</span> and the model simplifies to <span class="math inline">\(y_i=(\beta_0+\beta_2)+\beta_1x_i + \varepsilon_i\)</span>.</p>
<ul>
<li>This model has a y-intercept of <span class="math inline">\(\beta_0+\beta_2\)</span>.</li>
</ul></li>
</ul>
<p>The interpretation and inferences for <span class="math inline">\(\beta_1\)</span> resemble the work with any MLR model, noting that these results are “controlled for”, “adjusted for”, or “allowing for differences based on” the categorical variable in the model. The interpretation of <span class="math inline">\(\beta_2\)</span> is as a shift up or down in the y-intercept for the model that includes <span class="math inline">\(x_i\)</span>. When we make term-plots in a model with a quantitative and additive categorical variable, the two reported model components match with the previous discussion – the same estimated term from the quantitative variable for all observations and a shift to reflect the different y-intercepts in the two groups. In Figure <a href="8-9-section8-9.html#fig:Figure8-20">2.159</a>, the females are estimated to be that same 0.313 points higher on first year GPA. The males have a mean GPA slightly above 2.3 which is the predicted GPA for the average SATM percentile (remember that we have to hold the other variable at its mean to make each term-plot)<a href="#fn106" class="footnoteRef" id="fnref106"><sup>106</sup></a>.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(effects)
<span class="kw">plot</span>(<span class="kw">allEffects</span>(SATSex1))</code></pre></div>
<div class="figure"><span id="fig:Figure8-20"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-20-1.png" alt="Term-plots for the estimated model for \(\text{FYGPA}\sim\text{SATM} + \text{SEX}\)." width="576" />
<p class="caption">
Figure 2.159: Term-plots for the estimated model for <span class="math inline">\(\text{FYGPA}\sim\text{SATM} + \text{SEX}\)</span>.
</p>
</div>
<p>The model summary and confidence intervals provide some potential interesting inferences in these models. Again, these are just applications of MLR methods we have already seen except that the definition of one of the variables is “different” using the indicator coding idea. For the same model, the <code>SEX</code> coefficient can be used to generate inferences for differences in the mean the groups, controlling for their <em>SATM</em> scores.</p>
<pre><code>## SEXFEMALE    0.31322    0.04360   7.184 1.32e-12</code></pre>
<p>Testing the null hypothesis that <span class="math inline">\(H_0: \beta_2=0\)</span> vs <span class="math inline">\(H_A: \beta_2\ne 0\)</span> using our regular <span class="math inline">\(t\)</span>-test provides the opportunity to test for a difference in intercepts between the groups. In this situation, the test statistic is <span class="math inline">\(t=7.184\)</span> and, based on a <span class="math inline">\(t_{997}\)</span>-distribution if the null is true, the p-value is <span class="math inline">\(&lt;0.0001\)</span>. We have very strong evidence that there is a difference in the true y-intercept in a <em>SATM</em> model for first year college GPA between <em>males</em> and <em>females</em>. The confidence interval is also informative:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(SATSex1)</code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -0.07566665 0.50744709
## SATM         0.03355273 0.04367726
## SEXFEMALE    0.22766284 0.39877160</code></pre>
<p>We are 95% confident that the true mean GPA for females is between 0.228 and 0.399 points higher than for males, after adjusting for the <em>SATM</em> in the population of students. If we had subset the data set and fit two SLRs, we could have obtained the same simplified regression models but we never could have performed inferences for the differences between the two groups without putting all the observations together in one model and then assessing those differences with targeted coefficients. We also would not be able to get an estimate of their common slope for <em>SATM</em>, after adjusting for differences in the intercept for each group.</p>
</div>
<div class="footnotes">
<hr />
<ol start="102">
<li id="fn102"><p>We are actually making an educated guess about what these codes mean. Other similar data sets used 1 for males but the documentation on these data is a bit sparse. We proceed with a small potential that the conclusions regarding differences in <code>sex</code> are in the wrong direction.<a href="8-9-section8-9.html#fnref102">↩</a></p></li>
<li id="fn103"><p>Some people also call them <strong><em>dummy variables</em></strong> to reflect that they are stand-ins for dealing with the categorical information.<a href="8-9-section8-9.html#fnref103">↩</a></p></li>
<li id="fn104"><p>That may not read how I intended…<a href="8-9-section8-9.html#fnref104">↩</a></p></li>
<li id="fn105"><p>This is true for additive uses of indicator variables. In Section <a href="8-11-section8-11.html#section8-11">8.11</a>, we consider interactions between quantitative and categorical variables which has the effect of changing slopes and intercepts. The simplification ideas to produce estimated equations for each group are used there but we have to account for changing slopes by group too.<a href="8-9-section8-9.html#fnref105">↩</a></p></li>
<li id="fn106"><p>When making the SATM term-plot, the categorical variable is held at the most frequently occurring value in the data set. If you drop <code>ci.style=&quot;lines&quot;</code> from the effect plot options, it is best to copy the figures as Bitmaps or save them as an image or they may (for some reason) lose the shaded bands in some word processing programs.<a href="8-9-section8-9.html#fnref106">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="8-8-section8-8.html"><button class="btn btn-default">Previous</button></a>
<a href="8-10-section8-10.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
