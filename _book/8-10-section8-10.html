<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="8.10 Additive MLR with more than two groups: Headache example | Intermediate Statistics with R" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="gpeterson406/Greenwood_Book" />

<meta name="author" content="Mark C Greenwood" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="8.10 Additive MLR with more than two groups: Headache example | Intermediate Statistics with R">

<title>8.10 Additive MLR with more than two groups: Headache example | Intermediate Statistics with R</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#cover">Cover</a></li>
<li><a href="acknowledgments.html#acknowledgments">Acknowledgments</a></li>
<li class="has-sub"><a href="1-chapter1.html#chapter1"><span class="toc-section-number">1</span> Preface</a><ul>
<li><a href="1-1-section1-1.html#section1-1"><span class="toc-section-number">1.1</span> Overview of methods</a></li>
<li><a href="1-2-section1-2.html#section1-2"><span class="toc-section-number">1.2</span> Getting started in R</a></li>
<li><a href="1-3-section1-3.html#section1-3"><span class="toc-section-number">1.3</span> Basic summary statistics, histograms, and boxplots using R</a></li>
<li><a href="1-4-section1-4.html#section1-4"><span class="toc-section-number">1.4</span> Chapter summary</a></li>
<li><a href="1-5-section1-5.html#section1-5"><span class="toc-section-number">1.5</span> Summary of important R code</a></li>
<li><a href="1-6-section1-6.html#section1-6"><span class="toc-section-number">1.6</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="2-chapter2.html#chapter2"><span class="toc-section-number">2</span> (R)e-Introduction to statistics</a><ul>
<li><a href="2-1-section2-1.html#section2-1"><span class="toc-section-number">2.1</span> Histograms, boxplots, and density curves</a></li>
<li><a href="2-2-section2-2.html#section2-2"><span class="toc-section-number">2.2</span> Pirate-plots</a></li>
<li><a href="2-3-section2-3.html#section2-3"><span class="toc-section-number">2.3</span> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li><a href="2-4-section2-4.html#section2-4"><span class="toc-section-number">2.4</span> Permutation testing for the two sample mean situation</a></li>
<li><a href="2-5-section2-5.html#section2-5"><span class="toc-section-number">2.5</span> Hypothesis testing (general)</a></li>
<li><a href="2-6-section2-6.html#section2-6"><span class="toc-section-number">2.6</span> Connecting randomization (nonparametric) and parametric tests</a></li>
<li><a href="2-7-section2-7.html#section2-7"><span class="toc-section-number">2.7</span> Second example of permutation tests</a></li>
<li><a href="2-8-section2-8.html#section2-8"><span class="toc-section-number">2.8</span> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li><a href="2-9-section2-9.html#section2-9"><span class="toc-section-number">2.9</span> Confidence intervals and bootstrapping</a></li>
<li><a href="2-10-section2-10.html#section2-10"><span class="toc-section-number">2.10</span> Bootstrap confidence intervals for difference in GPAs</a></li>
<li><a href="2-11-section2-11.html#section2-11"><span class="toc-section-number">2.11</span> Chapter summary</a></li>
<li><a href="2-12-section2-12.html#section2-12"><span class="toc-section-number">2.12</span> Summary of important R code</a></li>
<li><a href="2-13-section2-13.html#section2-13"><span class="toc-section-number">2.13</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="3-chapter3.html#chapter3"><span class="toc-section-number">3</span> One-Way ANOVA</a><ul>
<li><a href="3-1-section3-1.html#section3-1"><span class="toc-section-number">3.1</span> Situation</a></li>
<li><a href="3-2-section3-2.html#section3-2"><span class="toc-section-number">3.2</span> Linear model for One-Way ANOVA (cell-means and reference-coding)</a></li>
<li><a href="3-3-section3-3.html#section3-3"><span class="toc-section-number">3.3</span> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li><a href="3-4-section3-4.html#section3-4"><span class="toc-section-number">3.4</span> ANOVA model diagnostics including QQ-plots</a></li>
<li><a href="3-5-section3-5.html#section3-5"><span class="toc-section-number">3.5</span> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li><a href="3-6-section3-6.html#section3-6"><span class="toc-section-number">3.6</span> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li><a href="3-7-section3-7.html#section3-7"><span class="toc-section-number">3.7</span> Pair-wise comparisons for the Overtake data</a></li>
<li><a href="3-8-section3-8.html#section3-8"><span class="toc-section-number">3.8</span> Chapter summary</a></li>
<li><a href="3-9-section3-9.html#section3-9"><span class="toc-section-number">3.9</span> Summary of important R code</a></li>
<li><a href="3-10-section3-10.html#section3-10"><span class="toc-section-number">3.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="4-chapter4.html#chapter4"><span class="toc-section-number">4</span> Two-Way ANOVA</a><ul>
<li><a href="4-1-section4-1.html#section4-1"><span class="toc-section-number">4.1</span> Situation</a></li>
<li><a href="4-2-section4-2.html#section4-2"><span class="toc-section-number">4.2</span> Designing a two-way experiment and visualizing results</a></li>
<li><a href="4-3-section4-3.html#section4-3"><span class="toc-section-number">4.3</span> Two-Way ANOVA models and hypothesis tests</a></li>
<li><a href="4-4-section4-4.html#section4-4"><span class="toc-section-number">4.4</span> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li><a href="4-5-section4-5.html#section4-5"><span class="toc-section-number">4.5</span> Observational study example: The Psychology of Debt</a></li>
<li><a href="4-6-section4-6.html#section4-6"><span class="toc-section-number">4.6</span> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li><a href="4-7-section4-7.html#section4-7"><span class="toc-section-number">4.7</span> Chapter summary</a></li>
<li><a href="4-8-section4-8.html#section4-8"><span class="toc-section-number">4.8</span> Summary of important R code</a></li>
<li><a href="4-9-section4-9.html#section4-9"><span class="toc-section-number">4.9</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="5-chapter5.html#chapter5"><span class="toc-section-number">5</span> Chi-square tests</a><ul>
<li><a href="5-1-section5-1.html#section5-1"><span class="toc-section-number">5.1</span> Situation, contingency tables, and tableplots</a></li>
<li><a href="5-2-section5-2.html#section5-2"><span class="toc-section-number">5.2</span> Homogeneity test hypotheses</a></li>
<li><a href="5-3-section5-3.html#section5-3"><span class="toc-section-number">5.3</span> Independence test hypotheses</a></li>
<li><a href="5-4-section5-4.html#section5-4"><span class="toc-section-number">5.4</span> Models for R by C tables</a></li>
<li><a href="5-5-section5-5.html#section5-5"><span class="toc-section-number">5.5</span> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-6-section5-6.html#section5-6"><span class="toc-section-number">5.6</span> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li><a href="5-7-section5-7.html#section5-7"><span class="toc-section-number">5.7</span> Examining residuals for the source of differences</a></li>
<li><a href="5-8-section5-8.html#section5-8"><span class="toc-section-number">5.8</span> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li><a href="5-9-section5-9.html#section5-9"><span class="toc-section-number">5.9</span> Political party and voting results: Complete analysis</a></li>
<li><a href="5-10-section5-10.html#section5-10"><span class="toc-section-number">5.10</span> Is cheating and lying related in students?</a></li>
<li><a href="5-11-section5-11.html#section5-11"><span class="toc-section-number">5.11</span> Analyzing a stratified random sample of California schools</a></li>
<li><a href="5-12-section5-12.html#section5-12"><span class="toc-section-number">5.12</span> Chapter summary</a></li>
<li><a href="5-13-section5-13.html#section5-13"><span class="toc-section-number">5.13</span> Summary of important R commands</a></li>
<li><a href="5-14-section5-14.html#section5-14"><span class="toc-section-number">5.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="6-chapter6.html#chapter6"><span class="toc-section-number">6</span> Correlation and Simple Linear Regression</a><ul>
<li><a href="6-1-section6-1.html#section6-1"><span class="toc-section-number">6.1</span> Relationships between two quantitative variables</a></li>
<li><a href="6-2-section6-2.html#section6-2"><span class="toc-section-number">6.2</span> Estimating the correlation coefficient</a></li>
<li><a href="6-3-section6-3.html#section6-3"><span class="toc-section-number">6.3</span> Relationships between variables by groups</a></li>
<li><a href="6-4-section6-4.html#section6-4"><span class="toc-section-number">6.4</span> Inference for the correlation coefficient</a></li>
<li><a href="6-5-section6-5.html#section6-5"><span class="toc-section-number">6.5</span> Are tree diameters related to tree heights?</a></li>
<li><a href="6-6-section6-6.html#section6-6"><span class="toc-section-number">6.6</span> Describing relationships with a regression model</a></li>
<li><a href="6-7-section6-7.html#section6-7"><span class="toc-section-number">6.7</span> Least Squares Estimation</a></li>
<li><a href="6-8-section6-8.html#section6-8"><span class="toc-section-number">6.8</span> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li><a href="6-9-section6-9.html#section6-9"><span class="toc-section-number">6.9</span> Outliers: leverage and influence</a></li>
<li><a href="6-10-section6-10.html#section6-10"><span class="toc-section-number">6.10</span> Residual diagnostics – setting the stage for inference</a></li>
<li><a href="6-11-section6-11.html#section6-11"><span class="toc-section-number">6.11</span> Old Faithful discharge and waiting times</a></li>
<li><a href="6-12-section6-12.html#section6-12"><span class="toc-section-number">6.12</span> Chapter summary</a></li>
<li><a href="6-13-section6-13.html#section6-13"><span class="toc-section-number">6.13</span> Summary of important R code</a></li>
<li><a href="6-14-section6-14.html#section6-14"><span class="toc-section-number">6.14</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="7-chapter7.html#chapter7"><span class="toc-section-number">7</span> Simple linear regression inference</a><ul>
<li><a href="7-1-section7-1.html#section7-1"><span class="toc-section-number">7.1</span> Model</a></li>
<li><a href="7-2-section7-2.html#section7-2"><span class="toc-section-number">7.2</span> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li><a href="7-3-section7-3.html#section7-3"><span class="toc-section-number">7.3</span> Bozeman temperature trend</a></li>
<li><a href="7-4-section7-4.html#section7-4"><span class="toc-section-number">7.4</span> Randomization-based inferences for the slope coefficient</a></li>
<li><a href="7-5-section7-5.html#section7-5"><span class="toc-section-number">7.5</span> Transformations part I: Linearizing relationships</a></li>
<li><a href="7-6-section7-6.html#section7-6"><span class="toc-section-number">7.6</span> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li><a href="7-7-section7-7.html#section7-7"><span class="toc-section-number">7.7</span> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li><a href="7-8-section7-8.html#section7-8"><span class="toc-section-number">7.8</span> Chapter summary</a></li>
<li><a href="7-9-section7-9.html#section7-9"><span class="toc-section-number">7.9</span> Summary of important R code</a></li>
<li><a href="7-10-section7-10.html#section7-10"><span class="toc-section-number">7.10</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="8-chapter8.html#chapter8"><span class="toc-section-number">8</span> Multiple linear regression</a><ul>
<li><a href="8-1-section8-1.html#section8-1"><span class="toc-section-number">8.1</span> Going from SLR to MLR</a></li>
<li><a href="8-2-section8-2.html#section8-2"><span class="toc-section-number">8.2</span> Validity conditions in MLR</a></li>
<li><a href="8-3-section8-3.html#section8-3"><span class="toc-section-number">8.3</span> Interpretation of MLR terms</a></li>
<li><a href="8-4-section8-4.html#section8-4"><span class="toc-section-number">8.4</span> Comparing multiple regression models</a></li>
<li><a href="8-5-section8-5.html#section8-5"><span class="toc-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</a></li>
<li><a href="8-6-section8-6.html#section8-6"><span class="toc-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</a></li>
<li><a href="8-7-section8-7.html#section8-7"><span class="toc-section-number">8.7</span> Overall F-test in multiple linear regression</a></li>
<li><a href="8-8-section8-8.html#section8-8"><span class="toc-section-number">8.8</span> Case study: First year college GPA and SATs</a></li>
<li><a href="8-9-section8-9.html#section8-9"><span class="toc-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</a></li>
<li><a href="8-10-section8-10.html#section8-10"><span class="toc-section-number">8.10</span> Additive MLR with more than two groups: Headache example</a></li>
<li><a href="8-11-section8-11.html#section8-11"><span class="toc-section-number">8.11</span> Different slopes and different intercepts</a></li>
<li><a href="8-12-section8-12.html#section8-12"><span class="toc-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li><a href="8-13-section8-13.html#section8-13"><span class="toc-section-number">8.13</span> AICs for model selection</a></li>
<li><a href="8-14-section8-14.html#section8-14"><span class="toc-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</a></li>
<li><a href="8-15-section8-15.html#section8-15"><span class="toc-section-number">8.15</span> Chapter summary</a></li>
<li><a href="8-16-section8-16.html#section8-16"><span class="toc-section-number">8.16</span> Summary of important R code</a></li>
<li><a href="8-17-section8-17.html#section8-17"><span class="toc-section-number">8.17</span> Practice problems</a></li>
</ul></li>
<li class="has-sub"><a href="9-chapter9.html#chapter9"><span class="toc-section-number">9</span> Case studies</a><ul>
<li><a href="9-1-section9-1.html#section9-1"><span class="toc-section-number">9.1</span> Overview of material covered</a></li>
<li><a href="9-2-section9-2.html#section9-2"><span class="toc-section-number">9.2</span> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li><a href="9-3-section9-3.html#section9-3"><span class="toc-section-number">9.3</span> Ants learn to rely on more informative attributes during decision-making</a></li>
<li><a href="9-4-section9-4.html#section9-4"><span class="toc-section-number">9.4</span> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li><a href="9-5-section9-5.html#section9-5"><span class="toc-section-number">9.5</span> What do didgeridoos really do about sleepiness?</a></li>
<li><a href="9-6-section9-6.html#section9-6"><span class="toc-section-number">9.6</span> General summary</a></li>
</ul></li>
<li><a href="references.html#references">References</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="section8-10" class="section level2">
<h2><span class="header-section-number">8.10</span> Additive MLR with more than two groups: Headache example</h2>
<p>The same techniques can be extended to more than two groups. A study was
conducted to explore sound tolerances using <span class="math inline">\(n=98\)</span> subjects with the data
available in the <code>Headache</code> data set from the <code>heplots</code> package
<span class="citation">(Fox and Friendly <a href="#ref-R-heplots" role="doc-biblioref">2018</a>)</span>.

Each
subject was initially exposed to a tone, stopping when the tone became definitely
intolerable (<em>DU</em>) and that decibel level was recorded (variable called <code>du1</code>).
Then the subjects were randomly assigned to one of four treatments: <em>T1</em>
(Listened again to the tone at their initial <em>DU</em> level, for the same amount of
time they were able to tolerate it before); <em>T2</em> (Same as <em>T1</em>, with one
additional minute of exposure); <em>T3</em> (Same as <em>T2</em>, but the subjects were
explicitly instructed to use the relaxation techniques); and <em>Control</em> (these
subjects experienced no further exposure to the noise tone until the final
sensitivity measures were taken). Then the <em>DU</em> was measured again (variable
called <code>du2</code>). One would expect that there would be a relationship between the
upper tolerance levels of the subjects before and after treatment. But
maybe the treatments impact that relationship? We can use our indicator 
approach to see if the treatments provide a shift to higher tolerances after
accounting for the relationship between the two measurements<a href="#fn129" class="footnote-ref" id="fnref129"><sup>129</sup></a>. The scatterplot<a href="#fn130" class="footnote-ref" id="fnref130"><sup>130</sup></a>
of the results in Figure <a href="8-10-section8-10.html#fig:Figure8-21">2.170</a> shows some variation in the
slopes and the intercepts for the groups although the variation in intercepts
seems more prominent than differences in slopes.</p>
<p>(ref:fig8-21) Scatterplot of post-treatment decibel tolerance (du2) vs
pre-treatment tolerance (du1) by treatment level (4 groups).</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb774-1" title="1"><span class="kw">library</span>(heplots)</a>
<a class="sourceLine" id="cb774-2" title="2"><span class="kw">data</span>(Headache)</a>
<a class="sourceLine" id="cb774-3" title="3">Headache &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(Headache)</a>
<a class="sourceLine" id="cb774-4" title="4">Headache</a></code></pre></div>
<pre><code>## # A tibble: 98 x 6
##    type    treatment    u1   du1    u2   du2
##    &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 Migrane T3         2.34  5.3   5.8   8.52
##  2 Migrane T1         2.73  6.85  4.68  6.68
##  3 Tension T1         0.37  0.53  0.55  0.84
##  4 Migrane T3         7.5   9.12  5.7   7.88
##  5 Migrane T3         4.63  7.21  5.63  6.75
##  6 Migrane T3         3.6   7.3   4.83  7.32
##  7 Migrane T2         2.45  3.75  2.5   3.18
##  8 Migrane T1         2.31  3.25  2     3.3 
##  9 Migrane T1         1.38  2.33  2.23  3.98
## 10 Tension T3         0.85  1.42  1.37  1.89
## # ... with 88 more rows</code></pre>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb776-1" title="1"><span class="kw">scatterplot</span>(du2<span class="op">~</span>du1<span class="op">|</span>treatment, <span class="dt">data=</span>Headache, <span class="dt">smooth=</span>F, <span class="dt">lwd=</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb776-2" title="2">            <span class="dt">main=</span><span class="st">&quot;Plot of Maximum DB tolerances before &amp; after treatment (by treatment)&quot;</span>,</a>
<a class="sourceLine" id="cb776-3" title="3">            <span class="dt">legend=</span><span class="kw">list</span>(<span class="dt">coords=</span><span class="st">&quot;topleft&quot;</span>,<span class="dt">columns=</span><span class="dv">2</span>))</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-21"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-21-1.png" alt="(ref:fig8-21)" width="960" />
<p class="caption">
Figure 2.170: (ref:fig8-21)
</p>
</div>
<p>This data set contains a categorical variable with 4 levels. To go beyond two
groups, we have to add more than one indicator variable,  defining three
indicators to turn on (1) or off (0) for three of the levels of the variable
with the same reference level used for all the indicators. For this example,
the <em>T1 Treatment</em> group is chosen as the baseline group so it sort of hides in
the background while we define indicators for the other three levels. The
indicators for <em>T2</em>, <em>T3</em>, and <em>Control</em> levels are:</p>
<ul>
<li><p>Indicator for <em>T2</em>: <span class="math inline">\(I_{T2,i}=\left\{\begin{array}{rl} 1 &amp; \text{if Treatment}=T2 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
<li><p>Indicator for <em>T3</em>: <span class="math inline">\(I_{T3,i}=\left\{\begin{array}{rl} 1 &amp; \text{if Treatment}=T3 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
<li><p>Indicator for <em>Control</em>: <span class="math inline">\(I_{\text{Control},i}=\left\{\begin{array}{rl} 1 &amp; \text{if Treatment}=\text{Control} \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
</ul>
<p>We can see the values of these indicators for a few observations and their
original variable (<code>treatment</code>) in the following output. The bolded
observations show each of the indicators being “turned on”. For <em>T1</em>, all the
indicators stay at 0.</p>

<table>
<thead>
<tr class="header">
<th align="left">Treatment</th>
<th align="right">I_T2</th>
<th align="right">I_T3</th>
<th align="right">I_Control</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">Control</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>When we fit the additive model of the form <code>y~x+group</code>, the <code>lm</code>
function takes the <span class="math inline">\(\boldsymbol{J}\)</span> categories and creates <span class="math inline">\(\boldsymbol{J-1}\)</span>
indicator variables.
 
The baseline level is always handled in the intercept.
The true model will be of the form</p>
<p><span class="math display">\[y_i=\beta_0 + \beta_1x_i +\beta_2I_{\text{Level}2,i}+\beta_3I_{\text{Level}3,i}
+\cdots+\beta_{J}I_{\text{Level}J,i}+\varepsilon_i\]</span></p>
<p>where the <span class="math inline">\(I_{\text{CatName}j,i}\text{&#39;s}\)</span> are the different indicator variables.
Note that each indicator variable gets a coefficient associated with it and is
“turned on” whenever the <span class="math inline">\(i^{th}\)</span> observation is in that category. Only one of
the <span class="math inline">\(I_{\text{CatName}j,i}\text{&#39;s}\)</span> is a 1 for any observation, so the
y-intercept will either be <span class="math inline">\(\beta_0\)</span> for the baseline group or <span class="math inline">\(\beta_0+\beta_j\)</span>
for <span class="math inline">\(j=2,\ldots,J\)</span>. It is important to remember that this
is an “additive” model since the effects just add and there is no interaction
between the grouping variable and the quantitative predictor. To be able to
trust this model, we need to check that we do not need different slope
coefficients for the groups as discussed in the next section.</p>
<p>For these types of models, it is always good to start with a plot of the data
set with regression lines for each group – assessing whether the lines look
relatively parallel or not.

In Figure <a href="8-10-section8-10.html#fig:Figure8-21">2.170</a>, there are some
differences in slopes – we investigate that further in the next section. For
now, we can proceed with fitting the additive model with different intercepts
for the four levels of <code>treatment</code> and the quantitative explanatory variable, <code>du1</code>.</p>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb777-1" title="1">head1 &lt;-<span class="st"> </span><span class="kw">lm</span>(du2<span class="op">~</span>du1<span class="op">+</span>treatment, <span class="dt">data=</span>Headache)</a>
<a class="sourceLine" id="cb777-2" title="2"><span class="kw">summary</span>(head1)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1 + treatment, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9085 -0.9551 -0.3118  1.1141 10.5364 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)       0.80918    0.50095   1.615    0.110
## du1               0.83705    0.05176  16.172   &lt;2e-16
## treatmentT2       0.07692    0.62622   0.123    0.903
## treatmentT3       0.80919    0.59271   1.365    0.175
## treatmentControl -0.55752    0.61830  -0.902    0.370
## 
## Residual standard error: 2.14 on 93 degrees of freedom
## Multiple R-squared:  0.7511, Adjusted R-squared:  0.7404 
## F-statistic: 70.16 on 4 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The complete estimated regression model is</p>
<p><span class="math display">\[\widehat{\text{du2}}_i=0.809+0.837\cdot\text{du1}_i +0.077I_{\text{T2},i}+0.809I_{\text{T3},i}-0.558I_{\text{Control},i}\ .\]</span></p>
<p>For each group, the model simplifies to an SLR as follows:</p>
<ul>
<li>For <em>T1</em> (baseline):</li>
</ul>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i &amp;=0.809+0.837\cdot\text{du1}_i +0.077I_{\text{T2},i}+0.809I_{\text{T3},i}-0.558I_{\text{Control},i} \\
&amp;= 0.809+0.837\cdot\text{du1}_i+0.077*0+0.809*0-0.558*0 \\
&amp;= 0.809+0.837\cdot\text{du1}_i.
\end{array}\]</span></p>
<ul>
<li>For <em>T2</em>:</li>
</ul>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i &amp;=0.809+0.837\cdot\text{du1}_i+0.077I_{\text{T2},i}+0.809I_{\text{T3},i}-0.558I_{\text{Control},i} \\
&amp;= 0.809+0.837\cdot\text{du1}_i+0.077*1+0.809*0-0.558*0 \\
&amp;= 0.809+0.837\cdot\text{du1}_i + 0.077 \\
&amp;= 0.886+0.837\cdot\text{du1}_i.
\end{array}\]</span></p>

<ul>
<li>Similarly for <em>T3</em>:</li>
</ul>
<p><span class="math display">\[\widehat{\text{du2}}_i = 1.618 + 0.837\cdot\text{du1}_i\ .\]</span></p>
<ul>
<li>Finally, for <em>Control</em>:</li>
</ul>
<p><span class="math display">\[\widehat{\text{du2}}_i = 0.251 + 0.837\cdot\text{du1}_i\ .\]</span></p>
<p>To reinforce what this additive model is doing, Figure <a href="8-10-section8-10.html#fig:Figure8-22">2.171</a>
displays the estimated regression lines for all four
groups, showing the shifts in the <em>y</em>-intercepts among the groups.
</p>

<div class="figure"><span id="fig:Figure8-22"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-22-1.png" alt="Plot of estimated noise tolerance additive model." width="960" />
<p class="caption">
Figure 2.171: Plot of estimated noise tolerance additive model.
</p>
</div>
<p>The term-plot (Figure <a href="8-10-section8-10.html#fig:Figure8-23">2.172</a>) shows how the <em>T3</em> group
seems to have shifted up the most relative to
the others and the <em>Control</em> group seems to be noticeably lower than the others,
in the model that otherwise assumes that the same relationship holds between
<code>du1</code> and <code>du2</code> for all the groups. After controlling for the <em>Treatment</em>
group, for a 1 decibel increase in initial tolerances, we expect, on average,
to obtain a 0.84 decibel change in the second tolerance measurement. The
<strong><em>R</em></strong><sup>2</sup> shows that this is a decent model for the responses, with
this model explaining 75.1% percent of the
variation in the second decibel tolerance measure. We should check the
diagnostic plots and VIFs to check for any issues – all the diagnostics and
assumptions are as before except that there is no assumption of linearity
between the grouping variable and the responses.

Additionally, sometimes we
need to add group information to diagnostics to see if any patterns in residuals look
different in different groups, like linearity or non-constant variance.</p>

<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb779-1" title="1"><span class="kw">plot</span>(<span class="kw">allEffects</span>(head1, <span class="dt">residuals=</span>T))</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-23"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-23-1.png" alt="Term-plots of the additive decibel tolerance model." width="576" />
<p class="caption">
Figure 2.172: Term-plots of the additive decibel tolerance model.
</p>
</div>
<p>The diagnostic plots in Figure <a href="8-10-section8-10.html#fig:Figure8-24">2.173</a> provides some
indications of a few observations in the tails that deviate from a normal
distribution to having slightly heavier tails but
only one outlier is of real concern. There is a small indication of increasing
variability as a function of the fitted values as both the Residuals vs. Fitted
and Scale-Location plots show some fanning out for higher values but this is a
minor issue. There are no influential points in the data set. </p>

<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb780-1" title="1"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">oma=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</a>
<a class="sourceLine" id="cb780-2" title="2"><span class="kw">plot</span>(head1,</a>
<a class="sourceLine" id="cb780-3" title="3">     <span class="dt">sub.caption=</span><span class="st">&quot;Plot of diagnostics for additive model with du1 and treatment for du2&quot;</span>)</a></code></pre></div>
<div class="figure"><span id="fig:Figure8-24"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-24-1.png" alt="Diagnostic plots for the additive decibel tolerance model." width="960" />
<p class="caption">
Figure 2.173: Diagnostic plots for the additive decibel tolerance model.
</p>
</div>
<p>The VIFs are different for categorical variables than for quantitative
predictors in MLR. The 4 levels
are combined in a measure called the <strong><em>generalized VIF (GVIF)</em></strong>. For GVIFs,
we only focus on the inflation of the SE scale (square root for 1 df effects
and raised to the power <span class="math inline">\(1/(2*J)\)</span> for a <span class="math inline">\(J\)</span>-level predictor). On this scale,
the interpretation is as <strong>the multiplicative increase in the SEs for the coefficients on all the indicator variables due to
multicolinearity with other predictors</strong>. In this model, the SE for <code>du1</code> is
1.009 times larger due to multicollinearity with other predictors
and the SEs for the indicator variables are 1.003 times larger due to multicollinearity than they otherwise
would have been. Neither are large so multicollinearity is not a problem in
this model.</p>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb781-1" title="1"><span class="kw">vif</span>(head1)</a></code></pre></div>
<pre><code>##              GVIF Df GVIF^(1/(2*Df))
## du1       1.01786  1        1.008891
## treatment 1.01786  3        1.002955</code></pre>
<p>While there are inferences available in the model output, the tests for the
indicator variables are not too informative since they only compare each group
to the baseline. In Section <a href="8-12-section8-12.html#section8-12">8.12</a>, we see how to use ANOVA
<em>F</em>-tests to help us ask general questions about including a categorical predictor in the
model. But we can compare adjusted <strong><em>R</em></strong><sup>2</sup> values with and without
<em>Treatment</em> to see if including the categorical variable was “worth
it”:</p>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb783-1" title="1">head1R &lt;-<span class="st"> </span><span class="kw">lm</span>(du2<span class="op">~</span>du1, <span class="dt">data=</span>Headache)</a></code></pre></div>

<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb784-1" title="1"><span class="kw">summary</span>(head1R)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9887 -0.8820 -0.2765  1.1529 10.4165 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.84744    0.36045   2.351   0.0208
## du1          0.85142    0.05189  16.408   &lt;2e-16
## 
## Residual standard error: 2.165 on 96 degrees of freedom
## Multiple R-squared:  0.7371, Adjusted R-squared:  0.7344 
## F-statistic: 269.2 on 1 and 96 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The adjusted <strong><em>R</em></strong><sup>2</sup> in the model with both <em>Treatment</em> and <em>du1</em> is
0.7404 and the adjusted <em>R</em><sup>2</sup> for this reduced model with just <em>du1</em> is 0.7344,
suggesting the <em>Treatment</em> is useful. The next section
provides a technique to be able to work with different slopes on the
quantitative predictor for each group. Comparing those results to the results
for the additive model allows assessment of the assumption in this section that
all the groups had the same slope coefficient for the quantitative variable.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-heplots">
<p>Fox, John, and Michael Friendly. 2018. <em>Heplots: Visualizing Hypothesis Tests in Multivariate Linear Models</em>. <a href="https://CRAN.R-project.org/package=heplots">https://CRAN.R-project.org/package=heplots</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="129">
<li id="fn129"><p>Models like this with a categorical variable and quantitative variable are often called <em>ANCOVA</em> or <em>analysis of covariance</em> models but really are just versions of our linear models we’ve been using throughout this material.<a href="8-10-section8-10.html#fnref129" class="footnote-back">↩</a></p></li>
<li id="fn130"><p>Note that we employed some specific options in the <code>legend</code> option to get the legend to fit on this scatterplot better. Usually you can avoid this but the <code>coords</code> option defined a location and the <code>columns</code> option made it a two column legend.<a href="8-10-section8-10.html#fnref130" class="footnote-back">↩</a></p></li>
</ol>
</div>
<p style="text-align: center;">
<a href="8-9-section8-9.html"><button class="btn btn-default">Previous</button></a>
<a href="8-11-section8-11.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
