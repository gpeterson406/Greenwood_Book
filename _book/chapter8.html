<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Multiple linear regression | Intermediate Statistics with R</title>
  <meta name="description" content="Chapter 8 Multiple linear regression | Intermediate Statistics with R" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Multiple linear regression | Intermediate Statistics with R" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="gpeterson406/Greenwood_Book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Multiple linear regression | Intermediate Statistics with R" />
  
  
  

<meta name="author" content="Mark C Greenwood" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter7.html"/>
<link rel="next" href="chapter9.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Intermediate Statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="1" data-path="chapter1.html"><a href="chapter1.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="1.1" data-path="chapter1.html"><a href="chapter1.html#section1-1"><i class="fa fa-check"></i><b>1.1</b> Overview of methods</a></li>
<li class="chapter" data-level="1.2" data-path="chapter1.html"><a href="chapter1.html#section1-2"><i class="fa fa-check"></i><b>1.2</b> Getting started in R</a></li>
<li class="chapter" data-level="1.3" data-path="chapter1.html"><a href="chapter1.html#section1-3"><i class="fa fa-check"></i><b>1.3</b> Basic summary statistics, histograms, and boxplots using R</a></li>
<li class="chapter" data-level="1.4" data-path="chapter1.html"><a href="chapter1.html#section1-4"><i class="fa fa-check"></i><b>1.4</b> R Markdown</a></li>
<li class="chapter" data-level="1.5" data-path="chapter1.html"><a href="chapter1.html#section1-5"><i class="fa fa-check"></i><b>1.5</b> Grammar of Graphics</a></li>
<li class="chapter" data-level="1.6" data-path="chapter1.html"><a href="chapter1.html#section1-6"><i class="fa fa-check"></i><b>1.6</b> Exiting RStudio</a></li>
<li class="chapter" data-level="1.7" data-path="chapter1.html"><a href="chapter1.html#section1-7"><i class="fa fa-check"></i><b>1.7</b> Chapter summary</a></li>
<li class="chapter" data-level="1.8" data-path="chapter1.html"><a href="chapter1.html#section1-8"><i class="fa fa-check"></i><b>1.8</b> Summary of important R code</a></li>
<li class="chapter" data-level="1.9" data-path="chapter1.html"><a href="chapter1.html#section1-9"><i class="fa fa-check"></i><b>1.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter2.html"><a href="chapter2.html"><i class="fa fa-check"></i><b>2</b> (R)e-Introduction to statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter2.html"><a href="chapter2.html#section2-1"><i class="fa fa-check"></i><b>2.1</b> Data wrangling and density curves</a></li>
<li class="chapter" data-level="2.2" data-path="chapter2.html"><a href="chapter2.html#section2-2"><i class="fa fa-check"></i><b>2.2</b> Pirate-plots</a></li>
<li class="chapter" data-level="2.3" data-path="chapter2.html"><a href="chapter2.html#section2-3"><i class="fa fa-check"></i><b>2.3</b> Models, hypotheses, and permutations for the two sample mean situation</a></li>
<li class="chapter" data-level="2.4" data-path="chapter2.html"><a href="chapter2.html#section2-4"><i class="fa fa-check"></i><b>2.4</b> Permutation testing for the two sample mean situation</a></li>
<li class="chapter" data-level="2.5" data-path="chapter2.html"><a href="chapter2.html#section2-5"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing (general)</a></li>
<li class="chapter" data-level="2.6" data-path="chapter2.html"><a href="chapter2.html#section2-6"><i class="fa fa-check"></i><b>2.6</b> Connecting randomization (nonparametric) and parametric tests</a></li>
<li class="chapter" data-level="2.7" data-path="chapter2.html"><a href="chapter2.html#section2-7"><i class="fa fa-check"></i><b>2.7</b> Second example of permutation tests</a></li>
<li class="chapter" data-level="2.8" data-path="chapter2.html"><a href="chapter2.html#section2-8"><i class="fa fa-check"></i><b>2.8</b> Reproducibility Crisis: Moving beyond p &lt; 0.05, publication bias, and multiple testing issues</a></li>
<li class="chapter" data-level="2.9" data-path="chapter2.html"><a href="chapter2.html#section2-9"><i class="fa fa-check"></i><b>2.9</b> Confidence intervals and bootstrapping</a></li>
<li class="chapter" data-level="2.10" data-path="chapter2.html"><a href="chapter2.html#section2-10"><i class="fa fa-check"></i><b>2.10</b> Bootstrap confidence intervals for difference in GPAs</a></li>
<li class="chapter" data-level="2.11" data-path="chapter2.html"><a href="chapter2.html#section2-11"><i class="fa fa-check"></i><b>2.11</b> Chapter summary</a></li>
<li class="chapter" data-level="2.12" data-path="chapter2.html"><a href="chapter2.html#section2-12"><i class="fa fa-check"></i><b>2.12</b> Summary of important R code</a></li>
<li class="chapter" data-level="2.13" data-path="chapter2.html"><a href="chapter2.html#section2-13"><i class="fa fa-check"></i><b>2.13</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter3.html"><a href="chapter3.html"><i class="fa fa-check"></i><b>3</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter3.html"><a href="chapter3.html#section3-1"><i class="fa fa-check"></i><b>3.1</b> Situation</a></li>
<li class="chapter" data-level="3.2" data-path="chapter3.html"><a href="chapter3.html#section3-2"><i class="fa fa-check"></i><b>3.2</b> Linear model for One-Way ANOVA (cell means and reference-coding)</a></li>
<li class="chapter" data-level="3.3" data-path="chapter3.html"><a href="chapter3.html#section3-3"><i class="fa fa-check"></i><b>3.3</b> One-Way ANOVA Sums of Squares, Mean Squares, and F-test</a></li>
<li class="chapter" data-level="3.4" data-path="chapter3.html"><a href="chapter3.html#section3-4"><i class="fa fa-check"></i><b>3.4</b> ANOVA model diagnostics including QQ-plots</a></li>
<li class="chapter" data-level="3.5" data-path="chapter3.html"><a href="chapter3.html#section3-5"><i class="fa fa-check"></i><b>3.5</b> Guinea pig tooth growth One-Way ANOVA example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter3.html"><a href="chapter3.html#section3-6"><i class="fa fa-check"></i><b>3.6</b> Multiple (pair-wise) comparisons using Tukey’s HSD and the compact letter display</a></li>
<li class="chapter" data-level="3.7" data-path="chapter3.html"><a href="chapter3.html#section3-7"><i class="fa fa-check"></i><b>3.7</b> Pair-wise comparisons for the Overtake data</a></li>
<li class="chapter" data-level="3.8" data-path="chapter3.html"><a href="chapter3.html#section3-8"><i class="fa fa-check"></i><b>3.8</b> Chapter summary</a></li>
<li class="chapter" data-level="3.9" data-path="chapter3.html"><a href="chapter3.html#section3-9"><i class="fa fa-check"></i><b>3.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="3.10" data-path="chapter3.html"><a href="chapter3.html#section3-10"><i class="fa fa-check"></i><b>3.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter4.html"><a href="chapter4.html"><i class="fa fa-check"></i><b>4</b> Two-Way ANOVA</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter4.html"><a href="chapter4.html#section4-1"><i class="fa fa-check"></i><b>4.1</b> Situation</a></li>
<li class="chapter" data-level="4.2" data-path="chapter4.html"><a href="chapter4.html#section4-2"><i class="fa fa-check"></i><b>4.2</b> Designing a two-way experiment and visualizing results</a></li>
<li class="chapter" data-level="4.3" data-path="chapter4.html"><a href="chapter4.html#section4-3"><i class="fa fa-check"></i><b>4.3</b> Two-Way ANOVA models and hypothesis tests</a></li>
<li class="chapter" data-level="4.4" data-path="chapter4.html"><a href="chapter4.html#section4-4"><i class="fa fa-check"></i><b>4.4</b> Guinea pig tooth growth analysis with Two-Way ANOVA</a></li>
<li class="chapter" data-level="4.5" data-path="chapter4.html"><a href="chapter4.html#section4-5"><i class="fa fa-check"></i><b>4.5</b> Observational study example: The Psychology of Debt</a></li>
<li class="chapter" data-level="4.6" data-path="chapter4.html"><a href="chapter4.html#section4-6"><i class="fa fa-check"></i><b>4.6</b> Pushing Two-Way ANOVA to the limit: Un-replicated designs and Estimability</a></li>
<li class="chapter" data-level="4.7" data-path="chapter4.html"><a href="chapter4.html#section4-7"><i class="fa fa-check"></i><b>4.7</b> Chapter summary</a></li>
<li class="chapter" data-level="4.8" data-path="chapter4.html"><a href="chapter4.html#section4-8"><i class="fa fa-check"></i><b>4.8</b> Summary of important R code</a></li>
<li class="chapter" data-level="4.9" data-path="chapter4.html"><a href="chapter4.html#section4-9"><i class="fa fa-check"></i><b>4.9</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter5.html"><a href="chapter5.html"><i class="fa fa-check"></i><b>5</b> Chi-square tests</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter5.html"><a href="chapter5.html#section5-1"><i class="fa fa-check"></i><b>5.1</b> Situation, contingency tables, and tableplots</a></li>
<li class="chapter" data-level="5.2" data-path="chapter5.html"><a href="chapter5.html#section5-2"><i class="fa fa-check"></i><b>5.2</b> Homogeneity test hypotheses</a></li>
<li class="chapter" data-level="5.3" data-path="chapter5.html"><a href="chapter5.html#section5-3"><i class="fa fa-check"></i><b>5.3</b> Independence test hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="chapter5.html"><a href="chapter5.html#section5-4"><i class="fa fa-check"></i><b>5.4</b> Models for R by C tables</a></li>
<li class="chapter" data-level="5.5" data-path="chapter5.html"><a href="chapter5.html#section5-5"><i class="fa fa-check"></i><b>5.5</b> Permutation tests for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.6" data-path="chapter5.html"><a href="chapter5.html#section5-6"><i class="fa fa-check"></i><b>5.6</b> Chi-square distribution for the <span class="math inline">\(X^2\)</span> statistic</a></li>
<li class="chapter" data-level="5.7" data-path="chapter5.html"><a href="chapter5.html#section5-7"><i class="fa fa-check"></i><b>5.7</b> Examining residuals for the source of differences</a></li>
<li class="chapter" data-level="5.8" data-path="chapter5.html"><a href="chapter5.html#section5-8"><i class="fa fa-check"></i><b>5.8</b> General protocol for <span class="math inline">\(X^2\)</span> tests</a></li>
<li class="chapter" data-level="5.9" data-path="chapter5.html"><a href="chapter5.html#section5-9"><i class="fa fa-check"></i><b>5.9</b> Political party and voting results: Complete analysis</a></li>
<li class="chapter" data-level="5.10" data-path="chapter5.html"><a href="chapter5.html#section5-10"><i class="fa fa-check"></i><b>5.10</b> Is cheating and lying related in students?</a></li>
<li class="chapter" data-level="5.11" data-path="chapter5.html"><a href="chapter5.html#section5-11"><i class="fa fa-check"></i><b>5.11</b> Analyzing a stratified random sample of California schools</a></li>
<li class="chapter" data-level="5.12" data-path="chapter5.html"><a href="chapter5.html#section5-12"><i class="fa fa-check"></i><b>5.12</b> Chapter summary</a></li>
<li class="chapter" data-level="5.13" data-path="chapter5.html"><a href="chapter5.html#section5-13"><i class="fa fa-check"></i><b>5.13</b> Summary of important R commands</a></li>
<li class="chapter" data-level="5.14" data-path="chapter5.html"><a href="chapter5.html#section5-14"><i class="fa fa-check"></i><b>5.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter6.html"><a href="chapter6.html"><i class="fa fa-check"></i><b>6</b> Correlation and Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="chapter6.html"><a href="chapter6.html#section6-1"><i class="fa fa-check"></i><b>6.1</b> Relationships between two quantitative variables</a></li>
<li class="chapter" data-level="6.2" data-path="chapter6.html"><a href="chapter6.html#section6-2"><i class="fa fa-check"></i><b>6.2</b> Estimating the correlation coefficient</a></li>
<li class="chapter" data-level="6.3" data-path="chapter6.html"><a href="chapter6.html#section6-3"><i class="fa fa-check"></i><b>6.3</b> Relationships between variables by groups</a></li>
<li class="chapter" data-level="6.4" data-path="chapter6.html"><a href="chapter6.html#section6-4"><i class="fa fa-check"></i><b>6.4</b> Inference for the correlation coefficient</a></li>
<li class="chapter" data-level="6.5" data-path="chapter6.html"><a href="chapter6.html#section6-5"><i class="fa fa-check"></i><b>6.5</b> Are tree diameters related to tree heights?</a></li>
<li class="chapter" data-level="6.6" data-path="chapter6.html"><a href="chapter6.html#section6-6"><i class="fa fa-check"></i><b>6.6</b> Describing relationships with a regression model</a></li>
<li class="chapter" data-level="6.7" data-path="chapter6.html"><a href="chapter6.html#section6-7"><i class="fa fa-check"></i><b>6.7</b> Least Squares Estimation</a></li>
<li class="chapter" data-level="6.8" data-path="chapter6.html"><a href="chapter6.html#section6-8"><i class="fa fa-check"></i><b>6.8</b> Measuring the strength of regressions: R<sup>2</sup></a></li>
<li class="chapter" data-level="6.9" data-path="chapter6.html"><a href="chapter6.html#section6-9"><i class="fa fa-check"></i><b>6.9</b> Outliers: leverage and influence</a></li>
<li class="chapter" data-level="6.10" data-path="chapter6.html"><a href="chapter6.html#section6-10"><i class="fa fa-check"></i><b>6.10</b> Residual diagnostics – setting the stage for inference</a></li>
<li class="chapter" data-level="6.11" data-path="chapter6.html"><a href="chapter6.html#section6-11"><i class="fa fa-check"></i><b>6.11</b> Old Faithful discharge and waiting times</a></li>
<li class="chapter" data-level="6.12" data-path="chapter6.html"><a href="chapter6.html#section6-12"><i class="fa fa-check"></i><b>6.12</b> Chapter summary</a></li>
<li class="chapter" data-level="6.13" data-path="chapter6.html"><a href="chapter6.html#section6-13"><i class="fa fa-check"></i><b>6.13</b> Summary of important R code</a></li>
<li class="chapter" data-level="6.14" data-path="chapter6.html"><a href="chapter6.html#section6-14"><i class="fa fa-check"></i><b>6.14</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter7.html"><a href="chapter7.html"><i class="fa fa-check"></i><b>7</b> Simple linear regression inference</a>
<ul>
<li class="chapter" data-level="7.1" data-path="chapter7.html"><a href="chapter7.html#section7-1"><i class="fa fa-check"></i><b>7.1</b> Model</a></li>
<li class="chapter" data-level="7.2" data-path="chapter7.html"><a href="chapter7.html#section7-2"><i class="fa fa-check"></i><b>7.2</b> Confidence interval and hypothesis tests for the slope and intercept</a></li>
<li class="chapter" data-level="7.3" data-path="chapter7.html"><a href="chapter7.html#section7-3"><i class="fa fa-check"></i><b>7.3</b> Bozeman temperature trend</a></li>
<li class="chapter" data-level="7.4" data-path="chapter7.html"><a href="chapter7.html#section7-4"><i class="fa fa-check"></i><b>7.4</b> Randomization-based inferences for the slope coefficient</a></li>
<li class="chapter" data-level="7.5" data-path="chapter7.html"><a href="chapter7.html#section7-5"><i class="fa fa-check"></i><b>7.5</b> Transformations part I: Linearizing relationships</a></li>
<li class="chapter" data-level="7.6" data-path="chapter7.html"><a href="chapter7.html#section7-6"><i class="fa fa-check"></i><b>7.6</b> Transformations part II: Impacts on SLR interpretations: log(y), log(x), &amp; both log(y) &amp; log(x)</a></li>
<li class="chapter" data-level="7.7" data-path="chapter7.html"><a href="chapter7.html#section7-7"><i class="fa fa-check"></i><b>7.7</b> Confidence interval for the mean and prediction intervals for a new observation</a></li>
<li class="chapter" data-level="7.8" data-path="chapter7.html"><a href="chapter7.html#section7-8"><i class="fa fa-check"></i><b>7.8</b> Chapter summary</a></li>
<li class="chapter" data-level="7.9" data-path="chapter7.html"><a href="chapter7.html#section7-9"><i class="fa fa-check"></i><b>7.9</b> Summary of important R code</a></li>
<li class="chapter" data-level="7.10" data-path="chapter7.html"><a href="chapter7.html#section7-10"><i class="fa fa-check"></i><b>7.10</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter8.html"><a href="chapter8.html"><i class="fa fa-check"></i><b>8</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="chapter8.html"><a href="chapter8.html#section8-1"><i class="fa fa-check"></i><b>8.1</b> Going from SLR to MLR</a></li>
<li class="chapter" data-level="8.2" data-path="chapter8.html"><a href="chapter8.html#section8-2"><i class="fa fa-check"></i><b>8.2</b> Validity conditions in MLR</a></li>
<li class="chapter" data-level="8.3" data-path="chapter8.html"><a href="chapter8.html#section8-3"><i class="fa fa-check"></i><b>8.3</b> Interpretation of MLR terms</a></li>
<li class="chapter" data-level="8.4" data-path="chapter8.html"><a href="chapter8.html#section8-4"><i class="fa fa-check"></i><b>8.4</b> Comparing multiple regression models</a></li>
<li class="chapter" data-level="8.5" data-path="chapter8.html"><a href="chapter8.html#section8-5"><i class="fa fa-check"></i><b>8.5</b> General recommendations for MLR interpretations and VIFs</a></li>
<li class="chapter" data-level="8.6" data-path="chapter8.html"><a href="chapter8.html#section8-6"><i class="fa fa-check"></i><b>8.6</b> MLR inference: Parameter inferences using the t-distribution</a></li>
<li class="chapter" data-level="8.7" data-path="chapter8.html"><a href="chapter8.html#section8-7"><i class="fa fa-check"></i><b>8.7</b> Overall F-test in multiple linear regression</a></li>
<li class="chapter" data-level="8.8" data-path="chapter8.html"><a href="chapter8.html#section8-8"><i class="fa fa-check"></i><b>8.8</b> Case study: First year college GPA and SATs</a></li>
<li class="chapter" data-level="8.9" data-path="chapter8.html"><a href="chapter8.html#section8-9"><i class="fa fa-check"></i><b>8.9</b> Different intercepts for different groups: MLR with indicator variables</a></li>
<li class="chapter" data-level="8.10" data-path="chapter8.html"><a href="chapter8.html#section8-10"><i class="fa fa-check"></i><b>8.10</b> Additive MLR with more than two groups: Headache example</a></li>
<li class="chapter" data-level="8.11" data-path="chapter8.html"><a href="chapter8.html#section8-11"><i class="fa fa-check"></i><b>8.11</b> Different slopes and different intercepts</a></li>
<li class="chapter" data-level="8.12" data-path="chapter8.html"><a href="chapter8.html#section8-12"><i class="fa fa-check"></i><b>8.12</b> F-tests for MLR models with quantitative and categorical variables and interactions</a></li>
<li class="chapter" data-level="8.13" data-path="chapter8.html"><a href="chapter8.html#section8-13"><i class="fa fa-check"></i><b>8.13</b> AICs for model selection</a></li>
<li class="chapter" data-level="8.14" data-path="chapter8.html"><a href="chapter8.html#section8-14"><i class="fa fa-check"></i><b>8.14</b> Case study: Forced expiratory volume model selection using AICs</a></li>
<li class="chapter" data-level="8.15" data-path="chapter8.html"><a href="chapter8.html#section8-15"><i class="fa fa-check"></i><b>8.15</b> Chapter summary</a></li>
<li class="chapter" data-level="8.16" data-path="chapter8.html"><a href="chapter8.html#section8-16"><i class="fa fa-check"></i><b>8.16</b> Summary of important R code</a></li>
<li class="chapter" data-level="8.17" data-path="chapter8.html"><a href="chapter8.html#section8-17"><i class="fa fa-check"></i><b>8.17</b> Practice problems</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapter9.html"><a href="chapter9.html"><i class="fa fa-check"></i><b>9</b> Case studies</a>
<ul>
<li class="chapter" data-level="9.1" data-path="chapter9.html"><a href="chapter9.html#section9-1"><i class="fa fa-check"></i><b>9.1</b> Overview of material covered</a></li>
<li class="chapter" data-level="9.2" data-path="chapter9.html"><a href="chapter9.html#section9-2"><i class="fa fa-check"></i><b>9.2</b> The impact of simulated chronic nitrogen deposition on the biomass and N2-fixation activity of two boreal feather moss–cyanobacteria associations</a></li>
<li class="chapter" data-level="9.3" data-path="chapter9.html"><a href="chapter9.html#section9-3"><i class="fa fa-check"></i><b>9.3</b> Ants learn to rely on more informative attributes during decision-making</a></li>
<li class="chapter" data-level="9.4" data-path="chapter9.html"><a href="chapter9.html#section9-4"><i class="fa fa-check"></i><b>9.4</b> Multi-variate models are essential for understanding vertebrate diversification in deep time</a></li>
<li class="chapter" data-level="9.5" data-path="chapter9.html"><a href="chapter9.html#section9-5"><i class="fa fa-check"></i><b>9.5</b> What do didgeridoos really do about sleepiness?</a></li>
<li class="chapter" data-level="9.6" data-path="chapter9.html"><a href="chapter9.html#section9-6"><i class="fa fa-check"></i><b>9.6</b> General summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Intermediate Statistics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter8" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Multiple linear regression</h1>
<div id="section8-1" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Going from SLR to MLR</h2>
<p>In many situations, especially in observational studies, it is unlikely that
the system is simple enough to be characterized
by a single predictor variable. In experiments, if we randomly assign levels of
a predictor variable we can assume that the impacts of other variables cancel
out as a direct result of the random assignment.

But it is possible even in
these experimental situations that we can “improve” our model for the response
variable by adding additional predictor variables that explain additional
variation in the responses, reducing the amount of unexplained variation. This
can allow more precise inferences to be generated from the model. As mentioned
previously, it might be useful to know the sex or weight of the subjects in the
Beers vs BAC study to account for more of the variation in the responses – this
idea motivates our final topic: <strong><em>multiple linear regression</em></strong> (<strong>MLR</strong>)
models.



In observational studies,
we can think of a suite of characteristics of observations that might be
related to a response variable. For example, consider a study of yearly
salaries and variables that might explain the amount people get paid. We might
be most interested in seeing how incomes change based on age, but it would be
hard to ignore potential differences based on sex and education level. Trying
to explain incomes would likely require more than one predictor variable and we
wouldn’t be able to explain all the variability in the responses just based on
gender and education level, but a model using those variables might still
provide some useful information about each component and about age impacts on
income after we adjust (control) for sex and education. The extension to MLR
allows us to incorporate multiple predictors into a regression model.

Geometrically, this is a way of relating many different dimensions (number of
<span class="math inline">\(x\text{&#39;s}\)</span>) to what happened in a single response variable (one dimension).</p>
<p>We start with the same model as in SLR except now we allow <span class="math inline">\(K\)</span> different
<span class="math inline">\(x\text{&#39;s}\)</span>:
</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i}+ \ldots + \beta_Kx_{Ki}
+ \varepsilon_i\]</span></p>
<p>Note that if <span class="math inline">\(K = 1\)</span>, we are back to SLR. In the MLR model, there are <span class="math inline">\(K\)</span>
predictors and we still have a
<span class="math inline">\(y\)</span>-intercept.

The MLR model carries the same assumptions as an SLR model with a
couple of slight tweaks specific to MLR (see Section <a href="chapter8.html#section8-2">8.2</a>
for the details on the changes to the validity conditions).</p>
<div style="page-break-after: always;"></div>
<p>We are able to use the
least squares criterion for estimating the regression coefficients in MLR, but
the mathematics are beyond the scope of this course.

The <code>lm</code> function takes
care of finding the least squares coefficients using a very sophisticated
algorithm<a href="#fn131" class="footnote-ref" id="fnref131"><sup>131</sup></a>. The estimated
regression equation it returns is:</p>
<p><span class="math display">\[\widehat{y}_i = b_0 + b_1x_{1i} +b_2x_{2i}+\ldots+b_Kx_{Ki}\]</span></p>
<p>where each <span class="math inline">\(b_k\)</span> estimates its corresponding parameter <span class="math inline">\(\beta_k\)</span>.</p>
<p>An example of snow depths at some high elevation locations in Montana on a day in
April provides a nice motivation for these methods. A random sample of
<span class="math inline">\(n = 25\)</span> Montana locations (from the population of <span class="math inline">\(N = 85\)</span> at the time) were obtained
from the Natural Resources Conversation Service’s website
(<a href="http://www.wcc.nrcs.usda.gov/snotel/Montana/montana.html" class="uri">http://www.wcc.nrcs.usda.gov/snotel/Montana/montana.html</a>) a few years ago.
Information on the snow depth (<code>Snow.Depth</code>) in inches, daily Minimum and
Maximum Temperatures (<code>Min.Temp</code> and <code>Max.Temp</code>) in <span class="math inline">\(^\circ F\)</span> and
elevation of the site (<code>Elevation</code>) in feet. A snow science researcher (or
spring back-country skier) might be interested in understanding <em>Snow depth</em>
as a function of <em>Minimum Temperature</em>, <em>Maximum Temperature</em>, and <em>Elevation</em>.
One might assume that colder
and higher places will have more snow, but using just one of the predictor
variables might leave out some important predictive information. The following
code loads the data set and makes the scatterplot matrix
(Figure <a href="chapter8.html#fig:Figure8-1">8.1</a>) to allow
some preliminary assessment of the pairwise relationships.</p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="chapter8.html#cb710-1" aria-hidden="true" tabindex="-1"></a>snotel_s <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/snotel_s.csv&quot;</span>)</span></code></pre></div>

<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="chapter8.html#cb711-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GGally)</span>
<span id="cb711-2"><a href="chapter8.html#cb711-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Reorder columns slightly and only plot quantitative variables using &quot;columns = ...&quot;</span></span>
<span id="cb711-3"><a href="chapter8.html#cb711-3" aria-hidden="true" tabindex="-1"></a>snotel_s <span class="sc">%&gt;%</span> <span class="fu">ggpairs</span>(<span class="at">columns =</span> <span class="fu">c</span>(<span class="dv">4</span><span class="sc">:</span><span class="dv">6</span>,<span class="dv">3</span>)) <span class="sc">+</span> </span>
<span id="cb711-4"><a href="chapter8.html#cb711-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-1"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-1-1.png" alt="Scatterplot matrix of data from a sample of SNOTEL sites in April on four variables. " width="75%" />
<p class="caption">
Figure 8.1: Scatterplot matrix of data from a sample of SNOTEL sites in April on four variables. 
</p>
</div>
<p>It appears that there are many strong linear relationships between the variables,
with <em>Elevation</em> and <em>Snow Depth</em> having the largest magnitude, <strong><em>r</em></strong> = 0.80.
Higher temperatures seem to be associated with less snow – not a big surprise so
far! There might be an outlier at an elevation of 7400 feet and a snow depth
below 10 inches that we should explore further.</p>
<p>A new issue arises in attempting to build MLR models called
<strong><em>multicollinearity</em></strong>.  Again, it is a not surprise
that temperature and elevation are correlated but that creates a
problem if we try to put them both into a model to explain snow depth. Is it
the elevation, temperature, or the combination of both that matters for getting
and retaining more snow? <strong>Correlation between predictor variables</strong> is called
multicollinearity and <strong>makes estimation and interpretation of MLR models more
complicated than in SLR</strong>. Section <a href="chapter8.html#section8-5">8.5</a> deals with this issue
directly and discusses methods
for detecting its presence. For now, remember that in MLR this issue sometimes
makes it difficult to disentangle the impacts of different predictor variables
on the response when the predictors share information – when they are
correlated.</p>
<p>To get familiar with this example, we can start with fitting some
potential SLR
models and plotting the estimated models. Figure <a href="chapter8.html#fig:Figure8-2">8.2</a> contains
the result for the SLR using <em>Elevation</em> and results for two temperature based
models are in Figures <a href="chapter8.html#fig:Figure8-3">8.3</a> and <a href="chapter8.html#fig:Figure8-4">8.4</a>.
<em>Snow Depth</em> is selected as the
obvious response variable both due to skier interest and potential scientific
causation (snow can’t change elevation but elevation could be the driver of
snow deposition and retention).</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-2"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-2-1.png" alt="Plot of the estimated SLR model for Snow Depth with Elevation as the predictor along with observations and smoothing line generated by the residuals = T option being specified. " width="75%" />
<p class="caption">
Figure 8.2: Plot of the estimated SLR model for Snow Depth with Elevation as the predictor along with observations and smoothing line generated by the <code>residuals = T</code> option being specified. 
</p>
</div>
<!-- \newpage -->
<p>Based on the model summaries provided below, the three estimated SLR models
are:</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_i &amp; = -72.006 + 0.0163\cdot\text{Elevation}_i, \\
\widehat{\text{SnowDepth}}_i &amp; = 174.096 - 4.884\cdot\text{MinTemp}_i,\text{ and} \\
\widehat{\text{SnowDepth}}_i &amp; = 122.672 - 2.284\cdot\text{MaxTemp}_i.
\end{array}\]</span></p>
<p>The term-plots of the estimated models reinforce
our expected results, showing a positive change in <em>Snow Depth</em> for higher
<em>Elevations</em> and negative impacts for increasing temperatures on <em>Snow Depth</em>.
These plots are made across the observed range<a href="#fn132" class="footnote-ref" id="fnref132"><sup>132</sup></a> of the predictor
variable and help us to get a sense of the total impacts of
predictors. For example, for elevation in Figure <a href="chapter8.html#fig:Figure8-2">8.2</a>, the
smallest observed
value was 4925 feet and the largest was 8300 feet. The regression line goes
from estimating a mean snow depth of 8 inches to 63 inches. That gives you some
practical idea of the size of the estimated <em>Snow Depth</em> change for the changes in
<em>Elevation</em> observed in the data. Putting this together, we can say that
there was around a
55 inch change in predicted snow depths for a close to 3400 foot increase in
elevation. This helps make the slope coefficient of 0.0163 in the model more
easily understood.</p>
<p>Remember that in SLR, the range of <span class="math inline">\(x\)</span> matters just as much
as the units of <span class="math inline">\(x\)</span> in determining the practical importance and size of the slope
coefficient. A value of 0.0163 looks small but is actually at the heart of a
pretty interesting model for predicting snow depth. A one foot change of elevation is
“tiny” here relative to changes in the response so the slope coefficient can be
small and still amount to big changes in the predicted response across the range
of values of <span class="math inline">\(x\)</span>. If the <em>Elevation</em> had been recorded in thousands of feet,
then the slope would have been estimated to be <span class="math inline">\(0.0163*1000 = 16.3\)</span> inches change in mean
<em>Snow Depth</em> for a 1000 foot increase in elevation.</p>
<p>The plots of the two estimated temperature models in
Figures <a href="chapter8.html#fig:Figure8-3">8.3</a> and <a href="chapter8.html#fig:Figure8-4">8.4</a> suggest a similar change
in the responses over
the range of observed temperatures. Those predictors range from 22<span class="math inline">\(^\circ F\)</span>
to 34<span class="math inline">\(^\circ F\)</span> (minimum temperature) and from 26<span class="math inline">\(^\circ F\)</span> to 50<span class="math inline">\(^\circ F\)</span>
(maximum temperature). This tells us a 1<span class="math inline">\(^\circ F\)</span> increase in either
temperature is a
greater proportion of the observed range of each predictor than a 1 unit (foot)
increase in elevation, so the two temperature variables will generate larger apparent
magnitudes of slope coefficients. But having large slope coefficients is no
guarantee of a good model – in fact, the elevation model has the highest
<em>R</em><sup>2</sup> value of these three models even though its slope coefficient looks tiny
compared to the other models.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-3"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-3-1.png" alt="Plot of the estimated SLR model using Min Temp as predictor." width="75%" />
<p class="caption">
Figure 8.3: Plot of the estimated SLR model using Min Temp as predictor.
</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-4"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-4-1.png" alt="Plot of the estimated SLR model using Max Temp as predictor." width="75%" />
<p class="caption">
Figure 8.4: Plot of the estimated SLR model using Max Temp as predictor.
</p>
</div>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="chapter8.html#cb712-1" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation, <span class="at">data =</span> snotel_s)</span>
<span id="cb712-2"><a href="chapter8.html#cb712-2" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Min.Temp, <span class="at">data =</span> snotel_s)</span>
<span id="cb712-3"><a href="chapter8.html#cb712-3" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Max.Temp, <span class="at">data =</span> snotel_s)</span>
<span id="cb712-4"><a href="chapter8.html#cb712-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(effects)</span>
<span id="cb712-5"><a href="chapter8.html#cb712-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(m1, <span class="at">residuals =</span> T), <span class="at">main =</span> <span class="st">&quot;SLR: Effect of Elevation&quot;</span>)</span>
<span id="cb712-6"><a href="chapter8.html#cb712-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(m2, <span class="at">residuals =</span> T), <span class="at">main =</span> <span class="st">&quot;SLR: Effect of Min Temp&quot;</span>)</span>
<span id="cb712-7"><a href="chapter8.html#cb712-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(m3, <span class="at">residuals =</span> T), <span class="at">main =</span> <span class="st">&quot;SLR: Effect of Max Temp&quot;</span>)</span></code></pre></div>
<!-- \newpage -->
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="chapter8.html#cb713-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation, data = snotel_s)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -36.416  -5.135  -1.767   7.645  23.508 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -72.005873  17.712927  -4.065 0.000478
## Elevation     0.016275   0.002579   6.311 1.93e-06
## 
## Residual standard error: 13.27 on 23 degrees of freedom
## Multiple R-squared:  0.634,  Adjusted R-squared:  0.618 
## F-statistic: 39.83 on 1 and 23 DF,  p-value: 1.933e-06</code></pre>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="chapter8.html#cb715-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Min.Temp, data = snotel_s)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -26.156 -11.238   2.810   9.846  26.444 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 174.0963    25.5628   6.811 6.04e-07
## Min.Temp     -4.8836     0.9148  -5.339 2.02e-05
## 
## Residual standard error: 14.65 on 23 degrees of freedom
## Multiple R-squared:  0.5534, Adjusted R-squared:  0.534 
## F-statistic:  28.5 on 1 and 23 DF,  p-value: 2.022e-05</code></pre>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="chapter8.html#cb717-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Max.Temp, data = snotel_s)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -26.447 -10.367  -4.394  10.042  34.774 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 122.6723    19.6380   6.247 2.25e-06
## Max.Temp     -2.2840     0.5257  -4.345 0.000238
## 
## Residual standard error: 16.25 on 23 degrees of freedom
## Multiple R-squared:  0.4508, Adjusted R-squared:  0.4269 
## F-statistic: 18.88 on 1 and 23 DF,  p-value: 0.0002385</code></pre>
<p>Since all three variables look like they are potentially useful in predicting
snow depth, we want to consider if an MLR model might explain more of the
variability in <em>Snow Depth</em>. To fit an MLR model, we use the same general format
as in previous topics but with adding “<code>+</code>” between any additional
predictors<a href="#fn133" class="footnote-ref" id="fnref133"><sup>133</sup></a> we want to add to the model,
<code>y ~ x1 + x2 + ... + xk</code>: </p>

<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="chapter8.html#cb719-1" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation <span class="sc">+</span> Min.Temp <span class="sc">+</span> Max.Temp, <span class="at">data =</span> snotel_s)</span>
<span id="cb719-2"><a href="chapter8.html#cb719-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel_s)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.508  -7.679  -3.139   9.627  26.394 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -10.506529  99.616286  -0.105   0.9170
## Elevation     0.012332   0.006536   1.887   0.0731
## Min.Temp     -0.504970   2.042614  -0.247   0.8071
## Max.Temp     -0.561892   0.673219  -0.835   0.4133
## 
## Residual standard error: 13.6 on 21 degrees of freedom
## Multiple R-squared:  0.6485, Adjusted R-squared:  0.5983 
## F-statistic: 12.91 on 3 and 21 DF,  p-value: 5.328e-05</code></pre>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="chapter8.html#cb721-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(m4, <span class="at">residuals =</span> T), <span class="at">main =</span> <span class="st">&quot;MLR model with Elev, Min, &amp; Max Temps&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-5"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-5-1.png" alt="Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp. Compare this plot that comes from one MLR model to Figures 8.2, 8.3, and 8.4 for comparable SLR models. Note the points in these panels are the partial residuals that are generated after controlling for the other two of the three variables as explained below." width="75%" />
<p class="caption">
Figure 8.5: Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp. Compare this plot that comes from one MLR model to Figures <a href="chapter8.html#fig:Figure8-2">8.2</a>, <a href="chapter8.html#fig:Figure8-3">8.3</a>, and <a href="chapter8.html#fig:Figure8-4">8.4</a> for comparable SLR models. Note the points in these panels are the partial residuals that are generated after controlling for the other two of the three variables as explained below.
</p>
</div>
<p>Based on the output, the estimated MLR model is</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_i = -10.51 + 0.0123\cdot\text{Elevation}_i
-0.505\cdot\text{MinTemp}_i - 0.562\cdot\text{MaxTemp}_i\]</span></p>
<p>The direction of the estimated slope coefficients were similar but they
all changed in magnitude as compared to the respective SLRs, as seen in the
estimated term-plots from the MLR model in Figure <a href="chapter8.html#fig:Figure8-5">8.5</a>.</p>
<p>There are two ways to think about the changes from individual SLR slope
coefficients to the similar MLR results here.</p>
<ol style="list-style-type: decimal">
<li><p>Each term in the MLR is the result for estimating each
slope after controlling for the other two variables (and we will always
use this sort of interpretation any time we interpret MLR effects). For the <em>Elevation</em> slope,
we would say that the slope coefficient is “corrected for” or “adjusted for” the variability that is explained by the
temperature variables in the model.</p></li>
<li><p>Because of multicollinearity in the predictors, the
variables might share information that is useful for explaining the
variability in the response variable, so the slope coefficients of each
predictor get perturbed because the model cannot separate their effects on
the response. This issue disappears when the predictors are uncorrelated
or even just minimally correlated.</p></li>
</ol>
<p>There are some ramifications of multicollinearity in MLR:
</p>
<ol style="list-style-type: decimal">
<li><p>Adding variables to a model might lead to almost no improvement in the
overall variability explained by the model.</p></li>
<li><p>Adding variables to a model can cause slope coefficients to change signs
as well as magnitudes.</p></li>
<li><p>Adding variables to a model can lead to inflated standard errors for some
or all of the coefficients (this is less obvious
but is related to the shared information in predictors making it less
clear what slope coefficient to use for each variable, so more uncertainty in their estimation).</p></li>
<li><p>In extreme cases of multicollinearity, it may even be impossible to obtain
some or any coefficient estimates.</p></li>
</ol>
<p>These seem like pretty serious issues and they are but there are many, many
situations where we proceed with MLR even
in the presence of potentially correlated predictors.

It is likely that you
have heard or read about inferences from models that are dealing with this
issue – for example, medical studies often report the increased risk of death
from some behavior or trait after controlling for gender, age, health status, etc. In many
research articles, it is becoming common practice to report the slope for a
variable that is of most interest with it in the model alone (SLR) and in models
after adjusting for the other variables that are expected to matter. The “adjusted for other variables” results are built with MLR or related multiple-predictor models like MLR.
</p>
<!-- \newpage -->
</div>
<div id="section8-2" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Validity conditions in MLR</h2>
<p>But before we get too excited about any results, we should always assess our
validity conditions. For MLR, they are similar to those for SLR:
</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>The response and all predictors need to be quantitative variables.
This condition is relaxed to allow a categorical predictor in two ways
in Sections <a href="chapter8.html#section8-9">8.9</a> and <a href="chapter8.html#section8-11">8.11</a>.</li>
</ul></li>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li><p>This assumption is about the responses – we must assume that they were
collected in a fashion so that they can be assumed to be independent. This
implies that we also have independent random errors.
</p></li>
<li><p>This is not an assumption about the predictor variables!</p></li>
</ul></li>
<li><p><strong>Linearity of relationship (</strong><b><font color='red'>NEW VERSION FOR MLR!</font></b><strong>):</strong></p>
<ul>
<li><p>Linearity is assumed between the response variable and <strong>each</strong>
explanatory variable (<span class="math inline">\(y\)</span> and each <span class="math inline">\(x\)</span>).</p></li>
<li><p>We can check this three ways:</p>
<ol style="list-style-type: decimal">
<li><p>Make plots of the response versus each explanatory variable:</p>
<ul>
<li>Only visual evidence of a curving relationship is a problem here.
Transformations of individual explanatory variables or the
response are possible. It is possible to not find a problem in this
plot that becomes more obvious when we account for variability that
is explained by other variables in the partial residuals.
</li>
</ul></li>
<li><p>Examine the Residuals vs Fitted plot:</p>
<ul>
<li>When using MLR, curves in the residuals vs. fitted values
suggest a missed curving relationship with at least one predictor
variable, but it will not be specific as to which one is non-linear.
Revisit the scatterplots to identify the source of the issue.
</li>
</ul></li>
<li><p>Examine partial residuals and smoothing line in term-plots.</p>
<ul>
<li>Turning on the <code>residuals = T</code> option in the effects plot allows
direct assessment of residuals vs each predictor after accounting
for others. Look for clear patterns in the partial residuals<a href="#fn134" class="footnote-ref" id="fnref134"><sup>134</sup></a> that the smoothing line is
also following for potential issues with the linearity assumption.</li>
</ul></li>
</ol></li>
</ul></li>
<li><p><strong>Multicollinearity effects checked for:</strong></p>
<ul>
<li><p>Issues here do not mean we cannot proceed with a given model, but it can
impact our ability to trust and interpret the estimated terms. Extreme
issues might require removing some highly correlated variables prior to
really focusing on a model.</p></li>
<li><p>Check a scatterplot or correlation matrix  to
assess the potential for shared information in different predictor
variables.</p></li>
<li><p>Use the diagnostic measure called a <strong><em>variance inflation factor</em></strong>
(<strong><em>VIF</em></strong>) discussed in Section <a href="chapter8.html#section8-5">8.5</a> (we need to develop
some ideas first to understand this measure). </p></li>
</ul></li>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>Same as before since it pertains to the residuals.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>Same as before since it pertains to the residuals.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li><p>Leverage is now determined by how unusual a point is for multiple
explanatory variables.</p></li>
<li><p>The <strong><em>leverage</em></strong> values in the Residuals vs Leverage plot are
scaled to add up to the <em>degrees of freedom (df) used for the model</em>
which is the number of explanatory variables (<span class="math inline">\(K\)</span>) plus 1, so <span class="math inline">\(K+1\)</span>.
</p></li>
<li><p>The scale of leverages depends on the complexity of the model through
the <em>df</em> and the sample size.</p></li>
<li><p>The interpretation is still that the larger the leverage value, the
more leverage the point has.</p></li>
<li><p>The mean leverage is always <em>(model used df)/n = (K+1)/n</em> – so focus
on the values with above average leverage.</p>
<ul>
<li>For example, with <span class="math inline">\(K = 3\)</span> and <span class="math inline">\(n = 20\)</span>, the average leverage is
<span class="math inline">\(4/20 = 1/5\)</span>.</li>
</ul></li>
<li><p>High leverage points whose response does not follow the pattern defined
by the other observations (now based on patterns for multiple <span class="math inline">\(x\text{&#39;s}\)</span>
with the response) will be influential.</p></li>
<li><p>Use the Residual’s vs Leverage plot to identify problematic points.
Explore further with Cook’s D continuing to provide a measure of the
influence of each observation.</p>
<ul>
<li>The rules and interpretations for Cook’s D are the same as in SLR
(over 0.5 is possibly influential and over 1 is definitely influential).</li>
</ul></li>
</ul></li>
</ul>
<p>While not a condition for use of the methods, a note about random
assignment and random sampling is useful here in considering the scope of
inference of any results.  To make inferences
about a population, we need to have a representative sample. If we have
randomly assigned levels of treatment variables(s), then we can make causal
inferences to subjects like those that we could have observed. And if we both
have a representative sample and randomization, we can make causal inferences
for the population. It is possible to randomly assign levels of variable(s) to
subjects and still collect additional information from other explanatory
(sometimes called <strong><em>control</em></strong>) variables. The causal interpretations would
only be associated with the explanatory variables that were randomly assigned
even though the model might
contain other variables. Their interpretation still involves noting all the
variables included in the model, as demonstrated below. It is even possible to
include interactions between randomly assigned variables and other variables –
like drug dosage and sex of the subjects. In these cases, causal inference
could apply to the treatment levels but noting that the impacts differ based on
the non-randomly assigned variable.</p>
<p>For the <em>Snow Depth</em> data, the conditions can be assessed as:</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>These are all clearly quantitative variables.</li>
</ul></li>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li>The observations are based on a random sample of sites from the
population and the sites are spread around the mountains in Montana. Many
people would find it to be reasonable to assume that the sites are
independent of one another but others would be worried that sites closer
together in space might be more similar than they are to far-away
observations (this is called <strong><em>spatial correlation</em></strong>).
 I have been in a heated discussion with
statistics colleagues about whether spatial dependency should be considered
or if it is valid to ignore it in this sort of situation. It is certainly
possible to be concerned about independence of observations here but it
takes more advanced statistical methods to actually assess whether there is
spatial dependency in these data. Even if you were going to pursue models
that incorporate spatial correlations, the first task would be to fit this
sort of model and then explore the results. When data are collected across
space, you should note that there might be some sort of spatial dependency
that <em>could</em> violate the independence assumption.</li>
</ul></li>
</ul>
<p>To assess the remaining assumptions, we can use our diagnostic plots.
 The same code as before will provide diagnostic plots. There
is some extra code (<code>par(...)</code>) added to allow us to add labels to the plots
(<code>sub.caption = "..."</code>) to know which model is being displayed since we have so
many to discuss here. We can also employ a new approach, which is to simulate
new observations from the model and make plots to compare simulated data sets to
what was observed. The <code>simulate</code> function from Chapter <a href="chapter2.html#chapter2">2</a>
 can be used to generate new observations from the
model based on the estimated coefficients and where we know that the assumptions
are true. If the simulated data and the observed data are very different, then
the model is likely dangerous to use for inferences because of this mis-match.
This method can be used to assess the linearity, constant variance, normality of
residuals, and influential points aspects of the model. It is not something used
in every situation, but is especially helpful if you are struggling to decide if
what you are seeing in the diagnostics is just random variability or is really a
clear issue. The regular steps in assessing each assumption are discussed first.</p>

<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="chapter8.html#cb722-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb722-2"><a href="chapter8.html#cb722-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m4, <span class="at">sub.caption =</span> <span class="st">&quot;Diagnostics for m4&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-6"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-6-1.png" alt="Diagnostic plots for model m4: \(\text{Snow.Depth}\sim \text{Elevation} + \text{Min.Temp} + \text{Max.Temp}\)." width="75%" />
<p class="caption">
Figure 8.6: Diagnostic plots for model m4: <span class="math inline">\(\text{Snow.Depth}\sim \text{Elevation} + \text{Min.Temp} + \text{Max.Temp}\)</span>.
</p>
</div>
<ul>
<li><p><strong>Linearity of relationship (</strong><b><font color='red'>NEW VERSION FOR MLR!</font></b><strong>):</strong></p>
<ul>
<li><p>Make plots of the response versus each explanatory variable:</p>
<ul>
<li>In Figure <a href="chapter8.html#fig:Figure8-1">8.1</a>, the plots of each variable versus
snow depth do not clearly show any nonlinearity except for a little
dip around 7000 feet in the plot vs <em>Elevation</em>.</li>
</ul></li>
<li><p>Examine the Residuals vs Fitted plot in Figure <a href="chapter8.html#fig:Figure8-6">8.6</a>:</p>
<ul>
<li>Generally, there is no clear curvature in the Residuals vs Fitted
panel and that would be an acceptable answer. However, there is some
pattern in the smoothing line that could suggest a more complicated
relationship between at least one predictor and the response. This also
resembles the pattern in the <em>Elevation</em> vs. <em>Snow depth</em> panel in
Figure <a href="chapter8.html#fig:Figure8-1">8.1</a> so that might be the source of this
“problem.” This suggests that there is the potential to do a little
bit better but that it is not unreasonable to proceed on with the MLR,
ignoring this little wiggle in the diagnostic plot.</li>
</ul></li>
<li><p>Examine partial residuals as seen in Figure <a href="chapter8.html#fig:Figure8-5">8.5</a>:</p>
<ul>
<li>In the term-plot for elevation from this model, there is a slight
pattern in the partial residuals between 6,500 and 7,500 feet. This was
also apparent in the original plot and suggests a slight nonlinearity in
the pattern of responses versus this explanatory variable.</li>
</ul></li>
</ul></li>
<li><p><strong>Multicollinearity effects checked for:</strong></p>
<ul>
<li><p>The predictors certainly share information in this application
(correlations between -0.67 and -0.91) and multicollinearity looks to be
a major concern in being able to understand/separate the impacts of
temperatures and elevations on snow depths.</p></li>
<li><p>See Section <a href="chapter8.html#section8-5">8.5</a> for more on this issue in these data.</p></li>
</ul></li>
</ul>
<!-- \newpage -->
<ul>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>While there is a little bit more variability in the middle of the fitted
values, this is more an artifact of having a smaller data set with a couple
of moderate outliers that fell in the same range of fitted values and maybe
a little bit of missed curvature. So there is not too much of an issue with
this condition.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>The residuals match the normal distribution fairly closely the QQ-plot,
showing only a little deviation for observation 9 from a normal distribution
and that deviation is extremely minor. There is certainly no indication of a
violation of the normality assumption here. </li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li><p>With <span class="math inline">\(K = 3\)</span> predictors and <span class="math inline">\(n = 25\)</span> observations, the average
leverage is <span class="math inline">\(4/25 = 0.16\)</span>. This gives us a scale to interpret the leverage
values on the <span class="math inline">\(x\)</span>-axis of the lower right panel of our diagnostic plots.</p></li>
<li><p>There are three higher leverage points (leverages over 0.3) with only
one being influential (point 9) with Cook’s D close to 1.</p>
<ul>
<li>Note that point 10 had the same leverage but was not influential with
Cook’s D less than 0.5.</li>
</ul></li>
<li><p>We can explore both of these points to see how two observations can have
the same leverage and different amounts of influence.</p></li>
</ul></li>
</ul>
<p>The two flagged points, observations 9 and 10 in the data set, are for the
sites “Northeast Entrance” (to Yellowstone) and “Combination.” We can use the
MLR equation to do some prediction for each observation and calculate residuals
to see how far the model’s predictions are from the actual observed values for
these sites. For the Northeast Entrance, the <em>Max.Temp</em> was 45, the <em>Min.Temp</em>
was 28, and the <em>Elevation</em> was 7350 as you can see in this printout of just the
two rows of the data set available by slicing rows 9 and 10 from <code>snotel_s</code>:</p>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="chapter8.html#cb723-1" aria-hidden="true" tabindex="-1"></a>snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">9</span>,<span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 x 6
##      ID Station            Snow.Depth Max.Temp Min.Temp Elevation
##   &lt;dbl&gt; &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1    18 Northeast Entrance       11.2       45       28      7350
## 2    53 Combination              14         36       28      5600</code></pre>
<p>The estimated <em>Snow Depth</em> for the <em>Northeast Entrance</em> site (observation 9)
is found using the estimated model with</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_9 &amp; = -10.51 + 0.0123\cdot\text{Elevation}_9 -
0.505\cdot\text{MinTemp}_9 - 0.562\cdot\text{MaxTemp}_9 \\
&amp; = -10.51 + 0.0123*\boldsymbol{7350} -0.505*\boldsymbol{28} - 
0.562*\boldsymbol{45} \\
&amp; = 40.465 \text{ inches,}
\end{array}\]</span></p>
<p>but the observed snow depth was actually <span class="math inline">\(y_9 = 11.2\)</span> inches. The observed <strong><em>residual</em></strong> is then</p>
<p><span class="math display">\[e_9 = y_9-\widehat{y}_9 = 11.2-40.465 = -29.265 \text{ inches.}\]</span></p>
<p>So the model “misses” the snow depth by over 29 inches with the model suggesting
over 40 inches of snow but only 11 inches actually being present<a href="#fn135" class="footnote-ref" id="fnref135"><sup>135</sup></a>.</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="chapter8.html#cb725-1" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">10.51</span> <span class="sc">+</span> <span class="fl">0.0123</span><span class="sc">*</span><span class="dv">7350</span> <span class="sc">-</span> <span class="fl">0.505</span><span class="sc">*</span><span class="dv">28</span> <span class="sc">-</span> <span class="fl">0.562</span><span class="sc">*</span><span class="dv">45</span></span></code></pre></div>
<pre><code>## [1] 40.465</code></pre>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="chapter8.html#cb727-1" aria-hidden="true" tabindex="-1"></a><span class="fl">11.2</span> <span class="sc">-</span> <span class="fl">40.465</span></span></code></pre></div>
<pre><code>## [1] -29.265</code></pre>
<p>This point is being rated as influential (Cook’s D <span class="math inline">\(\approx\)</span> 1) with a
leverage of nearly 0.35 and a standardized residual (<span class="math inline">\(y\)</span>-axis of Residuals vs. 
Leverage plot) of nearly -3. This suggests that even
with this observation impacting/distorting the slope coefficients (that is what
<strong><em>influence</em></strong> means), the model is still doing really poorly at fitting this
observation. We’ll drop it and re-fit the model in a second to see how the slopes
change. First, let’s compare that result to what happened for data point 10
(“Combination”) which was just as high leverage but not identified as
influential.</p>
<p>The estimated snow depth for the <em>Combination</em> site is </span></p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_{10} &amp; = -10.51 + 0.0123\cdot\text{Elevation}_{10} -
0.505\cdot\text{MinTemp}_{10} - 0.562\cdot\text{MaxTemp}_{10} \\
&amp; = -10.51 + 0.0123*\boldsymbol{5600} -0.505*\boldsymbol{28} - 
0.562*\boldsymbol{36} \\
&amp; = 23.998 \text{ inches.}
\end{array}\]</span></p>
<p>The observed snow depth here was <span class="math inline">\(y_{10} = 14.0\)</span> inches so the observed
residual is then</p>
<p><span class="math display">\[e_{10} = y_{10}-\widehat{y}_{10} = 14.0-23.998 = -9.998 \text{ inches.}\]</span></p>
<p>This results in a standardized residual of around -1. This is still a “miss”
but not as glaring as the previous result and also is not having a major impact
on the model’s estimated slope coefficients based on the small Cook’s D value.</p>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="chapter8.html#cb729-1" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">10.51</span> <span class="sc">+</span> <span class="fl">0.0123</span><span class="sc">*</span><span class="dv">5600</span> <span class="sc">-</span> <span class="fl">0.505</span><span class="sc">*</span><span class="dv">28</span> <span class="sc">-</span> <span class="fl">0.562</span><span class="sc">*</span><span class="dv">36</span></span></code></pre></div>
<pre><code>## [1] 23.998</code></pre>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="chapter8.html#cb731-1" aria-hidden="true" tabindex="-1"></a><span class="dv">14</span> <span class="sc">-</span> <span class="fl">23.998</span></span></code></pre></div>
<pre><code>## [1] -9.998</code></pre>
<p>Note that any predictions using this model presume that it is
trustworthy, but
the large Cook’s D on one observation suggests we should consider the model
after removing that observation. We can re-run the model without the
9<sup>th</sup> observation using the data set <code>snotel_s %&gt;% slice(-9)</code>.</p>
<!-- \newpage -->
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="chapter8.html#cb733-1" aria-hidden="true" tabindex="-1"></a>m5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation <span class="sc">+</span> Min.Temp <span class="sc">+</span> Max.Temp, <span class="at">data =</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="dv">9</span>))</span>
<span id="cb733-2"><a href="chapter8.html#cb733-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel_s %&gt;% 
##     slice(-9))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -29.2918  -4.9757  -0.9146   5.4292  20.4260 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -1.424e+02  9.210e+01  -1.546  0.13773
## Elevation    2.141e-02  6.101e-03   3.509  0.00221
## Min.Temp     6.722e-01  1.733e+00   0.388  0.70217
## Max.Temp     5.078e-01  6.486e-01   0.783  0.44283
## 
## Residual standard error: 11.29 on 20 degrees of freedom
## Multiple R-squared:  0.7522, Adjusted R-squared:  0.715 
## F-statistic: 20.24 on 3 and 20 DF,  p-value: 2.843e-06</code></pre>

<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="chapter8.html#cb735-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(m5, <span class="at">residuals =</span> T), <span class="at">main =</span> <span class="st">&quot;MLR model with NE Ent. Removed&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-7"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-7-1.png" alt="Term-plots for the MLR for Snow Depth based on Elevation, Min Temp, and Max Temp with Northeast entrance observation removed from data set (n = 24)." width="75%" />
<p class="caption">
Figure 8.7: Term-plots for the MLR for Snow Depth based on Elevation, Min Temp, and Max Temp with Northeast entrance observation removed from data set (n = 24).
</p>
</div>
<p>The estimated MLR model with <span class="math inline">\(n = 24\)</span> after removing the influential
“NE Entrance” observation is</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_i = -142.4 + 0.0214\cdot\text{Elevation}_i
+0.672\cdot\text{MinTemp}_i +0.508\cdot\text{MaxTemp}_i\]</span></p>
<p>Something unusual has happened here: there is a positive slope for both
temperature terms in Figure <a href="chapter8.html#fig:Figure8-7">8.7</a> that both
contradicts reasonable expectations (warmer temperatures are related to higher
snow levels?) and our original SLR results. So what happened? First, removing
the influential point has drastically changed the slope coefficients (remember
that was the definition of an influential point). Second, when there are
predictors that share information, the results can be somewhat unexpected for
some or all the predictors when they are all in the model together. Note that
the <em>Elevation</em> term looks like what we might expect and seems to have a big
impact on the predicted <em>Snow Depths</em>. So when the temperature variables
are included in the model they might be functioning to explain some differences
in sites that the <em>Elevation</em> term could not explain. This is where our
“adjusting for” terminology comes into play. The unusual-looking slopes for
the temperature effects can be explained
by interpreting them as the estimated change in the response for changes in
temperature <strong>after we control for the impacts of elevation</strong>. Suppose that
<em>Elevation</em> explains most of the variation in <em>Snow Depth</em> except for a few
sites where the elevation cannot explain all the variability and the site
characteristics happen to show higher temperatures and more snow (or lower
temperatures and less snow). This could be because warmer areas might have been
hit by a recent snow storm while colder areas might have been missed (this is
just one day and subject to spatial and temporal fluctuations in precipitation
patterns). Or maybe there is another factor related to having marginally warmer
temperatures that are accompanied by more snow (maybe the lower snow sites for
each elevation were so steep that they couldn’t hold much snow but were also
relatively colder?). Thinking about it this way, the temperature model
components could provide useful corrections to what <em>Elevation</em> is providing in
an overall model and explain more variability than any of the variables could
alone. It is also possible that the
temperature variables are not needed in a model with <em>Elevation</em> in it, are just
“explaining noise,” and should be removed from the model. Each of the next
sections take on various aspects of these
issues and eventually lead to a general set of modeling and model selection
recommendations to help you work in situations as complicated as this.
Exploring the results for this model assumes we trust it and, once again, we
need to check diagnostics before getting too focused on any particular results
from it.</p>
<p>The Residuals vs. Leverage diagnostic plot in Figure <a href="chapter8.html#fig:Figure8-8">8.8</a>
for the model fit to the data set without NE Entrance (now <span class="math inline">\(n = 24\)</span>) reveals a new
point that is somewhat influential (point 22 in the data set has Cook’s D
<span class="math inline">\(\approx\)</span> 0.5). It is for a location called “Bloody
<span class="math inline">\(\require{color}\colorbox{black}{Redact.}\)</span>”<a href="#fn136" class="footnote-ref" id="fnref136"><sup>136</sup></a> which has a
leverage of nearly 0.2 and a standardized residual of nearly -3.
This point did not show up as influential in the original version of the data
set with the same model but it is now. It also shows up as a potential outlier.
As we did before, we can explore it a bit by comparing the model predicted snow
depth to the observed snow depth. The predicted snow depth for this site (see
output below for variable values) is</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_{22} = -142.4 + 0.0214*\boldsymbol{7550}
+0.672*\boldsymbol{26} +0.508*\boldsymbol{39} = 56.45 \text{ inches.}\]</span></p>
<p>The observed snow depth was 27.2 inches, so the estimated residual is -39.25
inches. Again, this point is potentially influential and an outlier.
Additionally, our model contains results that are not what we would have
expected <em>a priori</em>, so it is not unreasonable to consider removing this
observation to be able to work towards a model that is fully trustworthy.</p>

<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="chapter8.html#cb736-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb736-2"><a href="chapter8.html#cb736-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m5, <span class="at">sub.caption =</span> <span class="st">&quot;Diagnostics for m5&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-8"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-8-1.png" alt="Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with Northeast entrance observation removed from data set." width="75%" />
<p class="caption">
Figure 8.8: Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with Northeast entrance observation removed from data set.
</p>
</div>

<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel_s %&gt;% 
##     slice(-c(9, 22)))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.878  -4.486   0.024   3.996  20.728 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -2.133e+02  7.458e+01  -2.859   0.0100
## Elevation    2.686e-02  4.997e-03   5.374 3.47e-05
## Min.Temp     9.843e-01  1.359e+00   0.724   0.4776
## Max.Temp     1.243e+00  5.452e-01   2.280   0.0343
## 
## Residual standard error: 8.832 on 19 degrees of freedom
## Multiple R-squared:  0.8535, Adjusted R-squared:  0.8304 
## F-statistic:  36.9 on 3 and 19 DF,  p-value: 4.003e-08</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-9"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-9-1.png" alt="Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed (\(n = 23\))." width="75%" />
<p class="caption">
Figure 8.9: Diagnostic plots for MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed (<span class="math inline">\(n = 23\)</span>).
</p>
</div>
<!-- \newpage -->
<p>This worry-some observation is located in the 22<sup>nd</sup> row of the
original data set:</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="chapter8.html#cb738-1" aria-hidden="true" tabindex="-1"></a>snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">22</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 6
##      ID Station          Snow.Depth Max.Temp Min.Temp Elevation
##   &lt;dbl&gt; &lt;fct&gt;                 &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1    36 Bloody [Redact.]       27.2       39       26      7550</code></pre>
<p>With the removal of both the “Northeast Entrance” and “Bloody
<span class="math inline">\(\require{color}\colorbox{black}{Redact.}\)</span>” sites, there are <span class="math inline">\(n = 23\)</span> observations
remaining. This model (<code>m6</code>) seems to contain residual diagnostics (Figure
<a href="chapter8.html#fig:Figure8-9">8.9</a>) that are finally generally reasonable.</p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="chapter8.html#cb740-1" aria-hidden="true" tabindex="-1"></a>m6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation <span class="sc">+</span> Min.Temp <span class="sc">+</span> Max.Temp, <span class="at">data =</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>)))</span>
<span id="cb740-2"><a href="chapter8.html#cb740-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m6)</span>
<span id="cb740-3"><a href="chapter8.html#cb740-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb740-4"><a href="chapter8.html#cb740-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m6, <span class="at">sub.caption =</span> <span class="st">&quot;Diagnostics for m6&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<p>It is hard to suggest that there any curvature issues and the slight variation
in the Scale-Location plot is mostly
due to few observations with fitted values around 30 happening to be well
approximated by the model. The normality assumption is generally reasonable and
no points seem to be overly influential on this model (finally!).</p>
<p>The term-plots (Figure <a href="chapter8.html#fig:Figure8-10">8.10</a>) show that the temperature slopes
are both positive although in this model <em>Max.Temp</em> seems to be more
“important” than <em>Min.Temp</em>. We have ruled out individual
influential points as the source of un-expected directions in slope coefficients
and the more likely issue is multicollinearity – in a model that
includes <em>Elevation</em>, the temperature
effects may be positive, again acting with the <em>Elevation</em> term to generate
the best possible predictions of the
observed responses. Throughout this discussion, we have mainly focused on the
slope coefficients and diagnostics. We have other tools in MLR to more
quantitatively assess and compare different regression models that are considered
in the next sections.
</p>

<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="chapter8.html#cb741-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(m6, <span class="at">residuals =</span> T), <span class="at">main =</span> <span class="st">&quot;MLR model with n = 23&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-10"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-10-1.png" alt="Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed." width="75%" />
<p class="caption">
Figure 8.10: Term-plots for the MLR for Snow Depth based on Elevation, Min Temp and Max Temp with two observations removed.
</p>
</div>
<p>As a final assessment of this model, we can consider simulating a set of
<span class="math inline">\(n = 23\)</span> responses from this model and then comparing that data set to the one we
just analyzed. This does not change the predictor variables, but creates two new
versions of the response called <code>SimulatedSnow</code> and <code>SimulatedSnow2</code> in the
following code chunk which are plotted in Figure <a href="chapter8.html#fig:Figure8-11">8.11</a>. In
exploring two realizations of simulated responses from the model, the results
look fairly similar to the original data set. This model appeared to have
reasonable assumptions and the match between simulated responses and the
original ones reinforces those previous assessments. When the match is not so
close, it can reinforce or create concern about the way that the assumptions
have been assessed using other tools.</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="chapter8.html#cb742-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">307</span>)</span>
<span id="cb742-2"><a href="chapter8.html#cb742-2" aria-hidden="true" tabindex="-1"></a>snotel_final <span class="ot">&lt;-</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>))</span>
<span id="cb742-3"><a href="chapter8.html#cb742-3" aria-hidden="true" tabindex="-1"></a>snotel_final <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> </span>
<span id="cb742-4"><a href="chapter8.html#cb742-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">#Creates first and second set of simulated responses</span></span>
<span id="cb742-5"><a href="chapter8.html#cb742-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">SimulatedSnow =</span> <span class="fu">simulate</span>(m6)[[<span class="dv">1</span>]],</span>
<span id="cb742-6"><a href="chapter8.html#cb742-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">SimulatedSnow2 =</span> <span class="fu">simulate</span>(m6)[[<span class="dv">1</span>]]</span>
<span id="cb742-7"><a href="chapter8.html#cb742-7" aria-hidden="true" tabindex="-1"></a>         ) </span></code></pre></div>

<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="chapter8.html#cb743-1" aria-hidden="true" tabindex="-1"></a>r1 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Elevation, <span class="at">y =</span> Snow.Depth)) <span class="sc">+</span> </span>
<span id="cb743-2"><a href="chapter8.html#cb743-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb743-3"><a href="chapter8.html#cb743-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-4"><a href="chapter8.html#cb743-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Real Responses&quot;</span>)</span>
<span id="cb743-5"><a href="chapter8.html#cb743-5" aria-hidden="true" tabindex="-1"></a>r2 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Max.Temp, <span class="at">y =</span> Snow.Depth)) <span class="sc">+</span> </span>
<span id="cb743-6"><a href="chapter8.html#cb743-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb743-7"><a href="chapter8.html#cb743-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-8"><a href="chapter8.html#cb743-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Real Responses&quot;</span>)</span>
<span id="cb743-9"><a href="chapter8.html#cb743-9" aria-hidden="true" tabindex="-1"></a>r3 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Min.Temp, <span class="at">y =</span> Snow.Depth)) <span class="sc">+</span> </span>
<span id="cb743-10"><a href="chapter8.html#cb743-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb743-11"><a href="chapter8.html#cb743-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-12"><a href="chapter8.html#cb743-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Real Responses&quot;</span>)</span>
<span id="cb743-13"><a href="chapter8.html#cb743-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb743-14"><a href="chapter8.html#cb743-14" aria-hidden="true" tabindex="-1"></a>s1 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Elevation, <span class="at">y =</span> SimulatedSnow)) <span class="sc">+</span> </span>
<span id="cb743-15"><a href="chapter8.html#cb743-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">&quot;forestgreen&quot;</span>) <span class="sc">+</span> </span>
<span id="cb743-16"><a href="chapter8.html#cb743-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-17"><a href="chapter8.html#cb743-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;First Simulated Responses&quot;</span>)</span>
<span id="cb743-18"><a href="chapter8.html#cb743-18" aria-hidden="true" tabindex="-1"></a>s2 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Max.Temp, <span class="at">y =</span> SimulatedSnow)) <span class="sc">+</span> </span>
<span id="cb743-19"><a href="chapter8.html#cb743-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">&quot;forestgreen&quot;</span>) <span class="sc">+</span> </span>
<span id="cb743-20"><a href="chapter8.html#cb743-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-21"><a href="chapter8.html#cb743-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;First Simulated Responses&quot;</span>)</span>
<span id="cb743-22"><a href="chapter8.html#cb743-22" aria-hidden="true" tabindex="-1"></a>s3 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Min.Temp, <span class="at">y =</span> SimulatedSnow)) <span class="sc">+</span> </span>
<span id="cb743-23"><a href="chapter8.html#cb743-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">&quot;forestgreen&quot;</span>) <span class="sc">+</span> </span>
<span id="cb743-24"><a href="chapter8.html#cb743-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-25"><a href="chapter8.html#cb743-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;First Simulated Responses&quot;</span>)</span>
<span id="cb743-26"><a href="chapter8.html#cb743-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb743-27"><a href="chapter8.html#cb743-27" aria-hidden="true" tabindex="-1"></a>s12 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Elevation, <span class="at">y =</span> SimulatedSnow2)) <span class="sc">+</span> </span>
<span id="cb743-28"><a href="chapter8.html#cb743-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">&quot;skyblue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb743-29"><a href="chapter8.html#cb743-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-30"><a href="chapter8.html#cb743-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Second Simulated Responses&quot;</span>)</span>
<span id="cb743-31"><a href="chapter8.html#cb743-31" aria-hidden="true" tabindex="-1"></a>s22 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Max.Temp, <span class="at">y =</span> SimulatedSnow2)) <span class="sc">+</span> </span>
<span id="cb743-32"><a href="chapter8.html#cb743-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">&quot;skyblue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb743-33"><a href="chapter8.html#cb743-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-34"><a href="chapter8.html#cb743-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Second Simulated Responses&quot;</span>)</span>
<span id="cb743-35"><a href="chapter8.html#cb743-35" aria-hidden="true" tabindex="-1"></a>s32 <span class="ot">&lt;-</span> snotel_final <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Min.Temp, <span class="at">y =</span> SimulatedSnow2)) <span class="sc">+</span> </span>
<span id="cb743-36"><a href="chapter8.html#cb743-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">col =</span> <span class="st">&quot;skyblue&quot;</span>) <span class="sc">+</span> </span>
<span id="cb743-37"><a href="chapter8.html#cb743-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb743-38"><a href="chapter8.html#cb743-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Second Simulated Responses&quot;</span>)</span>
<span id="cb743-39"><a href="chapter8.html#cb743-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb743-40"><a href="chapter8.html#cb743-40" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(r1, r2, r3, s1, s2, s3, s12, s22, s32, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-11"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-11-1.png" alt="Plot of the original responses versus the three predictors (\(n\) = 23 data set) in the top row and two sets of simulated responses versus the predictors in the bottom two rows." width="100%" />
<p class="caption">
Figure 8.11: Plot of the original responses versus the three predictors (<span class="math inline">\(n\)</span> = 23 data set) in the top row and two sets of simulated responses versus the predictors in the bottom two rows.
</p>
</div>
</div>
<div id="section8-3" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Interpretation of MLR terms</h2>
<p>Since these results (finally) do not contain any highly influential points,
we can formally discuss interpretations of the slope coefficients and how the
term-plots (Figure <a href="chapter8.html#fig:Figure8-10">8.10</a>) aid our interpretations. Term-plots
in MLR are constructed by holding all the other quantitative variables<a href="#fn137" class="footnote-ref" id="fnref137"><sup>137</sup></a> at
their mean and generating predictions and 95% CIs for the mean response across
the levels of observed values for each predictor variable. This idea also help
us to work towards interpretations of each term in an MLR model. For example,
for <em>Elevation</em>, the term-plot starts at an elevation around 5000 feet and ends
at an elevation around 8000 feet. To generate that line and CIs for the mean
snow depth at different elevations, the MLR model of</p>
<p><span class="math display">\[\widehat{\text{SnowDepth}}_i = -213.3 + 0.0269\cdot\text{Elevation}_i
+0.984\cdot\text{MinTemp}_i +1.243\cdot\text{MaxTemp}_i\]</span></p>
<p>is used, but we need to have “something” to put in for the two temperature
variables to predict <em>Snow Depth</em> for different <em>Elevations</em>. The typical
convention is to hold the “other” variables at their means to
generate these plots. This tactic also provides a way of interpreting each
slope coefficient. Specifically, we can interpret the <em>Elevation</em> slope as:
For a 1 foot increase in <em>Elevation</em>, we estimate the mean <em>Snow Depth</em> to
increase by 0.0269 inches, holding the minimum and maximum temperatures
constant. More generally, the <strong><em>slope interpretation in an MLR</em></strong> is:
</p>
<blockquote>
<p>For a 1 <strong>[<em>units of <span class="math inline">\(\boldsymbol{x_k}\)</span></em>]</strong> increase in
<span class="math inline">\(\boldsymbol{x_k}\)</span>, we estimate the mean of <span class="math inline">\(\boldsymbol{y}\)</span> to change by
<span class="math inline">\(\boldsymbol{b_k}\)</span> <strong>[<em>units of y</em>]</strong>, after controlling for
<strong>[list of other explanatory variables in model]</strong>.</p>
</blockquote>
<p>To make this more concrete, we can recreate some points in the Elevation
term-plot. To do this, we first need the mean of the “other” predictors,
<em>Min.Temp</em> and <em>Max.Temp</em>.</p>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="chapter8.html#cb744-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(snotel_final<span class="sc">$</span>Min.Temp)</span></code></pre></div>
<pre><code>## [1] 27.82609</code></pre>
<div style="page-break-after: always;"></div>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="chapter8.html#cb746-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(snotel_final<span class="sc">$</span>Max.Temp)</span></code></pre></div>
<pre><code>## [1] 36.3913</code></pre>
<p>We can put these values into the MLR equation and simplify it by combining like
terms, to an equation that is in terms of just <em>Elevation</em> given that we are
holding <em>Min.Temp</em> and <em>Max.Temp</em> at their means:</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{SnowDepth}}_i &amp; = -213.3 + 0.0269\cdot\text{Elevation}_i
+0.984*\boldsymbol{27.826} +1.243*\boldsymbol{36.391} \\
&amp; = -213.3 + 0.0269\cdot\text{Elevation}_i + 27.38 + 45.23 \\
&amp; = \boldsymbol{-140.69 + 0.0269\cdot\textbf{Elevation}_i}.
\end{array}\]</span></p>
<p>So at the means on the two temperature variables,
the model looks like an SLR with an estimated <span class="math inline">\(y\)</span>-intercept of -140.69 (mean
<em>Snow Depth</em> for <em>Elevation</em> of 0 if temperatures are at their means)
and an estimated
slope of 0.0269. Then we can plot the predicted changes in <span class="math inline">\(y\)</span> across all the
values of the predictor variable (<em>Elevation</em>) while holding the other
variables constant. To generate the needed values to define a line, we can plug
various <em>Elevation</em> values into the simplified equation:</p>
<ul>
<li><p>For an elevation of 5000 at the average temperatures, we predict a mean snow
depth of <span class="math inline">\(-140.69 + 0.0269*5000 = -6.19\)</span> inches.</p></li>
<li><p>For an elevation of 6000 at the average temperatures, we predict a mean snow
depth of <span class="math inline">\(-140.69 + 0.0269*6000 = 20.71\)</span> inches.</p></li>
<li><p>For an elevation of 8000 at the average temperatures, we predict a mean snow
depth of <span class="math inline">\(-140.69 + 0.0269*8000 = 74.51\)</span> inches.</p></li>
</ul>
<p>We can plot this information (Figure <a href="chapter8.html#fig:Figure8-12">8.12</a>) using the <code>geom_point</code>
function to show the points we calculated and the <code>geom_line</code> function to add
a line that connects the dots. In the <code>geom_point</code>, the <code>size</code> option is
used to make the points a little easier to see.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-12"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-12-1.png" alt="Term-plot for Elevation “by-hand,” holding temperature variables constant at their means." width="75%" />
<p class="caption">
Figure 8.12: Term-plot for Elevation “by-hand,” holding temperature variables constant at their means.
</p>
</div>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="chapter8.html#cb748-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Making own effect plot:</span></span>
<span id="cb748-2"><a href="chapter8.html#cb748-2" aria-hidden="true" tabindex="-1"></a>modelres2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">elevs =</span> <span class="fu">c</span>(<span class="dv">5000</span>, <span class="dv">6000</span>, <span class="dv">8000</span>), <span class="at">snowdepths =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">6.19</span>, <span class="fl">20.71</span>, <span class="fl">74.51</span>))</span>
<span id="cb748-3"><a href="chapter8.html#cb748-3" aria-hidden="true" tabindex="-1"></a>modelres2 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> elevs, <span class="at">y =</span> snowdepths)) <span class="sc">+</span></span>
<span id="cb748-4"><a href="chapter8.html#cb748-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb748-5"><a href="chapter8.html#cb748-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">lwd =</span> <span class="dv">1</span>, <span class="at">alpha =</span> .<span class="dv">75</span>, <span class="at">col =</span> <span class="st">&quot;tomato&quot;</span>) <span class="sc">+</span></span>
<span id="cb748-6"><a href="chapter8.html#cb748-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb748-7"><a href="chapter8.html#cb748-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Effect plot of elevation by hand&quot;</span>)</span></code></pre></div>
<p>Note that we only needed 2 points to
define the line but need a denser grid of elevations if we want to add the 95%
CIs for the true mean snow depth across the different elevations since they
vary as a function of the distance from the mean of the explanatory variables.</p>
<p>The partial residuals in MLR models<a href="#fn138" class="footnote-ref" id="fnref138"><sup>138</sup></a> highlight the relationship between each predictor and the
response after the impacts of the other variables are incorporated. To do this,
we start with the raw residuals, <span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>, which is the left-over
part of the responses after accounting for all the predictors. If we add the
component of interest to explore (say <span class="math inline">\(b_kx_{kj}\)</span>) to the residuals, <span class="math inline">\(e_i\)</span>, we
get <span class="math inline">\(e_i + b_kx_{kj} = y_i - \hat{y}_i + b_kx_{kj} = y_i - (b_0 + b_1x_{1i} + b_2x_{2i}+\ldots + b_kx_{ki} + \ldots + b_Kx_{Ki}) + b_kx_{kj}\)</span> <span class="math inline">\(= y_i - (b_0 + b_1x_{1i} +b_2x_{2i}+\ldots + b_{k-1}x_{k-1,i} + b_{k+1}x_{k+1,i} + \ldots + b_Kx_{Ki})\)</span>. This new residual is a partial residual (also known as
“component-plus-residuals” to indicate that we put the residuals together with
the component of interest to create them).  It contains
all of the regular residual as well as what would be explained by <span class="math inline">\(b_kx_{kj}\)</span>
given the other variables in the model. Some choose to plot these partial
residuals or to center them at 0 and, either way, plot them versus the component,
here <span class="math inline">\(x_{kj}\)</span>. In effects plots, partial residuals are vertically scaled to
match the height that the term-plot has created by holding the other predictors
at their means so they can match the y-axis of the lines of the estimated terms
based on the model. However they are vertically located, partial residuals help
to highlight missed patterns left in the residuals that might be related to a
particular predictor.</p>
<p>To get the associated 95% CIs for an individual term, we could return to
using the <code>predict</code> function for the MLR, again holding the temperatures at
their mean values. The <code>predict</code> function is sensitive and needs the same
variable names as used in the original model fitting to work. First we create a
“new” data set using the <code>seq</code> function to generate the desired grid of
elevations and the <code>rep</code> function<a href="#fn139" class="footnote-ref" id="fnref139"><sup>139</sup></a> to repeat the means of the
temperatures for each of elevation values we need to make the plot. The code
creates a specific version of the predictor variables that is stored in
<code>newdata1</code> that is provided to the <code>predict</code> function so that it will
provide fitted values and CIs across different elevations with temperatures held
constant.  </p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="chapter8.html#cb749-1" aria-hidden="true" tabindex="-1"></a>elevs <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">5000</span>, <span class="at">to =</span> <span class="dv">8000</span>, <span class="at">length.out =</span> <span class="dv">30</span>)</span>
<span id="cb749-2"><a href="chapter8.html#cb749-2" aria-hidden="true" tabindex="-1"></a>newdata1 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">Elevation =</span> elevs, <span class="at">Min.Temp =</span> <span class="fu">rep</span>(<span class="fl">27.826</span>,<span class="dv">30</span>),</span>
<span id="cb749-3"><a href="chapter8.html#cb749-3" aria-hidden="true" tabindex="-1"></a>                   <span class="at">Max.Temp =</span> <span class="fu">rep</span>(<span class="fl">36.3913</span>,<span class="dv">30</span>))</span>
<span id="cb749-4"><a href="chapter8.html#cb749-4" aria-hidden="true" tabindex="-1"></a>newdata1</span></code></pre></div>
<pre><code>## # A tibble: 30 x 3
##    Elevation Min.Temp Max.Temp
##        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
##  1     5000      27.8     36.4
##  2     5103.     27.8     36.4
##  3     5207.     27.8     36.4
##  4     5310.     27.8     36.4
##  5     5414.     27.8     36.4
##  6     5517.     27.8     36.4
##  7     5621.     27.8     36.4
##  8     5724.     27.8     36.4
##  9     5828.     27.8     36.4
## 10     5931.     27.8     36.4
## # ... with 20 more rows</code></pre>
<p>The first 10 predicted snow depths along with 95% confidence intervals for the mean,
holding temperatures at their means, are:</p>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="chapter8.html#cb751-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(m6, <span class="at">newdata =</span> newdata1, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##           fit        lwr      upr
## 1  -6.3680312 -24.913607 12.17754
## 2  -3.5898846 -21.078518 13.89875
## 3  -0.8117379 -17.246692 15.62322
## 4   1.9664088 -13.418801 17.35162
## 5   4.7445555  -9.595708 19.08482
## 6   7.5227022  -5.778543 20.82395
## 7  10.3008489  -1.968814 22.57051
## 8  13.0789956   1.831433 24.32656
## 9  15.8571423   5.619359 26.09493
## 10 18.6352890   9.390924 27.87965</code></pre>
<p>So we could do this with any model <strong>for each predictor</strong> variable to create
term-plots, or we can just use the <code>allEffects</code> function to do this for us.
This exercise is useful to complete once to understand what is being displayed
in term-plots but using the <code>allEffects</code> function makes getting these plots
much easier.
</p>
<p>There are two other model components of possible interest in this model. The
slope of 0.984 for <em>Min.Temp</em> suggests that for a 1<span class="math inline">\(^\circ F\)</span> increase in
<em>Minimum Temperature</em>, we estimate a 0.984 inch change in the mean <em>Snow Depth</em>,
after controlling for <em>Elevation</em> and <em>Max.Temp</em> at the sites. Similarly, the
slope of 1.243 for the <em>Max.Temp</em> suggests that for a 1<span class="math inline">\(^\circ F\)</span> increase in
<em>Maximum Temperature</em>, we estimate a 1.243 inch change in the mean <em>Snow Depth</em>,
holding <em>Elevation</em> and <em>Min.Temp</em> constant. Note that there are a variety of ways
to note that each term in an
MLR is only a particular value given the other variables in the model. We can
use words such as “holding the other variables constant” or “after adjusting
for the other variables” or “in a model with…” or “for observations with similar values of the other variables but a difference of 1 unit in the predictor..” The main
point is to find words that reflect that this single slope coefficient might be
different if we had a different overall model and the only way to interpret it
is conditional on the other model components.</p>
<p>Term-plots have a few general uses to enhance our regular slope
interpretations. They can help us assess how much change in the mean of <span class="math inline">\(y\)</span> the model predicts over the range of each
observed <span class="math inline">\(x\)</span>. This can
help you to get a sense of the “practical” importance of each term.
Additionally, the term-plots show 95% confidence intervals for the mean response
across the range of each variable,
holding the other variables at their means. These intervals can be useful for
assessing the precision in the estimated mean at different values of each
predictor. However, note that you should not use these plots for deciding
whether the term should be retained in the model – we have other tools for
making that assessment. And one last note about term-plots – they do not mean
that the relationships are really linear between the predictor and response
variable being displayed. The model <strong>forces</strong> the relationship to be linear
even if that is not the real functional form. <strong>Term-plots are not diagnostics
for the model unless you add the partial residuals, the lines are just summaries of the model you assumed was correct!</strong>
Any time we do linear regression, the inferences are contingent upon the
model we chose. We know our model is not
perfect, but we hope that it helps us learn something about our research
question(s) and, to trust its results, we hope it matches the data fairly well.</p>
<p>To both illustrate the calculation of partial residuals and demonstrate their potential utility, a small simulated example is considered. These are simulated data to help to highlight these patterns but are not too different than results that can be seen in some real applications. This situation has a response of simulated cholesterol levels with (also simulated) predictors of age, exercise level, and healthiness level with a sample size of <span class="math inline">\(n = 100\)</span>. First, consider the plot of the response versus each of the predictors in Figure <a href="chapter8.html#fig:Figure8-13">8.13</a>. It appears that age might be positively related to the response, but exercise and healthiness levels do not appear to be related to the response. But it is important to remember that the response is made up of potential contributions that can be explained by each predictor and unexplained variation, and so plotting the response versus each predictor may not allow us to see the real relationship with each predictor.</p>

<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="chapter8.html#cb753-1" aria-hidden="true" tabindex="-1"></a>a1 <span class="ot">&lt;-</span> d1 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> CholLevel)) <span class="sc">+</span></span>
<span id="cb753-2"><a href="chapter8.html#cb753-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb753-3"><a href="chapter8.html#cb753-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb753-4"><a href="chapter8.html#cb753-4" aria-hidden="true" tabindex="-1"></a>e1 <span class="ot">&lt;-</span> d1 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> ExAmount, <span class="at">y =</span> CholLevel)) <span class="sc">+</span></span>
<span id="cb753-5"><a href="chapter8.html#cb753-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb753-6"><a href="chapter8.html#cb753-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb753-7"><a href="chapter8.html#cb753-7" aria-hidden="true" tabindex="-1"></a>h1 <span class="ot">&lt;-</span> d1 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> HealthLevel, <span class="at">y =</span> CholLevel)) <span class="sc">+</span></span>
<span id="cb753-8"><a href="chapter8.html#cb753-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb753-9"><a href="chapter8.html#cb753-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb753-10"><a href="chapter8.html#cb753-10" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(a1, e1, h1, <span class="at">ncol =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-13"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-13-1.png" alt="Scatterplot of Cholesterol level versus three predictors (simulated data)." width="75%" />
<p class="caption">
Figure 8.13: Scatterplot of Cholesterol level versus three predictors (simulated data).
</p>
</div>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb754-1"><a href="chapter8.html#cb754-1" aria-hidden="true" tabindex="-1"></a>sim1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(CholLevel <span class="sc">~</span> Age <span class="sc">+</span> ExAmount <span class="sc">+</span> HealthLevel, <span class="at">data =</span> d1)</span>
<span id="cb754-2"><a href="chapter8.html#cb754-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sim1)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##                Estimate Std. Error    t value     Pr(&gt;|t|)
## (Intercept) 94.54572326 4.63863859  20.382214 1.204735e-36
## Age          3.50787191 0.14967450  23.436670 1.679060e-41
## ExAmount     0.07447965 0.04029175   1.848508 6.760692e-02
## HealthLevel -1.16373873 0.07212890 -16.134153 4.339546e-29</code></pre>
<p>In the summary it appears that each predictor might be related to the response
given the other predictors in the model with p-values of &lt;0.0001, 0.068, and
&lt; 0.0001 for Age, Exercise, and Healthiness, respectively.</p>
<p>In Figure <a href="chapter8.html#fig:Figure8-14">8.14</a>, we can see more of the story here by
exploring the partial residuals versus each of the predictors. There are
actually quite clear relationships for each partial residual versus its
predictor. For <em>Age</em> and <em>HealthLevel</em>, the relationship after adjusting for
other predictors is clearly positive and linear. For <em>ExAmount</em> there is a clear
relationship but it is actually curving, so would violate the linearity
assumption. It is interesting that none of these were easy to see or even at all
present in plots of the response versus individual predictors. This demonstrates
the power of MLR methods to adjust/control for other variables to help us
potentially more clearly see relationships between individual predictors and the
response, or at least their part of the response.</p>

<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb756-1"><a href="chapter8.html#cb756-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(sim1, <span class="at">residuals =</span> T), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-14"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-14-1.png" alt="Term-plots with partial residuals for Cholesterol level versus three predictors (simulated data)." width="75%" />
<p class="caption">
Figure 8.14: Term-plots with partial residuals for Cholesterol level versus three predictors (simulated data).
</p>
</div>
<p>For those that are interested in these partial residuals, we can
re-construct some of the work that the <code>effects</code> package does to provide them.
As noted above, we need to take our regular residuals and add back in the
impacts of a predictor of interest to calculate the partial residuals. The
regular residuals can be extracted using the <code>residuals</code> function on the
estimated model and the contribution of, say, the <em>ExAmount</em> predictor is found
by taking the values in that variable times its estimated slope coefficient,
<span class="math inline">\(b_2 = 0.07447965\)</span>. Plotting these partial residuals versus <em>ExAmount</em> as in
Figure <a href="chapter8.html#fig:Figure8-15">8.15</a> provides a plot that is similar to the second
term-plot except for differences in the y-axis. The y-axis in term-plots
contains an additional adjustment but the two plots provide the same utility in
diagnosing a clear missed curve in the partial residuals that is related to the
<em>ExAmount</em>. Methods to incorporate polynomial functions of the predictor are
simple extensions of the <code>lm</code> work we have been doing but are beyond the scope
of this material – but you should always be checking the partial residuals to
assess the linearity assumption with each quantitative predictor and if you see
a pattern like this, seek out additional statistical resources such as the
<em>Statistical Sleuth</em> (<span class="citation"><a href="#ref-Ramsey2012" role="doc-biblioref">Ramsey and Schafer</a> (<a href="#ref-Ramsey2012" role="doc-biblioref">2012</a>)</span>) or a statistician for help.</p>

<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="chapter8.html#cb757-1" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> d1 <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">partres =</span> <span class="fu">residuals</span>(sim1) <span class="sc">+</span> ExAmount <span class="sc">*</span> <span class="fl">0.07447965</span>)</span>
<span id="cb757-2"><a href="chapter8.html#cb757-2" aria-hidden="true" tabindex="-1"></a>d1 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> ExAmount, <span class="at">y =</span> partres)) <span class="sc">+</span></span>
<span id="cb757-3"><a href="chapter8.html#cb757-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb757-4"><a href="chapter8.html#cb757-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb757-5"><a href="chapter8.html#cb757-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">se =</span> F, <span class="at">col =</span> <span class="st">&quot;darkred&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb757-6"><a href="chapter8.html#cb757-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb757-7"><a href="chapter8.html#cb757-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;Partial Residual&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-15"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-15-1.png" alt="Plot of partial residual for ExAmount with the solid line for the MLR fit for this model component and the dashed line for the smoothing line that highlights the curvilinear relationship that the model failed to account for." width="75%" />
<p class="caption">
Figure 8.15: Plot of partial residual for <code>ExAmount</code> with the solid line for the MLR fit for this model component and the dashed line for the smoothing line that highlights the curvilinear relationship that the model failed to account for.
</p>
</div>
</div>
<div id="section8-4" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Comparing multiple regression models</h2>
<p>With more than one variable, we now have many potential models that we could
consider.  We could include only one of the
predictors, all of them, or combinations of sets of the variables. For example,
maybe the model that includes <em>Elevation</em> does not “need”
both <em>Min.Temp</em> and <em>Max.Temp</em>? Or maybe the model isn’t improved over an SLR
with just <em>Elevation</em> as a predictor. Or maybe none of the predictors are
“useful?” In this section, we discuss some general model comparison issues and a
metric that can be used to pick among a suite of different models (often called
a set of <strong><em>candidate models</em></strong> to reflect that they are all potentially
interesting and we need to compare them and possibly pick one).
</p>
<p>It is certainly possible the researchers may have an <em>a priori</em>
reason to only consider a single model. For example, in a designed experiment
where combinations of, say, three different predictors are randomly assigned,
the initial model with all three predictors may be sufficient to address all the
research questions of interest. One advantage in these situations is that the
variable combinations can be created to prevent multicollinearity among the
predictors and avoid that complication in interpretations. However, this is
more the exception than the rule. Usually, there are competing predictors or
questions about whether some predictors matter more than others. This type of
research always introduces the potential for multicollinearity to complicate the
interpretation of each predictor in the presence of others. Because of this,
multiple models are often considered, where “unimportant” variables are dropped
from the model. The assessment of “importance” using p-values will be discussed
in Section <a href="chapter8.html#section8-6">8.6</a>, but for now we will consider other reasons to pick
one model over another. </p>
<p>There are some general reasons to choose a particular model:</p>
<ol style="list-style-type: decimal">
<li><p>Diagnostics are better with one model compared to others.</p></li>
<li><p>One model predicts/explains the responses better than the others
(<strong><em>R</em></strong><sup>2</sup>).</p></li>
<li><p><em>a priori</em> reasons to “use” a particular model, for example in a designed
experiment or it includes variable(s) whose estimated slopes directly address the research question(s), even if the variables are not “important” in the model.</p></li>
<li><p>Model selection “criteria” suggest one model is better than the others<a href="#fn140" class="footnote-ref" id="fnref140"><sup>140</sup></a>.</p></li>
</ol>
<p>It is OK to consider multiple reasons to select a model but it is dangerous to
“shop” for a model across many possible models – a practice which is sometimes
called <strong><em>data-dredging</em></strong> and leads to a high chance of spurious results from a
single model that is usually reported based on this type of exploration. Just
like in other discussions of
multiple testing issues previously, if you explore many versions of a model,
maybe only keeping the best ones, this is very different from picking one model
(and tests) <em>a priori</em> and just exploring that result.</p>
<p>As in SLR, we can use the <strong><em>R</em></strong><sup>2</sup> (the <strong><em>coefficient of
determination</em></strong>)  to measure the percentage of the variation in the
response variable that the model explains. In MLR, it is important to remember
that <strong><em>R</em></strong><sup>2</sup> is now an overall
measure for the model and not specific to a single variable. It is comparable to
other models including those fit with only a single predictor (SLR). So to
meet criterion (2), we could simply find the model with the largest
<strong><em>R</em></strong><sup>2</sup> value, finding the model that explains the most variation in
the responses.
Unfortunately for this idea, when you add more “stuff” to a regression model
(even “unimportant” predictors), the <strong><em>R</em></strong><sup>2</sup> will always go up. This
can be seen by considering</p>
<p><span class="math display">\[R^2 = \frac{\text{SS}_{\text{regression}}}{\text{SS}_{\text{total}}}\ 
\text{ where }\ \text{SS}_{\text{regression}} = \text{SS}_{\text{total}}
- \text{SS}_{\text{error}}\ 
\text{ and }\ \text{SS}_{\text{error}} = \Sigma(y-\widehat{y})^2\]</span></p>
<p>Because adding extra variables to a linear model will only make the fitted
values better, not worse, the <span class="math inline">\(\text{SS}_{\text{error}}\)</span> will always go down
if more predictors are added to the model. If <span class="math inline">\(\text{SS}_{\text{error}}\)</span>
goes down and <span class="math inline">\(\text{SS}_{\text{total}}\)</span> is fixed, then adding extra variables
will always increase <span class="math inline">\(\text{SS}_{\text{regression}}\)</span> and, thus, increase
<strong><em>R</em></strong><sup>2</sup>. This means that <strong><em>R</em></strong><sup>2</sup> is only useful for
selecting models when you are picking between two models of the same size
(same number of predictors). So we mainly use it as a summary of model quality
once we pick a model, not a method of picking among a set of candidate models.
Remember that <strong><em>R</em></strong><sup>2</sup> continues to have the property of being between
0 and 1 (or 0% and 100%) and that value refers to the <strong>proportion (percentage)
of variation in the response explained by the model</strong>, whether we are using it
for SLR or MLR.</p>
<p>However, there is an adjustment to the <strong><em>R</em></strong><sup>2</sup> measure that makes it
useful for selecting among models. The measure is called the <strong><em>adjusted</em></strong>
<strong><em>R</em></strong><sup>2</sup>.  The <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> measure adds a
penalty for adding more variables to the model, providing the potential for this
measure to decrease if the extra variables do not really benefit the model. The
measure is calculated as</p>
<p><span class="math display">\[R^2_{\text{adjusted}} = 1 - 
\frac{\text{SS}_{\text{error}}/df_{\text{error}}}{\text{SS}_{\text{total}}/(N-1)}
= 1 - \frac{\text{MS}_{\text{error}}}{\text{MS}_{\text{total}}},\]</span></p>
<p>which incorporates the <em>degrees of freedom</em> for the model via the error
<em>degrees of freedom</em> which go
down as the model complexity increases. This adjustment means that just
adding extra useless variables (variables that do not explain very much extra
variation) do not increase this measure. That makes this measure useful for
model selection since it can help us to stop adding unimportant variables and
find a “good” model among a set of candidates. Like the regular
<strong><em>R</em></strong><sup>2</sup>, larger values are better. The downside to
<span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> is that it <strong>is no longer a percentage
of variation in the response that is explained by the model</strong>; it can be less
than 0 and so has no interpretable scale. It is just “larger is better.” It
provides
one method for building a model (different from using p-values to drop
unimportant variables as discussed below), by fitting a set of candidate models
containing different variables and then <strong>picking the model with the largest</strong>
<span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>.

You will want to interpret this new
measure on a percentage scale, but do not do that. It is a just a measure to
help you pick a model and that is all it is!</p>
<p>One other caveat in
model comparison is worth mentioning: make sure you are comparing models for
the same responses. That may sound trivial and usually it is. But when there
are missing values in the data set, especially on some explanatory variables
and not others, it is important to be careful that the <span class="math inline">\(y\text{&#39;s}\)</span> do not
change between models you are comparing. This relates to our <em>Snow Depth</em>
modeling because responses were being removed due to their influential nature.
We can’t compare <strong><em>R</em></strong><sup>2</sup> or <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>
for <span class="math inline">\(n = 25\)</span> to a model when <span class="math inline">\(n = 23\)</span> – it isn’t a fair comparison on
either measure since they based on the total variability which is changing as
the responses used change.</p>
<p>In the MLR (or SLR) model summaries, both the <strong><em>R</em></strong><sup>2</sup> and
<span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>
are available. Make sure you are able to pick out the correct one. For the
reduced data set (<span class="math inline">\(n = 23\)</span>) <em>Snow Depth</em> models, the pertinent part of the model
summary for the model with all three predictors is in the last three lines:</p>
<div class="sourceCode" id="cb758"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb758-1"><a href="chapter8.html#cb758-1" aria-hidden="true" tabindex="-1"></a>m6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation <span class="sc">+</span> Min.Temp <span class="sc">+</span> Max.Temp, </span>
<span id="cb758-2"><a href="chapter8.html#cb758-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">data =</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>)))</span>
<span id="cb758-3"><a href="chapter8.html#cb758-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m6)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel_s %&gt;% 
##     slice(-c(9, 22)))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.878  -4.486   0.024   3.996  20.728 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -2.133e+02  7.458e+01  -2.859   0.0100
## Elevation    2.686e-02  4.997e-03   5.374 3.47e-05
## Min.Temp     9.843e-01  1.359e+00   0.724   0.4776
## Max.Temp     1.243e+00  5.452e-01   2.280   0.0343
## 
## Residual standard error: 8.832 on 19 degrees of freedom
## Multiple R-squared:  0.8535, Adjusted R-squared:  0.8304 
## F-statistic:  36.9 on 3 and 19 DF,  p-value: 4.003e-08</code></pre>
<p>There is a value for <span class="math inline">\(\large{\textbf{Multiple R-Squared}} \text{ of } 0.8535\)</span>,
this is the <strong><em>R</em></strong><sup>2</sup> value and suggests that the model with
<em>Elevation</em>, <em>Min</em> and <em>Max</em> temperatures explains 85.4% of the variation in
<em>Snow Depth</em>. The <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> is 0.8304 and is
available further to the right labeled as
<span class="math inline">\(\color{red}{{\textbf{Adjusted R-Squared}}}\)</span>. We repeated this for a
suite of different models for this same <span class="math inline">\(n = 23\)</span> data set and found the following
results in Table <a href="chapter8.html#tab:Table8-1">8.1</a>. The top <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>
model is the model with <em>Elevation</em> and <em>Max.Temp</em>, which beats out the model with
all three variables on <span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>. Note that the top
<em>R</em><sup>2</sup> model is the model with three predictors, but the most complicated model
will always have that characteristic.</p>
<!-- \newpage -->

<table style="width:100%;">
<caption><span id="tab:Table8-1">Table 8.1: </span> Model comparisons for Snow Depth data, sorted by model complexity.</caption>
<colgroup>
<col width="33%" />
<col width="10%" />
<col width="11%" />
<col width="21%" />
<col width="21%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"><strong>Model</strong>        </th>
<th align="center"><span class="math inline">\(\boldsymbol{K}\)</span></th>
<th align="right"><span class="math inline">\(\boldsymbol{R^2}\)</span></th>
<th align="right"><span class="math inline">\(\boldsymbol{R^2_{\text{adjusted}}}\)</span></th>
<th align="center"><span class="math inline">\(\boldsymbol{R^2_{\text{adjusted}}}\)</span>
<strong>Rank</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation</td>
<td align="center">1</td>
<td align="right">0.8087</td>
<td align="right">0.7996</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="left">SD <span class="math inline">\(\sim\)</span> Min.Temp</td>
<td align="center">1</td>
<td align="right">0.6283</td>
<td align="right">0.6106</td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Max.Temp</td>
<td align="center">1</td>
<td align="right">0.4131</td>
<td align="right">0.3852</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation + Min.Temp</td>
<td align="center">2</td>
<td align="right">0.8134</td>
<td align="right">0.7948</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation + Max.Temp</td>
<td align="center">2</td>
<td align="right">0.8495</td>
<td align="right">0.8344</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="left">SD <span class="math inline">\(\sim\)</span> Min.Temp + Max.Temp</td>
<td align="center">2</td>
<td align="right">0.6308</td>
<td align="right">0.5939</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="left">SD <span class="math inline">\(\sim\)</span> Elevation + Min.Temp
+ Max.Temp</td>
<td align="center">3</td>
<td align="right">0.8535</td>
<td align="right">0.8304</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>The top adjusted <strong><em>R</em></strong><sup>2</sup> model contained <em>Elevation</em> and <em>Max.Temp</em>
and has an <strong><em>R</em></strong><sup>2</sup> of 0.8495, so we can say that the model with
<em>Elevation</em> and <em>Maximum Temperature</em> explains 84.95% percent of the variation
in <em>Snow Depth</em> and also that this model was selected based on the
<span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span>. One of the important features of
<span class="math inline">\(\boldsymbol{R}^2_{\text{adjusted}}\)</span> is available in this example – adding
variables often does not always increase its value even though
<strong><em>R</em></strong><sup>2</sup> does increase with <strong>any</strong> addition. In
Section <a href="chapter8.html#section8-13">8.13</a> we consider a competitor for this model selection
criterion that may “work” a bit better and be extendable into more complicated
modeling situations; that measure is called the <strong><em>AIC</em></strong>.</p>
<div style="page-break-after: always;"></div>
</div>
<div id="section8-5" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> General recommendations for MLR interpretations and VIFs</h2>
<p>There are some important issues to remember<a href="#fn141" class="footnote-ref" id="fnref141"><sup>141</sup></a> when interpreting
regression models that can result in common mistakes.</p>
<ul>
<li><p><strong>Don’t claim to “hold everything constant” for a single individual</strong>:</p>
<p>Mathematically this is a correct interpretation of the MLR model but it is
rarely the case that we could have this occur in real applications. Is it
possible to increase the <em>Elevation</em> while holding the <em>Max.Temp</em> constant?
We discussed making term-plots doing exactly this – holding the other
variables constant at their means. If we
interpret each slope coefficient in an MLR conditionally then we can craft
interpretations such as: For locations that have a <em>Max.Temp</em> of, say,
<span class="math inline">\(45^\circ F\)</span> and <em>Min.Temp</em> of, say, <span class="math inline">\(30^\circ F\)</span>, a 1 foot increase in
<em>Elevation</em> tends to be associated with a 0.0268 inch increase in <em>Snow Depth</em>
on average. This does not try to imply that we can actually make that sort
of change but that given those other variables, the change for that variable
is a certain magnitude.</p></li>
<li><p><strong>Don’t interpret the regression results causally (or casually?)…</strong></p>
<p>Unless you are analyzing the results of a designed experiment (where the
levels of the explanatory variable(s) were randomly assigned) you cannot
state that a change in that <span class="math inline">\(x\)</span> <strong>causes</strong> a change in <span class="math inline">\(y\)</span>, especially for a
given individual. The multicollinearity in predictors makes it especially
difficult to put too much emphasis on a single slope coefficient because it
may be corrupted/modified by the other variables being in the model. In
observational studies, there are also all the potential lurking variables that
we did not measure or even confounding variables that we did measure but can’t
disentangle from the variable used in a particular model. 
While we do have a complicated mathematical model relating various
<span class="math inline">\(x\text{&#39;s}\)</span> to the response, do not lose that fundamental focus on causal
vs non-causal inferences based on the design of the study.</p></li>
<li><p><strong>Be cautious about doing prediction in MLR – you might be doing extrapolation!</strong></p>
<p>It is harder to know if you are doing extrapolation in MLR since you could be
in a region of the <span class="math inline">\(x\text{&#39;s}\)</span> that no observations were obtained. Suppose we
want to predict the <em>Snow Depth</em> for an <em>Elevation</em> of 6000 and <em>Max.Temp</em>
of 30. Is this extrapolation based on Figure <a href="chapter8.html#fig:Figure8-16">8.16</a>? In other
words, can you find any observations “nearby” in the plot of the two
variables together? What about an <em>Elevation</em> of 6000 and a <em>Max.Temp</em> of
40? The first prediction is in a different proximity to observations than
the second one… In situations with more than two explanatory variables it
becomes even more challenging to know whether you are doing extrapolation
and the problem grows as the number of dimensions to search increases… In
fact, in complicated MLR models we typically do not know whether there are
observations “nearby” if we are doing predictions for unobserved
combinations of our predictors. Note that Figure
<a href="chapter8.html#fig:Figure8-16">8.16</a> also reinforces our potential collinearity problem
between <em>Elevation</em> and <em>Max.Temp</em> with higher elevations being strongly
associated with lower temperatures.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-16"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-16-1.png" alt="Scatterplot of observed Elevations and Maximum Temperatures for SNOTEL data." width="75%" />
<p class="caption">
Figure 8.16: Scatterplot of observed Elevations and Maximum Temperatures for SNOTEL data.
</p>
</div></li>
<li><p><strong>Don’t think that the sign of a coefficient is special…</strong></p>
<p>Adding other variables into the MLR models can cause a switch in the
coefficients or change their magnitude or make them go from “important” to
“unimportant” without changing the slope too much. This is related to the
conditionality of the relationships being estimated in MLR and the potential
for sharing of information in the predictors when it is present.</p></li>
<li><p><strong>Multicollinearity in MLR models:</strong></p>
<p>When explanatory variables are not independent (related) to one another, then
including/excluding one variable will have an impact on the other variable.
Consider the correlations among the predictors in the SNOTEL data set or
visually displayed in Figure <a href="chapter8.html#fig:Figure8-17">8.17</a>:
 </p>
<p></p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="chapter8.html#cb760-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb760-2"><a href="chapter8.html#cb760-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb760-3"><a href="chapter8.html#cb760-3" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot.mixed</span>(<span class="fu">cor</span>(snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">6</span>)), </span>
<span id="cb760-4"><a href="chapter8.html#cb760-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">upper.col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">&quot;orange&quot;</span>), <span class="at">lower.col =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="st">&quot;orange&quot;</span>))</span>
<span id="cb760-5"><a href="chapter8.html#cb760-5" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cor</span>(snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="dv">3</span><span class="sc">:</span><span class="dv">6</span>)), <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-17"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-17-1.png" alt="Plot of correlation matrix in the snow depth data set with influential points removed" width="75%" />
<p class="caption">
Figure 8.17: Plot of correlation matrix in the snow depth data set with influential points removed
</p>
</div>
<pre><code>##            Snow.Depth Max.Temp Min.Temp Elevation
## Snow.Depth       1.00    -0.64    -0.79      0.90
## Max.Temp        -0.64     1.00     0.77     -0.84
## Min.Temp        -0.79     0.77     1.00     -0.91
## Elevation        0.90    -0.84    -0.91      1.00</code></pre>
<p>The predictors all share at least moderately strong linear relationships. For
example, the <span class="math inline">\(\boldsymbol{r} = -0.91\)</span> between <em>Min.Temp</em> and <em>Elevation</em>
suggests  that they contain very similar
information and that extends to other pairs of variables as well. When
variables share information, their addition to models may not improve the
performance of the model and actually can make the estimated
coefficients <strong><em>unstable</em></strong>, creating uncertainty in the correct coefficients
because of the shared information. It seems that <em>Elevation</em> is related to
<em>Snow Depth</em> but maybe it is because it has lower <em>Minimum Temperatures</em>? So
you might wonder how we can find the “correct” slopes when they are sharing
information in the response variable. The short answer is that we can’t. But
we do use <strong><em>Least Squares</em></strong> to find coefficient estimates as we did
before – except that we have to remember that these <strong>estimates are
conditional on other variables in the model</strong> for our interpretation since
they impact one another within the model. It ends up that the uncertainty
of pinning those variables down in the presence of shared information leads to
larger SEs for all the slopes. And that we can actually measure <strong>how much
each of the SEs are inflated</strong> because of multicollinearity with other
variables in the model using what are called <strong><em>Variance Inflation
Factors</em></strong> (or <strong><em>VIFs</em></strong>).</p></li>
</ul>
<p><strong><em>VIFs</em></strong> provide a way to assess the
multicollinearity in the MLR model that is caused by including specific
variables.  The amount of information that is
shared between a single explanatory variable and the others can be found by
regressing that variable on the others and calculating <strong><em>R</em></strong><sup>2</sup>
for that model. The code for this regression is something like:
<code>lm(X1 ~ X2 + X3 + ... + XK)</code>, which regresses <em>X1</em>on <em>X2</em> through <em>XK</em>.

The
<span class="math inline">\(1-\boldsymbol{R}^2\)</span> from this regression is the amount of independent
information in <em>X1</em> that is not explained by (or related to) the other variables in the model. 
The VIF for each variable is defined using this quantity as
<span class="math inline">\(\textbf{VIF}_{\boldsymbol{k}}\boldsymbol{=1/(1-R^2_k)}\)</span> for variable <span class="math inline">\(k\)</span>.
If there is no shared information <span class="math inline">\((\boldsymbol{R}^2 = 0)\)</span>, then the VIF will be
1. But if the information is completely shared with other variables
<span class="math inline">\((\boldsymbol{R}^2 = 1)\)</span>, then the VIF goes to infinity (1/0). Basically, large
VIFs are bad, with the rule of thumb that values over 5 or 10 are considered
“large” values indicating high (over 5) or extreme (over 10) multicollinearity in the model for that particular
variable, both indicating that slope coefficients are dangerous to interpret in that model. We use this scale to determine if multicollinearity is a definite problem for a
variable of interest. But any value of the VIF over 1 indicates some amount of multicollinearity is present. Additionally, the <span class="math inline">\(\boldsymbol{\sqrt{\textbf{VIF}_k}}\)</span> is
also very interesting as it is the number of times larger than the SE for the
slope for variable <span class="math inline">\(k\)</span> is due to collinearity with other variables in the model.
The square-root scale is the most useful scale to understand VIFs and allows you to make your own assessment of whether you think the multicollinearity is “important” based on how inflated the SEs are in a particular situation. An example will show how to easily get these results
and where the results come from.</p>
<p>In general, the easy way to obtain VIFs is using the <code>vif</code> function from the
<code>car</code> package (<span class="citation"><a href="#ref-R-carData" role="doc-biblioref">Fox, Weisberg, and Price</a> (<a href="#ref-R-carData" role="doc-biblioref">2020</a>)</span>, <span class="citation"><a href="#ref-Fox2003" role="doc-biblioref">Fox</a> (<a href="#ref-Fox2003" role="doc-biblioref">2003</a>)</span>).
 
It has the advantage of also providing a reasonable
result when we include categorical variables in models
(Sections <a href="chapter8.html#section8-9">8.9</a> and <a href="chapter8.html#section8-11">8.11</a>). We apply the <code>vif</code>
function directly to a model of interest and it generates values for each explanatory variable.</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="chapter8.html#cb762-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb762-2"><a href="chapter8.html#cb762-2" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(m6)</span></code></pre></div>
<pre><code>## Elevation  Min.Temp  Max.Temp 
##  8.164201  5.995301  3.350914</code></pre>
<p>Not surprisingly, there is an indication of problems with multicollinearity in
two of the three variables in the model with the largest issues identified for
<em>Elevation</em> and <em>Min.Temp</em>. Both of their VIFs exceed 5 indicating high levels of
multicollinearity impacting those terms in the model. On the square-root scale, the VIFs show more
interpretation utility.</p>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="chapter8.html#cb764-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">vif</span>(m6))</span></code></pre></div>
<pre><code>## Elevation  Min.Temp  Max.Temp 
##  2.857307  2.448530  1.830550</code></pre>
<p>The result for <em>Elevation</em> of 2.86 suggests that the SE for <em>Elevation</em> is 2.86
times larger than it should be because of multicollinearity with other variables
in the model. Similarly, the <em>Min.Temp</em> SE is 2.45 times larger and the
<em>Max.Temp</em> SE is 1.83 times larger. Even the result for <em>Max.Temp</em> suggests an issue with multicollinearity even though it is below the cut-off for noting high or extreme issues with shared information. All of this generally suggests issues with
multicollinearity in the model and that we need to be cautious in interpreting
any slope coefficients from this model because they are all being impacted by shared information in the predictor variables to some degree or another.</p>
<p>In order to see how the VIF is calculated for <em>Elevation</em>, we need to
regress <em>Elevation</em> on <em>Min.Temp</em> and <em>Max.Temp</em>. Note that this model is only
fit to find the percentage of variation in elevation explained by the temperature
variables. It ends up being 0.8775 – so a high percentage of <em>Elevation</em> can be
explained by the linear model using min and max temperatures.</p>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="chapter8.html#cb766-1" aria-hidden="true" tabindex="-1"></a><span class="co"># VIF calc:</span></span>
<span id="cb766-2"><a href="chapter8.html#cb766-2" aria-hidden="true" tabindex="-1"></a>elev1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Elevation <span class="sc">~</span> Min.Temp <span class="sc">+</span> Max.Temp, <span class="at">data =</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>)))</span>
<span id="cb766-3"><a href="chapter8.html#cb766-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(elev1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Elevation ~ Min.Temp + Max.Temp, data = snotel_s %&gt;% 
##     slice(-c(9, 22)))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1120.05  -142.99    14.45   186.73   624.61 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 14593.21     699.77  20.854 4.85e-15
## Min.Temp     -208.82      38.94  -5.363 3.00e-05
## Max.Temp      -56.28      20.90  -2.693    0.014
## 
## Residual standard error: 395.2 on 20 degrees of freedom
## Multiple R-squared:  0.8775, Adjusted R-squared:  0.8653 
## F-statistic: 71.64 on 2 and 20 DF,  p-value: 7.601e-10</code></pre>
<p>Using this result, we can calculate</p>
<p><span class="math display">\[\text{VIF}_{\text{elevation}} = \dfrac{1}{1-R^2_{\text{elevation}}} = \dfrac{1}{1-0.8775} = \dfrac{1}{0.1225} = 8.16\]</span></p>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="chapter8.html#cb768-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fl">0.8775</span></span></code></pre></div>
<pre><code>## [1] 0.1225</code></pre>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="chapter8.html#cb770-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span><span class="fl">0.1225</span></span></code></pre></div>
<pre><code>## [1] 8.163265</code></pre>
<p>Note that when we observe small VIFs (close to 1), that provides us with confidence that
multicollinearity is not causing problems under the surface of
a particular MLR model and that we can trust that the coefficients will not change dramatically based on whether the other terms in the model are removed. Also note that we can’t use the VIFs to do anything about
multicollinearity in the models – it is just a diagnostic to understand the
magnitude of the problem.</p>
</div>
<div id="section8-6" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> MLR inference: Parameter inferences using the t-distribution</h2>
<p>I have been deliberately vague about what an important variable is up to this
point, and chose to focus on some bigger modeling issues. Now we turn our
attention to one
of the most common tasks in any basic statistical model – assessing whether a
particular observed result is more unusual than we would expect by chance if it really wasn’t related to the response. The
previous discussions of estimation in MLR models informs our interpretations of
of the tests.

The <span class="math inline">\(t\)</span>-tests for slope coefficients are based on our standard
recipe – take the estimate, divide it by its standard error and then, assuming
the statistic follows a <span class="math inline">\(t\)</span>-distribution under the null hypothesis, find a
p-value.

This tests whether each true slope coefficient, <span class="math inline">\(\beta_k\)</span>, is 0 or not,
in a model that contains the other variables. Again, sometimes we say
“after adjusting for” the other <span class="math inline">\(x\text{&#39;s}\)</span> or
“conditional on” the other <span class="math inline">\(x\text{&#39;s}\)</span> in the model or “after allowing for”…
as in the slope coefficient interpretations above. The main point is that
<strong>you should not interpret anything related to slope coefficients in MLR without
referencing the other variables that are in the model!</strong> The tests for the
slope coefficients assess <span class="math inline">\(\boldsymbol{H_0:\beta_k = 0}\)</span>, which in words is
a test that there is no linear relationship between explanatory variable <span class="math inline">\(k\)</span>
and the response variable, <span class="math inline">\(y\)</span>, in the population, given the other variables in
model. The typical alternative hypothesis is <span class="math inline">\(\boldsymbol{H_0:\beta_k\ne 0}\)</span>.
In words, the alternative hypothesis is that there is some linear relationship
between explanatory variable <span class="math inline">\(k\)</span> and the response variable, <span class="math inline">\(y\)</span>, in the population,
given the other variables in the model. It is also possible to test for positive
or negative slopes in the alternative, but this is rarely the first concern,
especially when MLR slopes can occasionally come out in unexpected directions.</p>
<p>The test statistic for these hypotheses is
<span class="math inline">\(\boldsymbol{t = \dfrac{b_k}{\textbf{SE}_k}}\)</span> and, if our assumptions hold,
follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-K-1\)</span> <em>df</em> where <span class="math inline">\(K\)</span> is the number of
predictor variables in the model.

We perform the test for each slope
coefficient, but the test is conditional on the other variables in the model – the order the variables are fit in does
<strong>not</strong> change <span class="math inline">\(t\)</span>-test results. For the <em>Snow Depth</em> example with <strong>Elevation</strong>
and <em>Maximum Temperature</em> as predictors, the pertinent output is in the four
columns of the <strong><em>Coefficient table</em></strong> that is the first part of the model
summary we’ve been working with. You can find the estimated slope
(<code>Estimate</code> column), the SE of the slopes (<code>Std. Error</code> column), the
<span class="math inline">\(t\)</span>-statistics (<code>t value</code> column), and the p-values (<code>Pr(&gt;|t|)</code> column).
The degrees of freedom for the <span class="math inline">\(t\)</span>-distributions show up below the coefficients
and the <span class="math inline">\(df = 20\)</span> here. This is because <span class="math inline">\(n = 23\)</span> and <span class="math inline">\(K = 2\)</span>, so <span class="math inline">\(df = 23-2-1 = 20\)</span>.</p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="chapter8.html#cb772-1" aria-hidden="true" tabindex="-1"></a>m5 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation <span class="sc">+</span> Max.Temp, <span class="at">data =</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>)))</span>
<span id="cb772-2"><a href="chapter8.html#cb772-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m5)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Snow.Depth ~ Elevation + Max.Temp, data = snotel_s %&gt;% 
##     slice(-c(9, 22)))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -14.652  -4.645   0.518   3.744  20.550 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -1.675e+02  3.924e+01  -4.269 0.000375
## Elevation    2.407e-02  3.162e-03   7.613 2.48e-07
## Max.Temp     1.253e+00  5.385e-01   2.327 0.030556
## 
## Residual standard error: 8.726 on 20 degrees of freedom
## Multiple R-squared:  0.8495, Adjusted R-squared:  0.8344 
## F-statistic: 56.43 on 2 and 20 DF,  p-value: 5.979e-09</code></pre>
<p>The hypotheses for the <em>Maximum Temperature</em> term (<em>Max.Temp</em>) are:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{H_0: \beta_{\textbf{Max.Temp}} = 0}\)</span> <strong>given that</strong> <strong><em>Elevation</em></strong>
<strong>is in the model vs</strong></p></li>
<li><p><span class="math inline">\(\boldsymbol{H_A: \beta_{\textbf{Max.Temp}}\ne 0}\)</span> <strong>given that</strong>
<strong><em>Elevation</em></strong> <strong>is in the model.</strong></p></li>
</ul>
<p>The test statistic is <span class="math inline">\(t = 2.327\)</span> with <span class="math inline">\(df = 20\)</span> (so under the null hypothesis
the test statistic follows a <span class="math inline">\(t_{20}\)</span>-distribution).</p>
<p>The output provides a p-value of <span class="math inline">\(0.0306\)</span> for this test. We can also find this
using <code>pt</code>:

</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="chapter8.html#cb774-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(<span class="fl">2.327</span>, <span class="at">df =</span> <span class="dv">20</span>, <span class="at">lower.tail =</span> F)</span></code></pre></div>
<pre><code>## [1] 0.03058319</code></pre>
<p>The chance of observing a
slope for <em>Max.Temp</em> as extreme or more extreme than assuming there really is no
linear relationship between <em>Max.Temp</em> and <em>Snow Depth</em> (in a model with
<em>Elevation</em>), is about 3% so this presents moderate evidence against the null hypothesis, in favor of retaining this term in the model.</p>
<p>Conclusion: There is moderate evidence against the null hypothesis of no linear
relationship between <em>Max.Temp</em> and <em>Snow Depth</em> (<span class="math inline">\(t_{20} = 2.33\)</span>, p-value = 0.03), once we account for
<em>Elevation</em>, so we can conclude that there likely is a linear relationship between them given <em>Elevation</em> in the population of SNOTEL sites in Montana on this day and we should retain this term in the model. Because
we cannot randomly assign the temperatures to sites, we cannot conclude that
temperature causes changes in the snow depth – in fact it might even be
possible for a location to have different temperatures because of different
snow depths. The inferences do pertain to the population of SNOTEL sites on this day because of the random sample from the population of sites. </p>
<!-- \newpage -->
<p>Similarly, we can test for <em>Elevation</em> after controlling for the <em>Maximum Temperature</em>:</p>
<p><span class="math display">\[\boldsymbol{H_0: \beta_{\textbf{Elevation}} = 0 \textbf{ vs } H_A: \beta_{\textbf{Elevation}}\ne 0},\]</span></p>
<p>given that <em>Max.Temp</em> is in the model:</p>
<p><span class="math inline">\(t = 7.613\)</span> (<span class="math inline">\(df = 20\)</span>) with a p-value of <span class="math inline">\(0.00000025\)</span> or just <span class="math inline">\(&lt;0.00001\)</span>.</p>
<p>So there is strong evidence against the null hypothesis of no linear relationship between <em>Elevation</em> and <em>Snow Depth</em>, once we adjust for <em>Max.Temp</em> in the population of SNOTEL
sites in Montana on this day, so we would conclude that they are linearly related and that we should retain the <em>Elevation</em> predictor in the model with <em>Max.Temp</em>.</p>
<p>There is one last test that is of dubious interest in almost every
situation – to test that the <span class="math inline">\(y\)</span>-intercept <span class="math inline">\((\boldsymbol{\beta_0})\)</span> in an MLR
is 0. This tests if the
true mean response is 0 when all the predictor variables are set to 0. I see
researchers reporting this p-value frequently and it is possibly the most
useless piece of information in the regression model summary.

Sometimes less
educated statistics users even think this result is proof of something interesting
or are disappointed when the p-value is not small. Unless you want to do some
prediction and are interested in whether the mean response when all the
predictors are set to 0 is different from 0, this test should not be reported
or, if reported, is certainly not very interesting<a href="#fn142" class="footnote-ref" id="fnref142"><sup>142</sup></a>.

But we should at least go through the motions on this
test once so you don’t make the same mistakes:</p>
<p><span class="math inline">\(\boldsymbol{H_0: \beta_0 = 0 \textbf{ vs } H_A: \beta_0\ne 0}\)</span> in a model with
<em>Elevation</em> and <em>Maximum Temperature</em>.</p>
<p><span class="math inline">\(t = -4.269\)</span>, with an assumption that the test statistic follows a
<span class="math inline">\(t_{20}\)</span>-distribution under the null hypothesis, and the p-value <span class="math inline">\(= 0.000375\)</span>.</p>
<p>There is strong evidence against the null hypothesis that the true mean
<em>Snow Depth</em> is 0 when the <em>Maximum Temperature</em> is 0 and the
<em>Elevation</em> is 0 in the population of SNOTEL sites, so we could conclude that the true mean Snow Depth is different from 0 at these values of the predictors. To reinforce the general
uselessness of this test, think about the combination of <span class="math inline">\(x\text{&#39;s}\)</span> – is that
even physically possible in Montana (or the continental US) in April?</p>
<p>Remember when testing slope coefficients in MLR, that if we find weak evidence against the null hypothesis, it does not mean that there is no relationship or
even no linear
relationship between the variables, but that there is insufficient evidence against the null hypothesis of no linear
relationship <strong>once we account for the other variables in the model</strong>. If you do
not find a small p-value for a variable, you should
either be cautious when interpreting the coefficient, or not interpret it. Some
model building strategies would lead to dropping the term from the model but
sometimes we will have models to interpret that contain terms with larger
p-values. Sometimes they are still of interest but the weight on the
interpretation isn’t as heavy as if the term had a small p-value – you should
remember that you can’t prove that coefficient is different from 0 in that
model. It also may mean that you don’t know too much about its specific value.
Confidence intervals will help us pin down where we think the true slope
coefficient might be located, given the other variables in the model, and so are usually pretty interesting to report, regardless of how you approached model building and possible refinement.</p>
<p>Confidence intervals provide the dual uses of inferences for the
location of the true slope and whether the true slope seems to be different
from 0. The confidence intervals here have our regular format of estimate
<span class="math inline">\(\mp\)</span> margin of error. Like the previous tests,
we work with <span class="math inline">\(t\)</span>-distributions with <span class="math inline">\(n-K-1\)</span> degrees of freedom.


Specifically
the 95% confidence interval for slope coefficient <span class="math inline">\(k\)</span> is</p>
<p><span class="math display">\[\boldsymbol{b_k \mp t^*_{n-K-1}\textbf{SE}_{b_k}}\]</span></p>
<p>The interpretation is the same as in SLR with the additional tag of “after
controlling for the other variables in the model” for the reasons
discussed before. The general slope CI interpretation for predictor
<span class="math inline">\(\boldsymbol{x_k}\)</span> in an MLR is:
</p>
<blockquote>
<p>For a 1 <strong>[<em>unit of <span class="math inline">\(\boldsymbol{x_k}\)</span></em>]</strong> increase in <span class="math inline">\(\boldsymbol{x_k}\)</span>, we
are 95% confident that the true mean of <span class="math inline">\(\boldsymbol{y}\)</span> changes by between
<strong>LL</strong> and <strong>UL</strong> <strong>[<em>units of <span class="math inline">\(\boldsymbol{Y}\)</span></em>]</strong> in the population, after
adjusting for the other <span class="math inline">\(x\text{&#39;s}\)</span> <strong>[list them!]</strong>.</p>
</blockquote>
<p>We can either calculate these intervals as we have many times before or
rely on the <code>confint</code> function to do this:</p>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="chapter8.html#cb776-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(m5)</span></code></pre></div>
<pre><code>##                     2.5 %       97.5 %
## (Intercept) -249.37903311 -85.67576239
## Elevation      0.01747878   0.03067123
## Max.Temp       0.13001718   2.37644112</code></pre>
<p>So for a <span class="math inline">\(1^\circ F\)</span> increase in <em>Maximum Temperature</em>, we are 95% confident
that the true mean <em>Snow Depth</em> will change by between 0.13 and 2.38 inches
in the population, after adjusting for the <em>Elevation</em> of the sites. Similarly,
for a 1 foot increase in <em>Elevation</em>, we are 95% confident that the true mean
<em>Snow Depth</em> will change by between 0.0175 and 0.0307 inches in the population,
after adjusting for the <em>Maximum Temperature</em> of the sites.</p>
</div>
<div id="section8-7" class="section level2" number="8.7">
<h2><span class="header-section-number">8.7</span> Overall F-test in multiple linear regression</h2>
<p>In the MLR summary, there is an <span class="math inline">\(F\)</span>-test and p-value reported at the bottom
of the output. For the model with <em>Elevation</em> and <em>Maximum Temperature</em>, the
last row of the model summary is:</p>
<pre><code>## F-statistic: 56.43 on 2 and 20 DF, p-value: 5.979e-09</code></pre>
<p>This test is called the <strong><em>overall F-test</em></strong> in MLR and is very similar to
the <span class="math inline">\(F\)</span>-test in a reference-coded One-Way ANOVA model.

It tests the null
hypothesis that involves setting every coefficient except the <span class="math inline">\(y\)</span>-intercept to
0 (so all the slope coefficients equal 0). We saw this reduced model in the
One-Way material when we considered setting all the deviations from the
baseline group to 0 under the null hypothesis. We can frame this as a
comparison between a full and reduced model as follows:</p>
<ul>
<li><p><strong><em>Full Model:</em></strong>   <span class="math inline">\(y_i = \beta_0 + \beta_1x_{1i} + \beta_2x_{2i}+\cdots + \beta_Kx_{Ki}+\varepsilon_i\)</span></p></li>
<li><p><strong><em>Reduced Model:</em></strong>   <span class="math inline">\(y_i = \beta_0 + 0x_{1i} + 0x_{2i}+\cdots + 0x_{Ki}+\varepsilon_i\)</span></p></li>
</ul>
<p>The reduced model estimates the same values for all <span class="math inline">\(y\text{&#39;s}\)</span>,
<span class="math inline">\(\widehat{y}_i = \bar{y} = b_0\)</span> and corresponds to the null hypothesis of:</p>
<p><span class="math inline">\(\boldsymbol{H_0:}\)</span> <strong>No explanatory variables should be included in the model:</strong> <span class="math inline">\(\beta_1 = \beta_2 = \cdots = \beta_K = 0\)</span>.</p>
<p>The full model corresponds to the alternative:</p>
<p><span class="math inline">\(\boldsymbol{H_A:}\)</span> <strong>At least one explanatory variable should be included in the model: Not all</strong> <span class="math inline">\(\beta_k\text{&#39;s} = 0\)</span> for <span class="math inline">\((k = 1,\ldots,K)\)</span>.</p>
<p>Note that <span class="math inline">\(\beta_0\)</span> is not set to 0 in the reduced model (under the null
hypothesis) – it becomes the true mean of <span class="math inline">\(y\)</span> for all values of the
<span class="math inline">\(x\text{&#39;s}\)</span> since all the predictors are multiplied by coefficients of 0.</p>
<p>The test statistic to assess these hypotheses is
<span class="math inline">\(F = \text{MS}_{\text{model}}/\text{MS}_E\)</span>, which is assumed to follow an
<span class="math inline">\(F\)</span>-distribution with <span class="math inline">\(K\)</span> numerator <em>df</em> and <span class="math inline">\(n-K-1\)</span> denominator <em>df</em> under the
null hypothesis.

The output provides us with <span class="math inline">\(F(2, 20) = 56.43\)</span> and a p-value
of <span class="math inline">\(5.979*10^{-9}\)</span> (p-value <span class="math inline">\(&lt;0.00001\)</span>)
and strong evidence against the null hypothesis. Thus, there is strong evidence against the null hypothesis that the true slopes for the two predictors are 0 and so we would conclude that
at least one of the two slope coefficients (<em>Max.Temp</em>’s or <em>Elevation</em>’s) is
different from 0 in the population of SNOTEL sites in Montana on this date.
While this test is a little bit interesting and a good indicator of something
interesting existing in the model, the moment you see this result, you want to know more
about each predictor variable. If neither predictor variable is important, we
will discover that in the <span class="math inline">\(t\)</span>-tests for each coefficient and so our general recommendation is to start there.</p>
<p>The overall F-test, then, is really about testing whether there is something
good in the model somewhere.

And that certainly is important but it is also not
too informative. There is one situation where this test is really interesting,
when there is only one predictor variable in the model (SLR). In that situation,
this test provides exactly the same p-value as the <span class="math inline">\(t\)</span>-test. <span class="math inline">\(F\)</span>-tests will be
important when we are mixing categorical and quantitative predictor variables
in our MLR models (Section <a href="chapter8.html#section8-12">8.12</a>), but the overall <span class="math inline">\(F\)</span>-test is of
<strong>very</strong> limited utility.</p>
</div>
<div id="section8-8" class="section level2" number="8.8">
<h2><span class="header-section-number">8.8</span> Case study: First year college GPA and SATs</h2>
<p>Many universities require students to have certain test scores in order to be
admitted into their institutions. They
obviously must think that those scores are useful predictors of student success
to use them in this way. Quality assessments of recruiting classes are also
based on their test scores. The Educational Testing Service (the company behind
such fun exams as the SAT and GRE) collected a data set to validate their SAT
on <span class="math inline">\(n = 1000\)</span> students from an unnamed Midwestern university; the data set is
available in the <code>openintro</code> package <span class="citation">(<a href="#ref-R-openintro" role="doc-biblioref">Çetinkaya-Rundel et al. 2021</a>)</span>
in the <code>satgpa</code> data set.

It is unclear from the documentation whether a
random sample was collected, in fact it looks like it certainly wasn’t a random
sample of all incoming students at a large university (more later). What
potential issues would arise if a company was providing a data set to show the
performance of their test and it was not based on a random sample?</p>
<p>We will proceed assuming they used good methods in developing their test
(there are sophisticated
statistical models underlying the development of the SAT and GRE) and also in
obtaining a data set for testing out the performance of their tests that is at
least representative of the students (or some types of students) at this
university. They<a href="#fn143" class="footnote-ref" id="fnref143"><sup>143</sup></a> provided information on the <em>SAT Verbal</em> (<code>satv</code>)
and <em>Math</em> (<code>satm</code>) percentiles (these are not the scores but the ranking
percentile that each score translated to in a particular year),
<em>High School GPA</em> (<code>hsgpa</code>), <em>First Year</em> of college <em>GPA</em> (<code>fygpa</code>), <em>Gender</em> (<code>gender</code> of the students coded 1 and 2 with possibly 1 for males and 2 for females – the documentation was also unclear this). Should <code>gender</code> even be displayed in a plot with correlations since it is a categorical variable?<a href="#fn144" class="footnote-ref" id="fnref144"><sup>144</sup></a> Our interests here are in whether the two SAT percentiles are (together?)
related to the first year college GPA, describing the size of their impacts
and assessing the predictive potential of SAT-based measures for first year in
college GPA. There are certainly other possible research questions that can be
addressed with these data but this will keep us focused.
</p>

<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb779-1"><a href="chapter8.html#cb779-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(openintro)</span>
<span id="cb779-2"><a href="chapter8.html#cb779-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(satgpa)</span>
<span id="cb779-3"><a href="chapter8.html#cb779-3" aria-hidden="true" tabindex="-1"></a>satgpa <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(satgpa)</span>
<span id="cb779-4"><a href="chapter8.html#cb779-4" aria-hidden="true" tabindex="-1"></a>satgpa <span class="ot">&lt;-</span> satgpa <span class="sc">%&gt;%</span> <span class="fu">rename</span>(<span class="at">gender =</span> sex , <span class="co">#Renaming variables </span></span>
<span id="cb779-5"><a href="chapter8.html#cb779-5" aria-hidden="true" tabindex="-1"></a>                            <span class="at">satv =</span> sat_v, <span class="at">satm =</span> sat_m, <span class="at">satsum =</span> sat_sum, </span>
<span id="cb779-6"><a href="chapter8.html#cb779-6" aria-hidden="true" tabindex="-1"></a>                            <span class="at">hsgpa =</span> hs_gpa, </span>
<span id="cb779-7"><a href="chapter8.html#cb779-7" aria-hidden="true" tabindex="-1"></a>                            <span class="at">fygpa =</span> fy_gpa) </span>
<span id="cb779-8"><a href="chapter8.html#cb779-8" aria-hidden="true" tabindex="-1"></a>satgpa <span class="sc">%&gt;%</span> </span>
<span id="cb779-9"><a href="chapter8.html#cb779-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="dv">4</span>) <span class="sc">%&gt;%</span></span>
<span id="cb779-10"><a href="chapter8.html#cb779-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggpairs</span>() <span class="sc">+</span> </span>
<span id="cb779-11"><a href="chapter8.html#cb779-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-18"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-18-1.png" alt="Scatterplot matrix of SAT and GPA data set." width="75%" />
<p class="caption">
Figure 8.18: Scatterplot matrix of SAT and GPA data set.
</p>
</div>
<p>There are positive relationships in Figure <a href="chapter8.html#fig:Figure8-18">8.18</a> among all the
pre-college measures and the <em>college GPA</em> but none are above the moderate
strength level. The <em>hsgpa</em> has a highest correlation with
first year of college results but its correlation is not that strong. Maybe
together in a model the SAT percentiles can also be useful? Also note this plot
shows an odd <em>hsgpa</em> of 4.5 that probably should be removed<a href="#fn145" class="footnote-ref" id="fnref145"><sup>145</sup></a> if that variable is going to be used (<em>hsgpa</em>
was not used in the following models so the observation remains in the data).</p>
<!-- \newpage -->
<p>In MLR, the modeling process is a bit more complex and often involves
more than one model, so we will often avoid the 6+ steps in testing initially
and try to generate a model we can use in that more specific process. In this
case, the first model of interest using the two SAT percentiles,</p>
<p><span class="math display">\[\text{fygpa}_i = \beta_0 + \beta_{\text{satv}}\text{satv}_i + \beta_{\text{satm}}\text{satm}_i +\varepsilon_i,\]</span></p>
<p>looks like it might be worth interrogating further so we can jump straight
into considering the 6+ steps involved in hypothesis testing for the two slope
coefficients to address our RQ about assessing the predictive ability and relationship of the SAT scores on first year college GPA.

We will use <span class="math inline">\(t\)</span>-based
inferences, assuming that we can trust the assumptions and the initial plots get us some idea of the potential relationship.</p>
<p>Note that this is not a randomized experiment but we can assume that
it is representative of the students at that
single university. We would not want to extend these inferences to other
universities (who might be more or less selective) or to students who did not
get into this university and, especially, not to students that failed to complete
the first year. The second and third constraints point to a severe limitation
in this research – only students who were accepted, went to, and finished one
year at this university could be studied. Lower SAT percentile students might
not have been allowed in or may not have finished the first year and higher SAT
students might have been attracted to other more prestigious institutions. So
the scope of inference is just limited to students that were invited and chose
to attend this institution and successfully completed one year of courses. It
is hard to know if the SAT “works” when the inferences are so restricted in who
they might apply to… But you could see why the company that administers the SAT might want to analyze these data. Educational researchers and institutional admissions offices also often focus on predicting first year retention rates, but that is a categorical response variable (retained/not) and so not compatible with the linear models considered here.</p>
<p>The following code fits the model of interest, provides a model summary,
and the diagnostic plots, allowing us to consider the tests of interest:</p>

<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="chapter8.html#cb780-1" aria-hidden="true" tabindex="-1"></a>gpa1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(fygpa <span class="sc">~</span> satv <span class="sc">+</span> satm, <span class="at">data =</span> satgpa)</span>
<span id="cb780-2"><a href="chapter8.html#cb780-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(gpa1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = fygpa ~ satv + satm, data = satgpa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.19647 -0.44777  0.02895  0.45717  1.60940 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.007372   0.152292   0.048    0.961
## satv        0.025390   0.002859   8.879  &lt; 2e-16
## satm        0.022395   0.002786   8.037 2.58e-15
## 
## Residual standard error: 0.6582 on 997 degrees of freedom
## Multiple R-squared:  0.2122, Adjusted R-squared:  0.2106 
## F-statistic: 134.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="chapter8.html#cb782-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb782-2"><a href="chapter8.html#cb782-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gpa1, <span class="at">sub.caption =</span> <span class="st">&quot;Diagnostics for GPA model with satv and satm&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-19"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-19-1.png" alt="Diagnostic plots for the \(\text{fygpa}\sim\text{satm} + \text{satm}\) model." width="75%" />
<p class="caption">
Figure 8.19: Diagnostic plots for the <span class="math inline">\(\text{fygpa}\sim\text{satm} + \text{satm}\)</span> model.
</p>
</div>
<div style="page-break-after: always;"></div>
<ol style="list-style-type: decimal">
<li><p>Hypotheses of interest:</p>
<ul>
<li><p><span class="math inline">\(H_0: \beta_\text{satv} = 0\)</span> given <em>satm</em> in the model vs
<span class="math inline">\(H_A: \beta_\text{satv}\ne 0\)</span> given <em>satm</em> in the model.</p></li>
<li><p><span class="math inline">\(H_0: \beta_\text{satm} = 0\)</span> given <em>satv</em> in the model vs
<span class="math inline">\(H_A: \beta_\text{satm}\ne 0\)</span> given <em>satv</em> in the model.</p></li>
</ul></li>
<li><p>Plot the data and assess validity conditions:</p>
<ul>
<li><p><strong>Quantitative variables condition:</strong></p>
<ul>
<li>The variables used here in this model are quantitative. Note that <em>Gender</em> was
plotted in the previous scatterplot matrix and is not quantitative –
we will explore its use later.</li>
</ul></li>
</ul>
<p><!-- \newpage --></p>
<ul>
<li><p><strong>Independence of observations:</strong></p>
<ul>
<li>With a sample from a single university from (we are assuming) a
single year of students, there is no particular reason to assume a
violation of the independence assumption. If there was information about
students from different years being included or maybe even from
different colleges in the university in a single year, we might worry
about systematic differences in the GPAs and violations of the
independence assumption. We can’t account for either and there is
possibly not a big difference in the GPAs across colleges to be
concerned about, especially with a sample of students from a large
university.</li>
</ul></li>
<li><p><strong>Linearity of relationships:</strong></p>
<ul>
<li><p>The initial scatterplots (Figure <a href="chapter8.html#fig:Figure8-18">8.18</a>) do not show
any clear nonlinearities with each predictor used in this model.</p></li>
<li><p>The Residuals vs Fitted and Scale-Location plots (Figure
<a href="chapter8.html#fig:Figure8-19">8.19</a>) do not show much more than a football shape,
which is our desired result.</p></li>
<li><p>The partial residuals are displayed in Figure <a href="chapter8.html#fig:Figure8-20">8.20</a>
and do not suggest any clear missed curvature.</p>
<ul>
<li>Together, there is no suggestion of a violation of the linearity
assumption.</li>
</ul></li>
</ul></li>
<li><p><strong>Multicollinearity checked for:</strong></p>
<ul>
<li><p>The original scatterplots suggest that there is some collinearity
between the two SAT percentiles with a correlation of 0.47. That is
actually a bit lower than one might expect and suggests that each
score must be measuring some independent information about different
characteristics of the students.</p></li>
<li><p>VIFs also do not suggest a major issue with multicollinearity in the
model with the VIFs for both variables the same at 1.278<a href="#fn146" class="footnote-ref" id="fnref146"><sup>146</sup></a>. This suggests that both SEs are about 13% larger than they
otherwise would have been due to shared information between the two
predictor variables. </p></li>
</ul>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="chapter8.html#cb783-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(gpa1)</span></code></pre></div>
<pre><code>##     satv     satm 
## 1.278278 1.278278</code></pre>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="chapter8.html#cb785-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fu">vif</span>(gpa1))</span></code></pre></div>
<pre><code>##    satv    satm 
## 1.13061 1.13061</code></pre></li>
<li><p><strong>Equal (constant) variance:</strong></p>
<ul>
<li>There is no clear change in variability as a function of fitted
values so no indication of a violation of the constant variance of
residuals assumption.</li>
</ul></li>
<li><p><strong>Normality of residuals:</strong></p>
<ul>
<li>There is a minor deviation in the upper tail of the residual
distribution from normality. It is not pushing towards having larger
values than a normal distribution would generate so should not cause us
any real problems with inferences from this model. Note that this upper
limit is likely due to using GPA as a response variable and it has an
upper limit. This is an example of a potentially <strong><em>censored</em></strong>
variable.  For a continuous variable it is possible
that the range of a measurement scale doesn’t distinguish among subjects
who differ once they pass a certain point. For example, a 4.0 high
school student is likely going to have a high first year college GPA, on
average, but there is no room for variability in college GPA up, just
down once you are at the top of the GPA scale. For students more in the
middle of the range, they can vary up or down. So in some places you can
get symmetric distributions around the mean and in others you cannot.
There are specific statistical models for these types of responses that
are beyond our scope. In this situation, failing to account for the
censoring may push some slopes toward 0 a little because we can’t have
responses over 4.0 in college GPA to work with.</li>
</ul></li>
<li><p><strong>No influential points:</strong></p>
<ul>
<li>There are no influential points. In large data sets, the influence
of any point is decreased and even high leverage and outlying points
can struggle to have any impacts at all on the results.</li>
</ul></li>
</ul></li>
</ol>
<p>So we are fairly comfortable with all the assumptions being at least not clearly
violated and so the inferences from our model should be relatively trustworthy.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Calculate the test statistics and p-values:</p>
<ul>
<li><p>For <em>satv</em>: <span class="math inline">\(t = \dfrac{0.02539}{0.002859} = 8.88\)</span> with the <span class="math inline">\(t\)</span> having
<span class="math inline">\(df = 997\)</span> and p-value <span class="math inline">\(&lt;0.0001\)</span>.</p></li>
<li><p>For <em>satm</em>: <span class="math inline">\(t = \dfrac{0.02240}{0.002786} = 8.04\)</span> with the <span class="math inline">\(t\)</span> having
<span class="math inline">\(df = 997\)</span> and p-value <span class="math inline">\(&lt;0.0001\)</span>.</p></li>
</ul></li>
<li><p>Conclusions:</p>
<ul>
<li><p>For <em>satv</em>: There is strong evidence against the null hypothesis of
no linear relationship between <em>satv</em> and <em>fygpa</em> (<span class="math inline">\(t_{997} = 8.88\)</span>,
p-value &lt; 0.0001) and conclude that, in
fact, there is a linear relationship between <em>satv</em> percentile and the
first year of college <em>GPA</em>, after controlling for the <em>satm</em> percentile,
in the population of students that completed their first year at this
university.</p></li>
<li><p>For <em>satm</em>: There is strong evidence against the null hypothesis of
no linear relationship between <em>satm</em> and <em>fygpa</em> (<span class="math inline">\(t_{997} = 8.04\)</span>,
p-value &lt; 0.0001)and conclude that, in
fact, there is a linear relationship between <em>satm</em> percentile and the
first year of college <em>GPA</em>, after controlling for the <em>satv</em> percentile,
in the population of students that completed their first year at this
university.</p></li>
</ul></li>
<li><p>Size:</p>
<ul>
<li>The model seems to be valid and have predictors with small p-values, but
note how much of the variation is not explained by the model. It only
explains 21.22%  of the variation in the responses. So we
found evidence that these variables are useful in predicting the responses,
but are they useful enough to use for decisions on admitting students? By
quantifying the size of the estimated slope coefficients, we can add to the
information about how potentially useful this model might be. The estimated
MLR model is</li>
</ul>
<p><span class="math display">\[\widehat{\text{fygpa}}_i = 0.00737+0.0254\cdot\text{satv}_i+0.0224\cdot\text{satm}_i\]</span></p>
<ul>
<li><p>So for a 1 percent increase in the <em>satv</em> percentile, we estimate, on
average, a 0.0254 point change in <em>GPA</em>, after controlling for <em>satm</em>
percentile. Similarly, for a 1 percent increase in the <em>satm</em> percentile, we
estimate, on average, a 0.0224 point change in <em>GPA</em>, after controlling for
<em>satv</em> percentile. While this is a correct interpretation of the slope
coefficients, it is often easier to assess “practical” importance of the
results by considering how much change this implies over the range of
observed predictor values.</p></li>
<li><p>The term-plots (Figure <a href="chapter8.html#fig:Figure8-20">8.20</a>) provide a visualization of
the “size” of the differences in the response variable explained by each
predictor.  The <em>satv</em> term-plot shows that for the
range of percentiles from around the 30<sup>th</sup> percentile to the 70<sup>th</sup>
percentile, the mean first year <em>GPA</em> is predicted to go from approximately
1.9 to 3.0. That is a pretty wide range of differences in GPAs across the
range of observed percentiles. This looks like a pretty interesting and
important change in the mean first year GPA across that range of different
SAT percentiles. Similarly, the <em>satm</em> term-plot shows that the <em>satm</em>
percentiles were observed to range between around the 30<sup>th</sup> percentile and
70<sup>th</sup> percentile and predict mean GPAs between 1.95 and 2.8. It seems that
the SAT Verbal percentiles produce slightly more impacts in the model,
holding the other variable constant, but that both are important variables.
The 95% confidence intervals for the means in both plots suggest that the
results are fairly precisely estimated – there is little variability
around the predicted means in each plot. This is mostly a function of the
sample size as opposed to the model itself explaining most of the variation
in the responses. </p></li>
</ul></li>
</ol>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb787-1"><a href="chapter8.html#cb787-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(gpa1, <span class="at">residuals =</span> T))</span></code></pre></div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-20"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-20-1.png" alt="Term-plots for the \(\text{fygpa}\sim\text{satv} + \text{satm}\) model with partial residuals." width="75%" />
<p class="caption">
Figure 8.20: Term-plots for the <span class="math inline">\(\text{fygpa}\sim\text{satv} + \text{satm}\)</span> model with partial residuals.
</p>
</div>
<ul>
<li>The confidence intervals also help us pin down the uncertainty in each
estimated slope coefficient. As always, the “easy” way to get 95% confidence
intervals is using the <code>confint</code> function:</li>
</ul>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="chapter8.html#cb788-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(gpa1)</span></code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -0.29147825 0.30622148
## satv         0.01977864 0.03100106
## satm         0.01692690 0.02786220</code></pre>
<ul>
<li>So, for a 1 percent increase in the <em>satv</em> percentile, we are 95% confident
that the true mean <em>fygpa</em> changes between 0.0198 and 0.031 points, in the
population of students who completed this year at this institution, after
controlling for <em>satm</em>. The <em>satm</em> result is similar with an interval from
0.0169 and 0.0279. Both of these intervals might benefit from re-scaling
the interpretation to, say, a 10 percentile increase in the predictor variable, with
the change in the <em>fygpa</em> for that level of increase of <em>satv</em> providing an
interval from 0.198 to 0.31 points and for <em>satm</em> providing an interval from
0.169 to 0.279. So a boost of 10% in either exam percentile likely results in a
noticeable but not huge average <em>fygpa</em> increase.</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li><p>Scope of Inference:</p>
<ul>
<li><p>The term-plots also inform the types of students attending this university
and successfully completing the first year of school. This seems like a good, but
maybe not great, institution with few students scoring over the 75<sup>th</sup>
percentile on either SAT Verbal or Math (at least that ended up in this data
set). This result makes questions about their sampling mechanism re-occur as
to who this data set might actually be representative of…</p></li>
<li><p>Note that neither inference is causal because there was no random
assignment of SAT percentiles to the subjects. The inferences
are also limited to students who stayed in school long enough to get a
<em>GPA</em> from their first year of college at this university.</p></li>
</ul></li>
</ol>
<p>One final use of these methods is to do prediction and generate prediction
intervals, which could be quite informative for a student considering going to
this university who has a particular set of SAT scores. For example, suppose
that the student is interested in the average <em>fygpa</em> to expect with <em>satv</em>
at the 30<sup>th</sup> percentile and <em>satm</em> at the 60<sup>th</sup> percentile.
The predicted mean value is</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\mu}_{\text{fygpa}_i} &amp; = 0.00737 + 0.0254\cdot\text{satv}_i 
+ 0.0224\cdot\text{satm}_i \\
&amp; = 0.00737 + 0.0254*30 + 0.0224*60 = 2.113.
\end{array}\]</span></p>
<p>This result and the 95% confidence interval for the mean student <em>fygpa</em> at these
scores can be found using the <code>predict</code> function as: </p>
<div class="sourceCode" id="cb790"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb790-1"><a href="chapter8.html#cb790-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">satv =</span> <span class="dv">30</span>, <span class="at">satm =</span> <span class="dv">60</span>))</span></code></pre></div>
<pre><code>##       1 
## 2.11274</code></pre>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb792-1"><a href="chapter8.html#cb792-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">satv =</span> <span class="dv">30</span>,<span class="at">satm =</span> <span class="dv">60</span>), <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 2.11274 1.982612 2.242868</code></pre>
<p>For students at the 30<sup>th</sup> percentile of <em>satv</em> and 60<sup>th</sup>
percentile of <em>satm</em>, we are 95% confident that the true mean first year GPA
is between 1.98 and 2.24 points. For an individual student, we would want the
95% prediction interval:</p>
<div class="sourceCode" id="cb794"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb794-1"><a href="chapter8.html#cb794-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> <span class="fu">tibble</span>(<span class="at">satv =</span> <span class="dv">30</span>, <span class="at">satm =</span> <span class="dv">60</span>), <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##       fit       lwr      upr
## 1 2.11274 0.8145859 3.410894</code></pre>
<p>For a student with <em>satv</em> = 30 and <em>satm</em> = 60, we are 95% sure that their first
year GPA will be between 0.81 and 3.4 points. You can see that while we are
very certain about the mean in this situation, there is a lot of uncertainty
in the predictions for individual students. The PI is so wide as to almost
not be useful.</p>
<p>To support this difficulty in getting a precise prediction for a new student,
review the original scatterplots and partial residuals: there is quite a bit of vertical variability
in first year <em>GPA</em>s for each level of any of the predictors. The residual
SE, <span class="math inline">\(\widehat{\sigma}\)</span>, is also informative in this regard –
remember that it is the standard deviation of the residuals around the
regression line. It is 0.6582, so the SD of new observations around the line is
0.66 GPA points and that is pretty large on a GPA scale. Remember that if the residuals meet our assumptions and follow a normal distribution around the line, observations within 2 or 3 SDs of the mean would be expected which is a large range of GPA values.
Figure <a href="chapter8.html#fig:Figure8-21">8.21</a> remakes
both term-plots, holding the other predictor at its mean, and adds the 95%
prediction intervals to show the difference in variability between estimating
the mean and pinning down the value of a new observation. The R code is very messy
and rarely needed, but hopefully this helps reinforce the differences in these
two types of intervals – to make them in MLR, you have to fix all but one of
the predictor variables and we usually do that by fixing the other variables at
their means.  </p>

<div class="sourceCode" id="cb796"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb796-1"><a href="chapter8.html#cb796-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remake effects plots with added 95% PIs</span></span>
<span id="cb796-2"><a href="chapter8.html#cb796-2" aria-hidden="true" tabindex="-1"></a>dv1 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">satv =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">24</span>, <span class="at">to =</span> <span class="dv">76</span>, <span class="at">length.out =</span> <span class="dv">50</span>), <span class="at">satm =</span> <span class="fu">rep</span>(<span class="fl">54.4</span>, <span class="dv">50</span>))</span>
<span id="cb796-3"><a href="chapter8.html#cb796-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-4"><a href="chapter8.html#cb796-4" aria-hidden="true" tabindex="-1"></a>mv1 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> dv1, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>))</span>
<span id="cb796-5"><a href="chapter8.html#cb796-5" aria-hidden="true" tabindex="-1"></a>pv1 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> dv1, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>))</span>
<span id="cb796-6"><a href="chapter8.html#cb796-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-7"><a href="chapter8.html#cb796-7" aria-hidden="true" tabindex="-1"></a>mres_GPA_v <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(dv1, mv1, pv1 <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>fit))</span>
<span id="cb796-8"><a href="chapter8.html#cb796-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-9"><a href="chapter8.html#cb796-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename CI and PI limits to have more explicit column names:</span></span>
<span id="cb796-10"><a href="chapter8.html#cb796-10" aria-hidden="true" tabindex="-1"></a>mres_GPA_v <span class="ot">&lt;-</span> mres_GPA_v <span class="sc">%&gt;%</span> <span class="fu">rename</span>(<span class="at">lwr_CI =</span> lwr...<span class="dv">4</span>, <span class="at">upr_CI =</span> upr...<span class="dv">5</span>, </span>
<span id="cb796-11"><a href="chapter8.html#cb796-11" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">lwr_PI =</span> lwr...<span class="dv">6</span>, <span class="at">upr_PI =</span> upr...<span class="dv">7</span>)</span>
<span id="cb796-12"><a href="chapter8.html#cb796-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-13"><a href="chapter8.html#cb796-13" aria-hidden="true" tabindex="-1"></a>v1 <span class="ot">&lt;-</span> mres_GPA_v <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb796-14"><a href="chapter8.html#cb796-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> satv, <span class="at">y =</span> fit), <span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb796-15"><a href="chapter8.html#cb796-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">x =</span> satv, <span class="at">ymin =</span> lwr_CI, <span class="at">ymax =</span> upr_CI), <span class="at">alpha =</span> .<span class="dv">4</span>, </span>
<span id="cb796-16"><a href="chapter8.html#cb796-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;beige&quot;</span>, <span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb796-17"><a href="chapter8.html#cb796-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">x =</span> satv, <span class="at">ymin =</span> lwr_PI, <span class="at">ymax =</span> upr_PI), <span class="at">alpha =</span> .<span class="dv">1</span>, </span>
<span id="cb796-18"><a href="chapter8.html#cb796-18" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;gray80&quot;</span>, <span class="at">color =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb796-19"><a href="chapter8.html#cb796-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;GPA&quot;</span>, <span class="at">x =</span> <span class="st">&quot;satv Percentile&quot;</span>, </span>
<span id="cb796-20"><a href="chapter8.html#cb796-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;satv Effect plot with 95% CI and PI&quot;</span>) <span class="sc">+</span></span>
<span id="cb796-21"><a href="chapter8.html#cb796-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb796-22"><a href="chapter8.html#cb796-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-23"><a href="chapter8.html#cb796-23" aria-hidden="true" tabindex="-1"></a>dm1 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">satv =</span> <span class="fu">rep</span>(<span class="fl">48.93</span>, <span class="dv">50</span>), <span class="at">satm =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">29</span>, <span class="at">to =</span> <span class="dv">77</span>, <span class="at">length.out =</span> <span class="dv">50</span>))</span>
<span id="cb796-24"><a href="chapter8.html#cb796-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-25"><a href="chapter8.html#cb796-25" aria-hidden="true" tabindex="-1"></a>mm1 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> dm1, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>))</span>
<span id="cb796-26"><a href="chapter8.html#cb796-26" aria-hidden="true" tabindex="-1"></a>pm1 <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">predict</span>(gpa1, <span class="at">newdata =</span> dm1, <span class="at">interval =</span> <span class="st">&quot;prediction&quot;</span>))</span>
<span id="cb796-27"><a href="chapter8.html#cb796-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-28"><a href="chapter8.html#cb796-28" aria-hidden="true" tabindex="-1"></a>mres_GPA_m <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(dm1, mm1, pm1 <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>fit))</span>
<span id="cb796-29"><a href="chapter8.html#cb796-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-30"><a href="chapter8.html#cb796-30" aria-hidden="true" tabindex="-1"></a><span class="co">#Rename CI and PI limits to have more explicit column names:</span></span>
<span id="cb796-31"><a href="chapter8.html#cb796-31" aria-hidden="true" tabindex="-1"></a>mres_GPA_m <span class="ot">&lt;-</span> mres_GPA_m <span class="sc">%&gt;%</span> <span class="fu">rename</span>(<span class="at">lwr_CI =</span> lwr...<span class="dv">4</span>, <span class="at">upr_CI =</span> upr...<span class="dv">5</span>, </span>
<span id="cb796-32"><a href="chapter8.html#cb796-32" aria-hidden="true" tabindex="-1"></a>                                    <span class="at">lwr_PI =</span> lwr...<span class="dv">6</span>, <span class="at">upr_PI =</span> upr...<span class="dv">7</span>)</span>
<span id="cb796-33"><a href="chapter8.html#cb796-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-34"><a href="chapter8.html#cb796-34" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> mres_GPA_m <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb796-35"><a href="chapter8.html#cb796-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x =</span> satm, <span class="at">y =</span> fit), <span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb796-36"><a href="chapter8.html#cb796-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">x =</span> satm, <span class="at">ymin =</span> lwr_CI, <span class="at">ymax =</span> upr_CI), <span class="at">alpha =</span> .<span class="dv">4</span>, </span>
<span id="cb796-37"><a href="chapter8.html#cb796-37" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;beige&quot;</span>, <span class="at">color =</span> <span class="st">&quot;darkred&quot;</span>, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb796-38"><a href="chapter8.html#cb796-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">x =</span> satm, <span class="at">ymin =</span> lwr_PI, <span class="at">ymax =</span> upr_PI), <span class="at">alpha =</span> .<span class="dv">1</span>, </span>
<span id="cb796-39"><a href="chapter8.html#cb796-39" aria-hidden="true" tabindex="-1"></a>              <span class="at">fill =</span> <span class="st">&quot;gray80&quot;</span>, <span class="at">color =</span> <span class="st">&quot;grey&quot;</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">lwd =</span> <span class="fl">1.5</span>) <span class="sc">+</span> </span>
<span id="cb796-40"><a href="chapter8.html#cb796-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">&quot;GPA&quot;</span>, <span class="at">x =</span> <span class="st">&quot;satm Percentile&quot;</span>, </span>
<span id="cb796-41"><a href="chapter8.html#cb796-41" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;satm Effect plot with 95% CI and PI&quot;</span>) <span class="sc">+</span> </span>
<span id="cb796-42"><a href="chapter8.html#cb796-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb796-43"><a href="chapter8.html#cb796-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb796-44"><a href="chapter8.html#cb796-44" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(v1, m1, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-21"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-21-1.png" alt="Term-plots for the \(\text{fygpa}\sim\text{satv} + \text{satm}\) model with 95% confidence intervals (dark, dashed lines) and 95% PIs (light grey, dotted lines)." width="75%" />
<p class="caption">
Figure 8.21: Term-plots for the <span class="math inline">\(\text{fygpa}\sim\text{satv} + \text{satm}\)</span> model with 95% confidence intervals (dark, dashed lines) and 95% PIs (light grey, dotted lines).
</p>
</div>
</div>
<div id="section8-9" class="section level2" number="8.9">
<h2><span class="header-section-number">8.9</span> Different intercepts for different groups: MLR with indicator variables</h2>
<p>One of the implicit assumptions up to this point was that the models were being
applied to a single homogeneous population.
 
In many cases, we take a sample
from a population but that overall group is likely a combination of individuals from
different sub-populations. For example, the SAT study was interested in all
students at the university but that contains the obvious sub-populations based
on the gender of the students. It is dangerous to fit MLR models across
subpopulations but we can also use MLR models to address more sophisticated
research questions by comparing groups. We will be able to compare the
intercepts (mean levels) and the slopes to see if they differ between the
groups. For example, does the relationship between the <em>satv</em> and <em>fygpa</em>
differ for male and female students? We can add the grouping information to
the scatterplot of <em>fygpa</em> vs <em>satv</em> (Figure <a href="chapter8.html#fig:Figure8-22">8.22</a>) and
consider whether there is visual evidence of a difference in the slope and/or
intercept between the two groups, with men coded<a href="#fn147" class="footnote-ref" id="fnref147"><sup>147</sup></a> as 1 and women coded as 2. Code below changes this variable to <code>GENDER</code> with more explicit labels, even though they might not be correct and the students were likely forced to choose one or the other.
</p>
<p>It appears that the slope for females might be larger (steeper) in this
relationship than it is for
males. So increases in SAT Verbal percentiles for females might have more of an
impact on the average first year GPA. We’ll handle this sort of situation in
Section <a href="chapter8.html#section8-11">8.11</a>, where we will formally consider how to change the
slopes for different groups. In this section, we develop new methods needed to
begin to handle these situations and explore creating models that assume the same
slope coefficient for all groups but allow for different <span class="math inline">\(y\)</span>-intercepts. This material
ends up resembling what we did for the Two-Way ANOVA additive model.</p>
<p>The results for <em>satv</em> contrast with Figure <a href="chapter8.html#fig:Figure8-23">8.23</a> for the relationship
between first year college <em>GPA</em> and <em>satm</em>
percentile by gender of the students. The lines for the two groups appear to be
mostly parallel and just seem to have different <span class="math inline">\(y\)</span>-intercepts. In this section, we will learn how we can use our
MLR techniques to fit a model to the entire data set that allows for different
<span class="math inline">\(y\)</span>-intercepts. The real power of this idea is that we can then also test whether
the different groups have different <span class="math inline">\(y\)</span>-intercepts – whether the shift between
the groups is “real.” In this example, it appears to suggest that females
generally have slightly higher GPAs than males, on average, but that an
increase in <em>satm</em> has about the same impact on GPA for both groups. If this difference in
<span class="math inline">\(y\)</span>-intercepts is not “real,” then there appears to be no difference between the
sexes in their relationship between <em>satm</em> and GPA and we can safely continue
using a model that does not differentiate the two groups. We could also just
subset the data set and do two analyses, but that approach will not allow us
to assess whether things are “really” different between the two groups.</p>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="chapter8.html#cb797-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Make 1,2 coded gender into factor GENDER</span></span>
<span id="cb797-2"><a href="chapter8.html#cb797-2" aria-hidden="true" tabindex="-1"></a>satgpa <span class="ot">&lt;-</span> satgpa <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">GENDER =</span> <span class="fu">factor</span>(gender)) </span>
<span id="cb797-3"><a href="chapter8.html#cb797-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Make category names clear but note that level names might be wrong</span></span>
<span id="cb797-4"><a href="chapter8.html#cb797-4" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(satgpa<span class="sc">$</span>GENDER) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;MALE&quot;</span>, <span class="st">&quot;FEMALE&quot;</span>) </span>
<span id="cb797-5"><a href="chapter8.html#cb797-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb797-6"><a href="chapter8.html#cb797-6" aria-hidden="true" tabindex="-1"></a>satgpa <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> satv, <span class="at">y =</span> fygpa, <span class="at">color =</span> GENDER, <span class="at">shape =</span> GENDER)) <span class="sc">+</span></span>
<span id="cb797-7"><a href="chapter8.html#cb797-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span> </span>
<span id="cb797-8"><a href="chapter8.html#cb797-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb797-9"><a href="chapter8.html#cb797-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb797-10"><a href="chapter8.html#cb797-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>, <span class="at">option =</span> <span class="st">&quot;plasma&quot;</span>) <span class="sc">+</span></span>
<span id="cb797-11"><a href="chapter8.html#cb797-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of GPA vs satv by gender&quot;</span>)</span>
<span id="cb797-12"><a href="chapter8.html#cb797-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb797-13"><a href="chapter8.html#cb797-13" aria-hidden="true" tabindex="-1"></a>satgpa <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> satm, <span class="at">y =</span> fygpa, <span class="at">color =</span> GENDER, <span class="at">shape =</span> GENDER)) <span class="sc">+</span></span>
<span id="cb797-14"><a href="chapter8.html#cb797-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span> </span>
<span id="cb797-15"><a href="chapter8.html#cb797-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb797-16"><a href="chapter8.html#cb797-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb797-17"><a href="chapter8.html#cb797-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>, <span class="at">option =</span> <span class="st">&quot;inferno&quot;</span>) <span class="sc">+</span></span>
<span id="cb797-18"><a href="chapter8.html#cb797-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of GPA vs satv by gender&quot;</span>)</span></code></pre></div>
<p>To fit one model to a data set that contains multiple groups, we need a way of
entering categorical variable information in an MLR model. Regression models
require quantitative predictor variables for the <span class="math inline">\(x\text{&#39;s}\)</span> so we can’t
directly enter the text coded information on the gender of the students into the regression model since it
contains “words” and how can multiply a word times a slope coefficient. To be able to
put in “numbers” as predictors, we create what are called
<strong><em>indicator variables</em></strong><a href="#fn148" class="footnote-ref" id="fnref148"><sup>148</sup></a>
that are made up of 0s and 1s, with the 0 reflecting one category and 1 the
other, changing depending on the category of the individual in that row of the data set. The
<code>lm</code> function does this whenever a
factor variable is used as an explanatory variable.  

It sets up the indicator
variables using a baseline category (which gets coded as a 0) and the deviation
category for the other level of the variable (which gets coded as a 1). We can see how this works by
exploring what happens when we put <code>GENDER</code> into our <code>lm</code> with <code>satm</code>, after first making sure it is categorical using
the <code>factor</code> function and making the factor <code>levels</code> explicit instead of 1s
and 2s.

</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="chapter8.html#cb798-1" aria-hidden="true" tabindex="-1"></a>SATGENDER1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(fygpa <span class="sc">~</span> satm <span class="sc">+</span> GENDER, <span class="at">data =</span> satgpa) <span class="co">#Fit lm with satm and GENDER</span></span>
<span id="cb798-2"><a href="chapter8.html#cb798-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(SATGENDER1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = fygpa ~ satm + GENDER, data = satgpa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.21589    0.14858   1.453    0.147
## satm          0.03861    0.00258  14.969  &lt; 2e-16
## GENDERFEMALE  0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-22"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-22-1.png" alt="Plot of fygpa vs satv by gender of students." width="75%" />
<p class="caption">
Figure 8.22: Plot of fygpa vs satv by gender of students.
</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-23"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-23-1.png" alt="Plot of fygpa vs satm by gender of students." width="75%" />
<p class="caption">
Figure 8.23: Plot of fygpa vs satm by gender of students.
</p>
</div>
<p>The <code>GENDER</code> row contains information that the linear model chose <em>MALE</em> as
the baseline category and <em>FEMALE</em> as the deviation category since <em>MALE</em> does
not show up in the output. To see what <code>lm</code> is doing for us when we give it a
two-level categorical variable, we can create our own “numerical” predictor that
is 0 for <em>males</em> and 1 for <em>females</em> that we called <code>GENDERINDICATOR</code>, displayed
for the first 10 observations:</p>
<div class="sourceCode" id="cb800"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb800-1"><a href="chapter8.html#cb800-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert logical to 1 for female, 0 for male using ifelse function</span></span>
<span id="cb800-2"><a href="chapter8.html#cb800-2" aria-hidden="true" tabindex="-1"></a>satgpa <span class="ot">&lt;-</span> satgpa <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">GENDERINDICATOR =</span> <span class="fu">ifelse</span>(GENDER <span class="sc">==</span> <span class="st">&quot;FEMALE&quot;</span>, <span class="dv">1</span>, <span class="dv">0</span>)) </span>
<span id="cb800-3"><a href="chapter8.html#cb800-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Explore first 10 observations on the two versions of GENDER using the head() function</span></span>
<span id="cb800-4"><a href="chapter8.html#cb800-4" aria-hidden="true" tabindex="-1"></a>satgpa <span class="sc">%&gt;%</span> <span class="fu">select</span>(GENDER, GENDERINDICATOR) <span class="sc">%&gt;%</span> <span class="fu">head</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##    GENDER GENDERINDICATOR
##    &lt;fct&gt;            &lt;dbl&gt;
##  1 MALE                 0
##  2 FEMALE               1
##  3 FEMALE               1
##  4 MALE                 0
##  5 MALE                 0
##  6 FEMALE               1
##  7 MALE                 0
##  8 MALE                 0
##  9 FEMALE               1
## 10 MALE                 0</code></pre>
<p>We can define the indicator variable more generally by calling it
<span class="math inline">\(I_{\text{Female},i}\)</span> to denote that it is an indicator
<span class="math inline">\((I)\)</span> that takes on a value of 1 for
observations in the category <em>Female</em> and 0 otherwise (<em>Male</em>) – changing based
on the observation (<span class="math inline">\(i\)</span>). Indicator variables, once created,
are quantitative variables that take on values of 0 or 1 and we can put them
directly
into linear models with other <span class="math inline">\(x\text{&#39;s}\)</span> (quantitative or categorical). If we
replace the categorical <code>GENDER</code> variable with our quantitative <code>GENDERINDICATOR</code>
and re-fit the model, we get:</p>
<div class="sourceCode" id="cb802"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb802-1"><a href="chapter8.html#cb802-1" aria-hidden="true" tabindex="-1"></a>SATGENDER2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(fygpa <span class="sc">~</span> satm <span class="sc">+</span> GENDERINDICATOR, <span class="at">data =</span> satgpa)</span>
<span id="cb802-2"><a href="chapter8.html#cb802-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(SATGENDER2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = fygpa ~ satm + GENDERINDICATOR, data = satgpa)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.42124 -0.42363  0.01868  0.46540  1.66397 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      0.21589    0.14858   1.453    0.147
## satm             0.03861    0.00258  14.969  &lt; 2e-16
## GENDERINDICATOR  0.31322    0.04360   7.184 1.32e-12
## 
## Residual standard error: 0.6667 on 997 degrees of freedom
## Multiple R-squared:  0.1917, Adjusted R-squared:  0.1901 
## F-statistic: 118.2 on 2 and 997 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This matches all the previous <code>lm</code> output except that we didn’t get any
information on the categories used since <code>lm</code> didn’t know that <em>GENDERINDICATOR</em>
was anything different from other quantitative predictors.</p>
<p>Now we want to think about what this model means. We can write the estimated
model as</p>
<p><span class="math display">\[\widehat{\text{fygpa}}_i = 0.216 + 0.0386\cdot\text{satm}_i +
0.313 \cdot I_{\text{Female},i}\]</span></p>
<p>When we have a <em>male</em> observation, the indicator takes on a value of 0 so the
0.313 drops out of the model, leaving an SLR just in terms of <em>satm</em>. For a
<em>female</em> student, the indicator is 1 and we add 0.313 to the previous
<span class="math inline">\(y\)</span>-intercept. The following
works this out step-by-step, simplifying the MLR into two SLRs:</p>
<ul>
<li><p>Simplified model for <em>Males</em> (plug in a 0 for <span class="math inline">\(I_{\text{Female},i}\)</span>):</p>
<ul>
<li><span class="math inline">\(\widehat{\text{fygpa}}_i = 0.216 + 0.0386\cdot\text{satm}_i +  0.313 \cdot 0 = 0.216 + 0.0386\cdot\text{satm}_i\)</span></li>
</ul></li>
<li><p>Simplified model for <em>Females</em> (plug in a 1 for <span class="math inline">\(I_{\text{Female},i}\)</span>):</p>
<ul>
<li><p><span class="math inline">\(\widehat{\text{fygpa}}_i = 0.216 + 0.0386\cdot\text{satm}_i + 0.313 \cdot 1\)</span></p></li>
<li><p><span class="math inline">\(= 0.216 + 0.0386\cdot\text{satm}_i + 0.313\)</span> (combine “like” terms to
simplify the equation)</p></li>
<li><p><span class="math inline">\(= 0.529 + 0.0386\cdot\text{satm}_i\)</span> </p></li>
</ul></li>
</ul>
<p>In this situation, we then end up with two SLR models that relate <em>satm</em> to
<em>GPA</em>, one model for <em>males</em>
<span class="math inline">\((\widehat{\text{fygpa}}_i = 0.216 + 0.0386\cdot\text{satm}_i)\)</span> and one for <em>females</em>
<span class="math inline">\((\widehat{\text{fygpa}}_i = 0.529 + 0.0386\cdot\text{satm}_i)\)</span>. The only difference
between these two models is in the <span class="math inline">\(y\)</span>-intercept, with the <em>female</em> model’s
<span class="math inline">\(y\)</span>-intercept shifted up from the <em>male</em> <span class="math inline">\(y\)</span>-intercept by 0.313. And that is what
adding indicator variables into models does in general<a href="#fn149" class="footnote-ref" id="fnref149"><sup>149</sup></a> – it shifts the intercept up or down from
the baseline group (here selected as <em>males</em>) to get a new intercept for the
deviation group (here <em>females</em>).</p>
<p>To make this visually clearer, Figure <a href="chapter8.html#fig:Figure8-24">8.24</a> contains the
regression lines that were estimated for each
group. For any <em>satm</em>, the difference in the groups is the 0.313 coefficient from
the <code>GENDERFEMALE</code> or <code>GENDERINDICATOR</code> row of the model summaries. For example,
at <em>satm</em> = 50, the difference in terms of predicted average first year GPAs
between males and females is displayed as a difference between 2.15 and 2.46.
This model assumes that the slope on <em>satm</em> is the same for both groups except
that they are allowed to have different <span class="math inline">\(y\)</span>-intercepts, which is reasonable here
because we saw approximately parallel relationships for the two groups in
Figure <a href="chapter8.html#fig:Figure8-23">8.23</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-24"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-24-1.png" alt="Plot of estimated model for fygpa vs satm by GENDER of students (female line is thicker dark line). Dashed lines aid in seeing the consistent vertical difference of 0.313 in the two estimated lines based on the model containing a different intercept for each group." width="75%" />
<p class="caption">
Figure 8.24: Plot of estimated model for <em>fygpa</em> vs <em>satm</em> by <em>GENDER</em> of students (female line is thicker dark line). Dashed lines aid in seeing the consistent vertical difference of 0.313 in the two estimated lines based on the model containing a different intercept for each group.
</p>
</div>
<p>Remember that <code>lm</code> selects baseline categories typically based on the
alphabetical order of the levels of the categorical variable when it is created
unless you actively use a function like <code>relevel</code> to change the baseline
category. Here, the <code>GENDER</code> variable started with a coding of 1 and 2 and
retained that order even with the recoding of levels that we created to give it
more explicit names. Because we allow <code>lm</code> to create indicator variables for
us, the main thing you need to do is explore the model summary and look for the
hint at the baseline level that is not displayed after the name of the
categorical variable.  </p>
<p>We can also work out the impacts of adding an indicator variable to the model
in general in the theoretical model with a single quantitative predictor <span class="math inline">\(x_i\)</span>
and indicator <span class="math inline">\(I_i\)</span>. The model starts as in the equation below.</p>
<p><span class="math display">\[y_i = \beta_0+\beta_1x_i + \beta_2I_i + \varepsilon_i\]</span></p>
<p>Again, there are two versions:</p>
<ul>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>baseline</strong> category, <span class="math inline">\(I_i = 0\)</span> and the model
is <span class="math inline">\(y_i = \beta_0+\beta_1x_i + \varepsilon_i\)</span>.</p></li>
<li><p>For any observation <span class="math inline">\(i\)</span> in the <strong>non-baseline (deviation)</strong> category, <span class="math inline">\(I_i = 1\)</span>
and the model simplifies to <span class="math inline">\(y_i = (\beta_0+\beta_2)+\beta_1x_i + \varepsilon_i\)</span>.</p>
<ul>
<li>This model has a <span class="math inline">\(y\)</span>-intercept of <span class="math inline">\(\beta_0+\beta_2\)</span>.</li>
</ul></li>
</ul>
<p>The interpretation and inferences for <span class="math inline">\(\beta_1\)</span> resemble the work with any
MLR model, noting that these results are “controlled for,” “adjusted for,” or
“allowing for differences based on” the categorical variable in the model. The
interpretation of <span class="math inline">\(\beta_2\)</span> is as a shift up or down in the <span class="math inline">\(y\)</span>-intercept for
the model that includes <span class="math inline">\(x_i\)</span>. When we make term-plots in a model with
a quantitative and additive categorical variable, the two reported model
components match with the previous discussion – the same estimated term from
the quantitative variable for all observations and a shift to reflect the
different <span class="math inline">\(y\)</span>-intercepts in the two groups. In Figure <a href="chapter8.html#fig:Figure8-25">8.25</a>, the
females are estimated to be that same 0.313 points higher on first year GPA.
The males have a mean GPA slightly above 2.3 which is the predicted GPA for the
average satm percentile for a male (remember that we have to hold the other
variable at its mean to make each term-plot). When making the satm term-plot,
the intercept is generated based on a weighted average of the intercept for the
baseline category (<code>male</code>) of <span class="math inline">\(b_0 = 0.216\)</span> and the intercept for the deviation
category (<code>female</code>) of <span class="math inline">\(b_0 + b_2 = 0.529\)</span> with weights of <span class="math inline">\(516/1000 = 0.516\)</span> for
the estimated male intercept and <span class="math inline">\(484/1000 = 0.484\)</span> for estimated female
intercept, <span class="math inline">\(0.516 \cdot 0.216 + 0.484 \cdot 0.529 = 0.368\)</span>.</p>

<div class="sourceCode" id="cb804"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb804-1"><a href="chapter8.html#cb804-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tally</span>(GENDER <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> satgpa)</span></code></pre></div>
<pre><code>##         1
## GENDER     1
##   MALE   516
##   FEMALE 484</code></pre>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="chapter8.html#cb806-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(SATGENDER1))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-25"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-25-1.png" alt="Term-plots for the estimated model for \(\text{fygpa}\sim\text{satm} + \text{GENDER}\)." width="75%" />
<p class="caption">
Figure 8.25: Term-plots for the estimated model for <span class="math inline">\(\text{fygpa}\sim\text{satm} + \text{GENDER}\)</span>.
</p>
</div>
<p>The model summary and confidence intervals provide some potential
interesting inferences in these models. Again, these are just applications of
MLR methods we have already seen except that the definition of one of the
variables is “different” using the indicator coding idea.  For
the same model, the <code>GENDER</code> coefficient can be used to generate inferences
for differences in the mean the groups, controlling for their <em>satm</em> scores.</p>
<pre><code>##                Estimate Std. Error t value Pr(&gt;|t|)
## GENDERFEMALE    0.31322    0.04360   7.184 1.32e-12</code></pre>
<p>Testing the null hypothesis that <span class="math inline">\(H_0: \beta_2 = 0\)</span> vs <span class="math inline">\(H_A: \beta_2\ne 0\)</span> using
our regular <span class="math inline">\(t\)</span>-test provides the opportunity to test for a difference in
intercepts between the groups. In this situation, the test statistic is
<span class="math inline">\(t = 7.184\)</span> and, based on a <span class="math inline">\(t_{997}\)</span>-distribution if the null is true, the
p-value is <span class="math inline">\(&lt;0.0001\)</span>. We have very strong evidence against the null hypothesis
that there is no difference in the true <span class="math inline">\(y\)</span>-intercept in a <em>satm</em> model for
first year college GPA between <em>males</em> and <em>females</em>, so we would conclude that
there is a difference in their true mean GPA levels controlled for <em>satm</em>. The
confidence interval is also informative:</p>
<!-- \newpage -->
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="chapter8.html#cb808-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(SATGENDER1)</span></code></pre></div>
<pre><code>##                    2.5 %     97.5 %
## (Intercept)  -0.07566665 0.50744709
## satm          0.03355273 0.04367726
## GENDERFEMALE  0.22766284 0.39877160</code></pre>
<p>We are 95% confident that the true mean GPA for females is between 0.228 and
0.399 points higher than for males, after adjusting for the <em>satm</em> in the
population of students. If we had subset the data set by gender and fit two SLRs, we
could have obtained the same simplified regression models for each group but we never could
have performed inferences for the differences between the two groups without
putting all the observations together in one model and then assessing those
differences with targeted coefficients. We also would not be able to get an
estimate of their common slope for <em>satm</em>, after adjusting for differences
in the intercept for each group.</p>
</div>
<div id="section8-10" class="section level2" number="8.10">
<h2><span class="header-section-number">8.10</span> Additive MLR with more than two groups: Headache example</h2>
<p>The same techniques can be extended to more than two groups. A study was
conducted to explore sound tolerances using <span class="math inline">\(n = 98\)</span> subjects with the data
available in the <code>Headache</code> data set from the <code>heplots</code> package
<span class="citation">(<a href="#ref-R-heplots" role="doc-biblioref">Fox and Friendly 2021</a>)</span>.  Each subject was initially
exposed to a tone, stopping when the tone became definitely intolerable (<em>DU</em>)
and that decibel level was recorded (variable called <code>du1</code>). Then the subjects
were randomly assigned to one of four treatments: <em>T1</em> (Listened again to the
tone at their initial <em>DU</em> level, for the same amount of time they were able to
tolerate it before); <em>T2</em> (Same as <em>T1</em>, with one additional minute of
exposure); <em>T3</em> (Same as <em>T2</em>, but the subjects were explicitly instructed to
use the relaxation techniques); and <em>Control</em> (these subjects experienced no
further exposure to the noise tone until the final sensitivity measures were
taken). Then the <em>DU</em> was measured again (variable called <code>du2</code>). One would
expect that there would be a relationship between the upper tolerance levels of
the subjects before and after treatment. But maybe the treatments impact that
relationship? We can use our indicator  approach to see if the
treatments provide a shift to higher tolerances after accounting for the
relationship between the two measurements<a href="#fn150" class="footnote-ref" id="fnref150"><sup>150</sup></a>. The scatterplot<a href="#fn151" class="footnote-ref" id="fnref151"><sup>151</sup></a>  of the results
in Figure <a href="chapter8.html#fig:Figure8-26">8.26</a> shows some variation in the slopes and the
intercepts for the groups although the variation in intercepts seems more
prominent than differences in slopes. Note that the <code>fct_relevel</code> function was
applied to the <code>treatment</code> variable with an option of <code>"Control"</code> to make
the <em>Control</em> category the baseline category as the person who created the data
set had set <code>T1</code> as the baseline in the <code>treatment</code> variable.</p>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="chapter8.html#cb810-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(heplots)</span>
<span id="cb810-2"><a href="chapter8.html#cb810-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(Headache)</span>
<span id="cb810-3"><a href="chapter8.html#cb810-3" aria-hidden="true" tabindex="-1"></a>Headache <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(Headache)</span>
<span id="cb810-4"><a href="chapter8.html#cb810-4" aria-hidden="true" tabindex="-1"></a>Headache</span></code></pre></div>
<pre><code>## # A tibble: 98 x 6
##    type    treatment    u1   du1    u2   du2
##    &lt;fct&gt;   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
##  1 Migrane T3         2.34  5.3   5.8   8.52
##  2 Migrane T1         2.73  6.85  4.68  6.68
##  3 Tension T1         0.37  0.53  0.55  0.84
##  4 Migrane T3         7.5   9.12  5.7   7.88
##  5 Migrane T3         4.63  7.21  5.63  6.75
##  6 Migrane T3         3.6   7.3   4.83  7.32
##  7 Migrane T2         2.45  3.75  2.5   3.18
##  8 Migrane T1         2.31  3.25  2     3.3 
##  9 Migrane T1         1.38  2.33  2.23  3.98
## 10 Tension T3         0.85  1.42  1.37  1.89
## # ... with 88 more rows</code></pre>
<div style="page-break-after: always;"></div>

<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb812-1"><a href="chapter8.html#cb812-1" aria-hidden="true" tabindex="-1"></a>Headache <span class="ot">&lt;-</span> Headache <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">treatment =</span> <span class="fu">factor</span>(treatment),</span>
<span id="cb812-2"><a href="chapter8.html#cb812-2" aria-hidden="true" tabindex="-1"></a>                                <span class="at">treatment =</span> <span class="fu">fct_relevel</span>(treatment, <span class="st">&quot;Control&quot;</span>)</span>
<span id="cb812-3"><a href="chapter8.html#cb812-3" aria-hidden="true" tabindex="-1"></a>                                )</span>
<span id="cb812-4"><a href="chapter8.html#cb812-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Make treatment a factor and Control the baseline category</span></span>
<span id="cb812-5"><a href="chapter8.html#cb812-5" aria-hidden="true" tabindex="-1"></a>Headache <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> du1, <span class="at">y =</span> du2, <span class="at">color =</span> treatment, </span>
<span id="cb812-6"><a href="chapter8.html#cb812-6" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">shape =</span> treatment)) <span class="sc">+</span></span>
<span id="cb812-7"><a href="chapter8.html#cb812-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span> </span>
<span id="cb812-8"><a href="chapter8.html#cb812-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb812-9"><a href="chapter8.html#cb812-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb812-10"><a href="chapter8.html#cb812-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.85</span>, <span class="at">option =</span> <span class="st">&quot;inferno&quot;</span>) <span class="sc">+</span> </span>
<span id="cb812-11"><a href="chapter8.html#cb812-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of Maximum DB tolerance before &amp; </span></span>
<span id="cb812-12"><a href="chapter8.html#cb812-12" aria-hidden="true" tabindex="-1"></a><span class="st">       after treatment (by treatment)&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-26"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-26-1.png" alt="Scatterplot of post-treatment decibel tolerance (du2) vs pre-treatment tolerance (du1) by treatment level (4 groups)." width="75%" />
<p class="caption">
Figure 8.26: Scatterplot of post-treatment decibel tolerance (du2) vs pre-treatment tolerance (du1) by treatment level (4 groups).
</p>
</div>
<p>This data set contains a categorical variable with 4 levels. To go beyond two
groups, we have to add more than one indicator variable,  defining three
indicators to turn on (1) or off (0) for three of the levels of the variable
with the same reference level used for all the indicators. For this example,
the <em>Control</em> group is chosen as the baseline group so it hides in
the background while we define indicators for the other three levels. The
indicators for <em>T1</em>, <em>T2</em>, and <em>T3</em> treatment levels are:</p>
<ul>
<li><p>Indicator for <em>T1</em>: <span class="math inline">\(I_{T1,i} = \left\{\begin{array}{rl} 1 &amp; \text{if Treatment} = T1 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
<li><p>Indicator for <em>T2</em>: <span class="math inline">\(I_{T2,i} = \left\{\begin{array}{rl} 1 &amp; \text{if Treatment} = T2 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
<li><p>Indicator for <em>T3</em>: <span class="math inline">\(I_{T3,i} = \left\{\begin{array}{rl} 1 &amp; \text{if Treatment} = T3 \\ 0 &amp; \text{else} \end{array}\right.\)</span></p></li>
</ul>
<p>We can see the values of these indicators for a few observations and their
original variable (<code>treatment</code>) in the following output. For <em>Control</em> all the
indicators stay at 0.</p>
<!-- \newpage -->
<table>
<thead>
<tr class="header">
<th align="left">Treatment</th>
<th align="right">I_T1</th>
<th align="right">I_T2</th>
<th align="right">I_T3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T2</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">T1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">Control</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">T3</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<p>When we fit the additive model of the form <code>y ~ x + group</code>, the <code>lm</code>
function takes the <span class="math inline">\(\boldsymbol{J}\)</span> categories and creates <span class="math inline">\(\boldsymbol{J-1}\)</span>
indicator variables.
 
The baseline level is always handled in the intercept.
The true model will be of the form</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_i +\beta_2I_{\text{Level}2,i}+\beta_3I_{\text{Level}3,i}
+\cdots+\beta_{J}I_{\text{Level}J,i}+\varepsilon_i\]</span></p>
<p>where the <span class="math inline">\(I_{\text{CatName}j,i}\text{&#39;s}\)</span> are the different indicator variables.
Note that each indicator variable gets a coefficient associated with it and is
“turned on” whenever the <span class="math inline">\(i^{th}\)</span> observation is in that category. At most only one of
the <span class="math inline">\(I_{\text{CatName}j,i}\text{&#39;s}\)</span> is a 1 for any observation, so the
<span class="math inline">\(y\)</span>-intercept will either be <span class="math inline">\(\beta_0\)</span> for the baseline group or <span class="math inline">\(\beta_0+\beta_j\)</span>
for <span class="math inline">\(j = 2,\ldots,J\)</span>. It is important to remember that this
is an “additive” model since the effects just add and there is no interaction
between the grouping variable and the quantitative predictor. To be able to
trust this model, we need to check that we do not need different slope
coefficients for the groups as discussed in the next section.</p>
<p>For these types of models, it is always good to start with a plot of the data
set with regression lines for each group – assessing whether the lines look
relatively parallel or not.

In Figure <a href="chapter8.html#fig:Figure8-26">8.26</a>, there are some
differences in slopes – we investigate that further in the next section. For
now, we can proceed with fitting the additive model with different intercepts
for the four levels of <code>treatment</code> and the quantitative explanatory variable, <code>du1</code>.</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="chapter8.html#cb813-1" aria-hidden="true" tabindex="-1"></a>head1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(du2 <span class="sc">~</span> du1 <span class="sc">+</span> treatment, <span class="at">data =</span> Headache)</span>
<span id="cb813-2"><a href="chapter8.html#cb813-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(head1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1 + treatment, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9085 -0.9551 -0.3118  1.1141 10.5364 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.25165    0.51624   0.487   0.6271
## du1          0.83705    0.05176  16.172   &lt;2e-16
## treatmentT1  0.55752    0.61830   0.902   0.3695
## treatmentT2  0.63444    0.63884   0.993   0.3232
## treatmentT3  1.36671    0.60608   2.255   0.0265
## 
## Residual standard error: 2.14 on 93 degrees of freedom
## Multiple R-squared:  0.7511, Adjusted R-squared:  0.7404 
## F-statistic: 70.16 on 4 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The complete estimated regression model is</p>
<p><span class="math display">\[\widehat{\text{du2}}_i = 0.252+0.837\cdot\text{du1}_i +0.558I_{\text{T1},i}+0.634I_{\text{T2},i}+1.367I_{\text{T3},i}\]</span></p>
<p>For each group, the model simplifies to an SLR as follows:</p>
<ul>
<li>For <em>Control</em> (baseline):</li>
</ul>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i &amp; = 0.252+0.837\cdot\text{du1}_i +0.558I_{\text{T1},i}+0.634I_{\text{T2},i}+1.367I_{\text{T3},i} \\
&amp; = 0.252+0.837\cdot\text{du1}_i+0.558*0+0.634*0+1.367*0 \\
&amp; = 0.252+0.837\cdot\text{du1}_i.
\end{array}\]</span></p>
<ul>
<li>For <em>T1</em>:</li>
</ul>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i &amp; = 0.252+0.837\cdot\text{du1}_i +0.558I_{\text{T1},i}+0.634I_{\text{T2},i}+1.367I_{\text{T3},i} \\
&amp; = 0.252+0.837\cdot\text{du1}_i+0.558*1+0.634*0+1.367*0 \\
&amp; = 0.252+0.837\cdot\text{du1}_i + 0.558 \\
&amp; = 0.81+0.837\cdot\text{du1}_i.
\end{array}\]</span></p>
<!-- \newpage -->
<ul>
<li>Similarly for <em>T2</em>:</li>
</ul>
<p><span class="math display">\[\widehat{\text{du2}}_i = 0.886 + 0.837\cdot\text{du1}_i\]</span></p>
<ul>
<li>Finally for <em>T3</em>:</li>
</ul>
<p><span class="math display">\[\widehat{\text{du2}}_i = 1.62 + 0.837\cdot\text{du1}_i\]</span></p>
<p>To reinforce what this additive model is doing, Figure <a href="chapter8.html#fig:Figure8-27">8.27</a>
displays the estimated regression lines for all four
groups, showing the shifts in the <em>y</em>-intercepts among the groups.
</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-27"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-27-1.png" alt="Plot of estimated noise tolerance additive model." width="75%" />
<p class="caption">
Figure 8.27: Plot of estimated noise tolerance additive model.
</p>
</div>
<p>The right panel of the term-plot (Figure <a href="chapter8.html#fig:Figure8-28">8.28</a>) shows
how the <em>T3</em> group seems to have shifted up the most relative to
the others and the <em>Control</em> group seems to have a mean that is a bit lower than
the others, in the model that otherwise assumes that the same linear
relationship holds between <code>du1</code> and <code>du2</code> for all the groups. After
controlling for the <em>Treatment</em> group, for a 1 decibel increase in initial
tolerances, we estimate, on average, to obtain a 0.84 decibel change in the
second tolerance measurement. The <strong><em>R</em></strong><sup>2</sup> shows that this is a decent model
for the responses, with this model explaining 75.1% percent of the
variation in the second decibel tolerance measure. We should check the
diagnostic plots and VIFs to check for any issues – all the diagnostics and
assumptions are as before except that there is no assumption of linearity
between the grouping variable and the responses. 
Additionally, sometimes we need to add group information to diagnostics to see
if any patterns in residuals look different in different groups, like linearity
or non-constant variance, when we are fitting models that might contain multiple
groups.</p>

<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="chapter8.html#cb815-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(head1, <span class="at">residuals =</span> T), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-28"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-28-1.png" alt="Term-plots of the additive decibel tolerance model with partial residuals." width="75%" />
<p class="caption">
Figure 8.28: Term-plots of the additive decibel tolerance model with partial residuals.
</p>
</div>
<p>The diagnostic plots in Figure <a href="chapter8.html#fig:Figure8-29">8.29</a> provides some
indications of a few observations in the tails that deviate from a normal
distribution to having slightly heavier tails but only one outlier is of real
concern and causes some concern about the normality assumption. There is a small
indication of increasing variability as a function of the fitted values as both
the Residuals vs. Fitted and Scale-Location plots show some fanning out for
higher values but this is a minor issue. There are no influential points here
since all the Cook’s D values are less than 0.5. </p>

<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb816-1"><a href="chapter8.html#cb816-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb816-2"><a href="chapter8.html#cb816-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(head1, <span class="at">pch =</span> <span class="dv">16</span>,</span>
<span id="cb816-3"><a href="chapter8.html#cb816-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">sub.caption =</span> <span class="st">&quot;Plot of diagnostics for additive model with du1 and </span></span>
<span id="cb816-4"><a href="chapter8.html#cb816-4" aria-hidden="true" tabindex="-1"></a><span class="st">     treatment for du2&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-29"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-29-1.png" alt="Diagnostic plots for the additive decibel tolerance model." width="75%" />
<p class="caption">
Figure 8.29: Diagnostic plots for the additive decibel tolerance model.
</p>
</div>
<p>Additionally, sometimes we need to add group information to diagnostics
to see if any patterns in residuals look different in different groups, like
linearity or non-constant variance, when we are fitting models that might
contain multiple groups. We can use the same scatterplot tools to make our own
plot the residuals (extracted using the <code>residuals</code> function) versus the
fitted values (extracted using the <code>fitted</code> function) by groups as in
Figure <a href="chapter8.html#fig:Figure8-30">8.30</a>. This provides an opportunity to introduce
faceting, where we can split our plots into panels by a grouping variable, here
by the <code>treatment</code> applied to each subject. 
 This can be helpful with multiple groups to be able
to see each one more clearly as we avoid overplotting. The addition of
<code>+ facet_grid(cols = vars(treatment))</code> facets the plot based on the
<code>treatment</code> variable and puts the facets in different columns because of the
<code>cols =</code> part of the code (<code>rows =</code> specifies the number of rows for the
facets), labeling each panel at the top with the level being displayed of the
faceting variable (<code>vars()</code> is needed to help ggplot find the variable). In
this example, there are no additional patterns identified by making this plot
although we do see some minor deviations in the fitted lines for each group,
but it is a good additional check in these multi-group situations.</p>

<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb817-1"><a href="chapter8.html#cb817-1" aria-hidden="true" tabindex="-1"></a>Headache <span class="ot">&lt;-</span> Headache <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">resids =</span> <span class="fu">residuals</span>(head1),</span>
<span id="cb817-2"><a href="chapter8.html#cb817-2" aria-hidden="true" tabindex="-1"></a>                                <span class="at">fits =</span> <span class="fu">fitted</span>(head1)</span>
<span id="cb817-3"><a href="chapter8.html#cb817-3" aria-hidden="true" tabindex="-1"></a>                                )</span>
<span id="cb817-4"><a href="chapter8.html#cb817-4" aria-hidden="true" tabindex="-1"></a>Headache <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> resids, </span>
<span id="cb817-5"><a href="chapter8.html#cb817-5" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">color =</span> treatment, <span class="at">shape =</span> treatment)) <span class="sc">+</span></span>
<span id="cb817-6"><a href="chapter8.html#cb817-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb817-7"><a href="chapter8.html#cb817-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb817-8"><a href="chapter8.html#cb817-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb817-9"><a href="chapter8.html#cb817-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.85</span>, <span class="at">option =</span> <span class="st">&quot;inferno&quot;</span>) <span class="sc">+</span></span>
<span id="cb817-10"><a href="chapter8.html#cb817-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of Residuals vs Fitted by Treatment Group&quot;</span>) <span class="sc">+</span></span>
<span id="cb817-11"><a href="chapter8.html#cb817-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="at">cols =</span> <span class="fu">vars</span>(treatment))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-30"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-30-1.png" alt="Faceted scatterplot of residuals versus fitted values by treatment group from the additive decibel tolerance model." width="75%" />
<p class="caption">
Figure 8.30: Faceted scatterplot of residuals versus fitted values by treatment group from the additive decibel tolerance model.
</p>
</div>
<p>The VIFs are different for categorical variables than for quantitative
predictors in MLR. The 4 levels are combined in a measure called the
<strong><em>generalized VIF (GVIF)</em></strong>. For GVIFs, we only focus on the inflation of the
SE scale (square root for 1 df effects and raised to the power <span class="math inline">\(1/(2*J)\)</span> for a
<span class="math inline">\(J\)</span>-level predictor). On this scale, the interpretation is as <strong>the
multiplicative increase in the SEs for the coefficients on all the indicator
variables due to multicollinearity with other predictors</strong>. In this model, the
SE for <code>du1</code> is 1.009 times larger due to multicollinearity with other
predictors and the SEs for the indicator variables for <code>treatment</code> are 1.003
times larger due to multicollinearity than they otherwise would have been.
Neither are large so multicollinearity is not a problem in this model.</p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="chapter8.html#cb818-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(head1)</span></code></pre></div>
<pre><code>##              GVIF Df GVIF^(1/(2*Df))
## du1       1.01786  1        1.008891
## treatment 1.01786  3        1.002955</code></pre>
<p>While there are inferences available in the model output, the tests for
the indicator variables are not too informative (at least to start) since they
only compare each group to the baseline. In Section <a href="chapter8.html#section8-12">8.12</a>, we see
how to use ANOVA <em>F</em>-tests to help us ask general questions about including a
categorical predictor in the model. But we can compare adjusted <strong><em>R</em></strong><sup>2</sup>
values with and without <em>Treatment</em> to see if including the categorical
variable was “worth it”:</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="chapter8.html#cb820-1" aria-hidden="true" tabindex="-1"></a>head1R <span class="ot">&lt;-</span> <span class="fu">lm</span>(du2 <span class="sc">~</span> du1, <span class="at">data =</span> Headache)</span></code></pre></div>
<!-- \newpage -->
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb821-1"><a href="chapter8.html#cb821-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(head1R)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.9887 -0.8820 -0.2765  1.1529 10.4165 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.84744    0.36045   2.351   0.0208
## du1          0.85142    0.05189  16.408   &lt;2e-16
## 
## Residual standard error: 2.165 on 96 degrees of freedom
## Multiple R-squared:  0.7371, Adjusted R-squared:  0.7344 
## F-statistic: 269.2 on 1 and 96 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The adjusted <strong><em>R</em></strong><sup>2</sup> in the model with both <em>Treatment</em> and <em>du1</em> is
0.7404 and the adjusted <em>R</em><sup>2</sup> for this reduced model with just <em>du1</em> is 0.7344,
suggesting the <em>Treatment</em> is useful. The next section
provides a technique to be able to work with different slopes on the
quantitative predictor for each group. Comparing those results to the results
for the additive model allows assessment of the assumption in this section that
all the groups had the same slope coefficient for the quantitative variable.</p>
</div>
<div id="section8-11" class="section level2" number="8.11">
<h2><span class="header-section-number">8.11</span> Different slopes and different intercepts</h2>
<p>Sometimes researchers are specifically interested in whether the slopes vary
across groups or the regression lines in the scatterplot for the different
groups may not look parallel or it may just be hard to tell visually if there
really is a difference in the slopes.

Unless you are <strong>very sure</strong> that there
is not an interaction between the grouping variable and the quantitative
predictor, you should<a href="#fn152" class="footnote-ref" id="fnref152"><sup>152</sup></a> start by fitting a model containing an
interaction and then see if you can drop it.


It may be the case that you end up
with the simpler additive model from the previous sections, but you don’t want
to assume the same slope across groups unless you are absolutely sure that is
the case.

This should remind you a bit of the discussions of the additive and
interaction models in the Two-way ANOVA material. The models, concerns, and
techniques are very similar, but with the quantitative variable replacing one
of the two categorical variables. As always, the scatterplot is a good first
step to understanding whether we need the extra complexity that these models
require.</p>
<p>A new example provides motivation for the consideration of different
slopes and
intercepts. A study was performed to address whether the relationship between
nonverbal IQs and
reading accuracy differs between dyslexic and non-dyslexic students. Two groups
of students were identified, one group of <em>dyslexic</em> students was identified
first (19 students) and then a group of gender and age similar student matches
were identified (25 students) for a total sample size of <span class="math inline">\(n = 44\)</span>, provided in the
<code>dyslexic3</code> data set from the <code>smdata</code> package <span class="citation">(<a href="#ref-R-smdata" role="doc-biblioref">Merkle and Smithson 2018</a>)</span>.

This type of study design is an attempt to “balance” the data from the two
groups on some important characteristics to make the comparisons of the groups
as fair as possible.

The researchers attempted to balance the characteristics
of the subjects in the two groups so that if they found different results for
the two groups, they could attribute it to the main difference they used to
create the groups – dyslexia or not. This design, <strong><em>case-control</em></strong> or
<strong>case-comparison</strong> where each subject with a trait is matched to one or more
subjects in the “control” group would hopefully reduce confounding from other
factors and then allow stronger conclusions in situations where it is
impossible to randomly
assign treatments to subjects.

We still would avoid using “causal” language but
this design is about as good as you can get when you are unable to randomly
assign levels to subjects.</p>
<p>Using these data, we can explore the relationship between nonverbal
IQ scores and reading accuracy, with reading accuracy measured as a proportion
correct. The fact that there is an
upper limit to the response variable attained by many students will cause
complications below, but we can still learn something from our attempts to
analyze these data using an MLR model. The scatterplot in
Figure <a href="chapter8.html#fig:Figure8-31">8.31</a> seems to indicate some clear differences in the
<em>IQ</em> vs <em>reading score</em> relationship between the <em>dys</em> = 0 (non-dyslexic) and
<em>dys</em> = 1 (dyslexic) students (code below makes these levels more explicit in the data set). Note that the IQ is standardized to have mean 0
and standard deviation of 1 which means that
a 1 unit change in IQ score is a 1 SD change and that the <em>y</em>-intercept (for
<span class="math inline">\(x = 0\)</span>) is right in the center of the plot and actually interesting<a href="#fn153" class="footnote-ref" id="fnref153"><sup>153</sup></a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-31"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-31-1.png" alt="Scatterplot for reading score versus nonverbal IQ by dyslexia group." width="75%" />
<p class="caption">
Figure 8.31: Scatterplot for reading score versus nonverbal IQ by dyslexia group.
</p>
</div>
<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb823-1"><a href="chapter8.html#cb823-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(smdata)</span>
<span id="cb823-2"><a href="chapter8.html#cb823-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;dyslexic3&quot;</span>)</span>
<span id="cb823-3"><a href="chapter8.html#cb823-3" aria-hidden="true" tabindex="-1"></a>dyslexic3 <span class="ot">&lt;-</span> dyslexic3 <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">dys =</span> <span class="fu">factor</span>(dys))</span>
<span id="cb823-4"><a href="chapter8.html#cb823-4" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(dyslexic3<span class="sc">$</span>dys) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>)</span>
<span id="cb823-5"><a href="chapter8.html#cb823-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb823-6"><a href="chapter8.html#cb823-6" aria-hidden="true" tabindex="-1"></a>dyslexic3 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> ziq, <span class="at">y =</span> score, <span class="at">color =</span> dys, <span class="at">shape =</span> dys)) <span class="sc">+</span></span>
<span id="cb823-7"><a href="chapter8.html#cb823-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb823-8"><a href="chapter8.html#cb823-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb823-9"><a href="chapter8.html#cb823-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb823-10"><a href="chapter8.html#cb823-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.7</span>, <span class="at">option =</span> <span class="st">&quot;plasma&quot;</span>) <span class="sc">+</span></span>
<span id="cb823-11"><a href="chapter8.html#cb823-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Plot of IQ vs Reading by dyslexia status&quot;</span>,</span>
<span id="cb823-12"><a href="chapter8.html#cb823-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Standardized nonverbal IQ scores&quot;</span>,</span>
<span id="cb823-13"><a href="chapter8.html#cb823-13" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Reading score&quot;</span>) <span class="sc">+</span></span>
<span id="cb823-14"><a href="chapter8.html#cb823-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="at">cols =</span> <span class="fu">vars</span>(dys))</span></code></pre></div>
<p>To allow for both different <span class="math inline">\(y\)</span>-intercepts and slope coefficients on the
quantitative predictor, we need to include a “modification” of the slope
coefficient. This is performed using an <strong><em>interaction</em></strong> between the two
predictor variables where we allow the impacts of one variable
(slopes) to change based on the levels of another variable (grouping variable).
 The formula notation is <code>y ~ x * group</code>, remembering
that this also includes the <strong><em>main effects</em></strong> (the additive variable
components) as well as the interaction coefficients; this is similar to what we
discussed in the Two-Way ANOVA interaction model.  We can
start with the general model for a two-level categorical variable with an
interaction, which is</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1x_i +\beta_2I_{\text{CatName},i} +
{\color{red}{\boldsymbol{\beta_3I_{\text{CatName},i}x_i}}}+\varepsilon_i,\]</span></p>
<p>where the new component involves the product of both the indicator and the quantitative
predictor variable. The <span class="math inline">\(\color{red}{\boldsymbol{\beta_3}}\)</span> coefficient will be
found in a row of output with <strong>both</strong> variable names in it (with the indicator
level name) with a colon between them (something like <code>x:grouplevel</code>). As
always, the best way to understand any
model involving indicators is to plug in 0s or 1s for the indicator variable(s)
and simplify the equations. </p>
<ul>
<li><p>For any observation in the baseline group <span class="math inline">\(I_{\text{CatName},i} = 0\)</span>, so</p>
<p><span class="math display">\[y_i = \beta_0+\beta_1x_i+\beta_2I_{\text{CatName},i}+
  {\color{red}{\boldsymbol{\beta_3I_{\text{CatName},i}x_i}}}+\varepsilon_i\]</span></p>
<p>simplifies quickly to:</p>
<p><span class="math display">\[y_i = \beta_0+\beta_1x_i+\varepsilon_i\]</span></p>
<ul>
<li>So the baseline group’s model involves the initial intercept and
quantitative slope coefficient.</li>
</ul></li>
<li><p>For any observation in the second category <span class="math inline">\(I_{\text{CatName},i} = 1\)</span>, so</p>
<p><span class="math display">\[y_i = \beta_0+\beta_1x_i+\beta_2I_{\text{CatName},i}+
  {\color{red}{\boldsymbol{\beta_3I_{\text{CatName},i}x_i}}}+\varepsilon_i\]</span></p>
<p>is</p>
<p><span class="math display">\[y_i = \beta_0+\beta_1x_i+\beta_2*1+
  {\color{red}{\boldsymbol{\beta_3*1*x_i}}}+\varepsilon_i\]</span></p>
<p>which “simplifies” to</p>
<p><span class="math display">\[y_i = (\beta_0+\beta_2) + (\beta_1+{\color{red}{\boldsymbol{\beta_3}}})x_i
  +\varepsilon_i,\]</span></p>
<p>by combining like terms.</p>
<ul>
<li>For the second category, the model contains a modified <span class="math inline">\(y\)</span>-intercept,
now <span class="math inline">\(\beta_0+\beta_2\)</span>, <strong>and</strong> a modified slope coefficient, now
<span class="math inline">\(\beta_1+\color{red}{\boldsymbol{\beta_3}}\)</span>.</li>
</ul></li>
</ul>
<p>We can make this more concrete by applying this to the dyslexia data with
<code>dys</code> as a categorical variable for dyslexia status of subjects (levels of
<em>no</em> and <em>yes</em>) and <code>ziq</code> the standardized IQ. The model is estimated as:</p>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb824-1"><a href="chapter8.html#cb824-1" aria-hidden="true" tabindex="-1"></a>dys_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> ziq <span class="sc">*</span> dys, <span class="at">data =</span> dyslexic3)</span>
<span id="cb824-2"><a href="chapter8.html#cb824-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(dys_model)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ ziq * dys, data = dyslexic3)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.26362 -0.04152  0.01682  0.06790  0.17740 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.87586    0.02391  36.628  &lt; 2e-16
## ziq          0.05827    0.02535   2.299   0.0268
## dysyes      -0.27951    0.03827  -7.304 7.11e-09
## ziq:dysyes  -0.07285    0.03821  -1.907   0.0638
## 
## Residual standard error: 0.1017 on 40 degrees of freedom
## Multiple R-squared:  0.712,  Adjusted R-squared:  0.6904 
## F-statistic: 32.96 on 3 and 40 DF,  p-value: 6.743e-11</code></pre>
<p>The estimated model can be written as</p>
<p><span class="math display">\[\widehat{\text{Score}}_i = 0.876+0.058\cdot\text{ZIQ}_i - 0.280I_{\text{yes},i}
-{\color{red}{\boldsymbol{0.073}}}I_{\text{yes},i}\cdot\text{ZIQ}_i\]</span></p>
<p>and simplified for the two groups as:</p>
<ul>
<li><p>For the baseline (non-dyslexic, <span class="math inline">\(I_{\text{yes},i} = 0\)</span>) students:</p>
<p><span class="math display">\[\widehat{\text{Score}}_i = 0.876+0.058\cdot\text{ZIQ}_i\]</span></p></li>
<li><p>For the deviation (dyslexic, <span class="math inline">\(I_{\text{yes},i} = 1\)</span>) students:</p>
<p><span class="math display">\[\begin{array}{rl}
  \widehat{\text{Score}}_i&amp; = 0.876+0.058\cdot\text{ZIQ}_i - 0.280*1-
  0.073*1\cdot\text{ZIQ}_i \\
  &amp; = (0.876- 0.280) + (0.058-0.073)\cdot\text{ZIQ}_i, \\
  \end{array}\]</span></p>
<p>which simplifies finally to:</p>
<p><span class="math display">\[\widehat{\text{Score}}_i = 0.596-0.015\cdot\text{ZIQ}_i\]</span></p></li>
<li><p>So the slope switched from 0.058 in the non-dyslexic students to -0.015 in
the dyslexic students. The interpretations of these coefficients are outlined
below:</p>
<ul>
<li><p>For the non-dyslexic students: For a 1 SD increase in verbal IQ score,
we estimate, on average, the reading score to go up by 0.058
“points.”</p></li>
<li><p>For the dyslexic students: For a 1 SD increase in verbal IQ score, we
estimate, on average, the reading score to change by -0.015
“points.”</p></li>
</ul></li>
</ul>
<p>So, an expected pattern of results emerges for the non-dyslexic students.
Those with higher IQs tend to have
higher reading accuracy; this does not mean higher IQ’s cause more accurate
reading because random assignment of IQ is not possible. However, for the
dyslexic students, the relationship is not what one would might expect. It is
slightly negative, showing that higher verbal IQ’s are related to lower reading
accuracy. What we conclude from this is that we should not expect higher IQ’s
to show higher performance on a test like this.</p>
<p>Checking the assumptions is always recommended before getting focused
on the inferences in the model. When interactions are present, you should not
use VIFs as they are naturally inflated because the same variable is re-used in
multiple parts of the model to create the interaction components. Checking the
multicollinearity in the related additive model can be performed to understand
shared information in the variables used in interactions. When fitting models
with multiple groups, it is possible to see “groups” in the fitted values
(<span class="math inline">\(x\)</span>-axis in Residuals vs Fitted and Scale-Location plots) and that is not a
problem – it is a feature of these models. 
  You should look for issues in
the residuals for each group but the residuals should overall still be normally
distributed and have the same variability everywhere. It is a bit hard to see
issues in Figure <a href="chapter8.html#fig:Figure8-32">8.32</a> because of the group differences,
but note the line of residuals for the higher fitted values. This is an
artifact of the upper threshold in the reading accuracy test used. As in the
first year of college GPA, these observations were <strong><em>censored</em></strong> – their
true score was outside the range of values we could observe – and so we did not
really get a measure of how good these students were since a lot of their
abilities were higher than the test could detect and they all binned up at the
same value of getting all the questions correct. The relationship in this group
might be even stronger if we could really observe differences in the highest
level readers. We should treat the results for the non-dyslexic group with
caution even though they are clearly scoring on average higher and have a
different slope than the results for the dyslexic students. The QQ-plot suggests
a slightly long left tail but this deviation is not too far from what might
happen if we simulated from a normal distribution, so is not clear evidence of a
violation of the normality assumption. The influence diagnostics do not suggest
any influential points because no points have Cook’s D over 0.5. </p>

<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb826-1"><a href="chapter8.html#cb826-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb826-2"><a href="chapter8.html#cb826-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dys_model,</span>
<span id="cb826-3"><a href="chapter8.html#cb826-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">sub.caption =</span> <span class="st">&quot;Plot of diagnostics for Dyslexia Interaction model&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-32"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-32-1.png" alt="Diagnostic plots for interaction model for reading scores." width="75%" />
<p class="caption">
Figure 8.32: Diagnostic plots for interaction model for reading scores.
</p>
</div>
<p>For these models, we have relaxed an earlier assumption that data were
collected from only one group. In fact, we are doing specific research that is
focused on questions about the differences between groups. However, these models
still make assumptions that, within a specific group, the relationships are
linear between the predictor and response variables. They also assume that
the variability in the residuals is the same for all observations. Sometimes it
can be difficult to check the assumptions by looking at the overall diagnostic
plots and it may be easier to go back to the original scatterplot or plot the
residuals vs fitted values by group to fully assess the results.
 Figure <a href="chapter8.html#fig:Figure8-33">8.33</a>
shows a scatterplot of the residuals vs the quantitative explanatory variable
by the groups. The variability in the residuals is a bit larger in the
non-dyslexic group, possibly suggesting that variability in the reading test is
higher for higher scoring individuals even though we couldn’t observe all of
that variability because there were so many perfect scores in this group.</p>

<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb827-1"><a href="chapter8.html#cb827-1" aria-hidden="true" tabindex="-1"></a>dyslexic3 <span class="ot">&lt;-</span> dyslexic3 <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">resids =</span> <span class="fu">residuals</span>(dys_model),</span>
<span id="cb827-2"><a href="chapter8.html#cb827-2" aria-hidden="true" tabindex="-1"></a>                                  <span class="at">fits =</span> <span class="fu">fitted</span>(dys_model)</span>
<span id="cb827-3"><a href="chapter8.html#cb827-3" aria-hidden="true" tabindex="-1"></a>                                  )</span>
<span id="cb827-4"><a href="chapter8.html#cb827-4" aria-hidden="true" tabindex="-1"></a>dyslexic3 <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> resids, <span class="at">color =</span> dys, <span class="at">shape =</span> dys)) <span class="sc">+</span></span>
<span id="cb827-5"><a href="chapter8.html#cb827-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> F) <span class="sc">+</span></span>
<span id="cb827-6"><a href="chapter8.html#cb827-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">2.5</span>) <span class="sc">+</span></span>
<span id="cb827-7"><a href="chapter8.html#cb827-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb827-8"><a href="chapter8.html#cb827-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.7</span>, <span class="at">option =</span> <span class="st">&quot;plasma&quot;</span>) <span class="sc">+</span></span>
<span id="cb827-9"><a href="chapter8.html#cb827-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatterplot of Residuals vs Fitted by Group&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-33"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-33-1.png" alt="Plot of Residuals vs Fitted from interaction dyslexia data model with groups indicated." width="75%" />
<p class="caption">
Figure 8.33: Plot of Residuals vs Fitted from interaction dyslexia data model with groups indicated.
</p>
</div>
<p>If we feel comfortable enough with the assumptions to trust the inferences here
(this might be dangerous), then we can consider what some of the model inferences
provide us in this situation. For example, the test for
<span class="math inline">\(H_0: {\color{red}{\boldsymbol{\beta_3}}} = 0\)</span> vs
<span class="math inline">\(H_A: {\color{red}{\boldsymbol{\beta_3}}}\ne 0\)</span> provides an interesting comparison.
Under the null hypothesis, the two groups would have the same slope so it
provides an opportunity to directly consider whether the relationship (via the
slope) is different between the groups in their respective populations. We find
<span class="math inline">\(t = -1.907\)</span> which, if the assumptions are true, follows a <span class="math inline">\(t(40)\)</span>-distribution
under the null hypothesis. This test statistic has a corresponding p-value of
0.0638. So it provides some evidence against the null hypothesis of no
difference in the slopes between the two groups but it isn’t strong evidence
against it. There are serious issues (like getting the wrong idea about
directions of relationships) if we ignore a potentially important
interaction and some statisticians would recommend retaining interactions even
if the evidence is only moderate for its inclusion in the model.
 For the original research question of whether the
relationships differ for the two groups, we only have marginal evidence to
support that result. Possibly with a larger sample size or a reading test that
only a few students could get 100% on, the researchers might have detected a
more pronounced difference in the slopes for the two groups.</p>
<p>In the presence of a categorical by quantitative interaction, term-plots
can be generated that plot the results for each group on the same display or on
separate facets for each level of the categorical variable. The first version is
useful for comparing the different lines and the second version is useful to add
the partial residuals and get a final exploration of model assumptions and
ranges of values where predictor variables were observed in each group.
 The term-plots basically provide a plot of the
“simplified” SLR models for each group. In Figure <a href="chapter8.html#fig:Figure8-34">8.34</a> we can
see noticeable differences in the slopes and intercepts. Note that
testing for differences in intercepts between groups is not very interesting
when there are different slopes because if you change the slope, you have to
change the intercept. The plot shows that there are clear differences in the
means even though we don’t have a test to directly assess that in this
complicated of a model<a href="#fn154" class="footnote-ref" id="fnref154"><sup>154</sup></a>.
Figure <a href="chapter8.html#fig:Figure8-35">8.35</a> splits the plots up and adds partial residuals to
the plots. The impact on the estimated model for the perfect scores in the
non-dyslexic subjects is very prominent as well as the difference in the
relationships between the two variables in the two groups.</p>

<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="chapter8.html#cb828-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(dys_model), <span class="at">ci.style =</span> <span class="st">&quot;bands&quot;</span>, <span class="at">multiline =</span> T, <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-34"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-34-1.png" alt="Term-plots for interaction model for reading scores using the multiline = T option to overlay the results for the two groups on one plot." width="75%" />
<p class="caption">
Figure 8.34: Term-plots for interaction model for reading scores using the <code>multiline = T</code> option to overlay the results for the two groups on one plot.
</p>
</div>

<div class="sourceCode" id="cb829"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb829-1"><a href="chapter8.html#cb829-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(dys_model, <span class="at">residuals =</span> T), <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-35"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-35-1.png" alt="Term-plots for interaction model for reading scores with partial residuals and the results for the two groups in different panels of the plot." width="75%" />
<p class="caption">
Figure 8.35: Term-plots for interaction model for reading scores with partial residuals and the results for the two groups in different panels of the plot.
</p>
</div>
<p>It certainly appears in the plots that IQ has a different impact on the
mean score in the two groups (even though the p-value only provided marginal
evidence in support of the interaction). To reinforce the potential dangers of
forcing the same slope for both groups, consider the additive model for these
data. Again, this just shifts one group off the other one, but both have the
same slope. The following model summary and term-plots
(Figure <a href="chapter8.html#fig:Figure8-36">8.36</a>) suggest the potentially dangerous conclusion that
can come from assuming a common slope when that might not be the case.</p>

<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="chapter8.html#cb830-1" aria-hidden="true" tabindex="-1"></a>dys_modelR <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> ziq <span class="sc">+</span> dys, <span class="at">data =</span> dyslexic3)</span>
<span id="cb830-2"><a href="chapter8.html#cb830-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb830-3"><a href="chapter8.html#cb830-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(dys_modelR)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ ziq + dys, data = dyslexic3)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.26062 -0.05565  0.02932  0.07577  0.13217 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.89178    0.02312  38.580  &lt; 2e-16
## ziq          0.02620    0.01957   1.339    0.188
## dysyes      -0.26879    0.03905  -6.883 2.41e-08
## 
## Residual standard error: 0.1049 on 41 degrees of freedom
## Multiple R-squared:  0.6858, Adjusted R-squared:  0.6705 
## F-statistic: 44.75 on 2 and 41 DF,  p-value: 4.917e-11</code></pre>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="chapter8.html#cb832-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(dys_modelR, <span class="at">residuals =</span> T))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-36"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-36-1.png" alt="Term-plots for additive model for reading scores." width="75%" />
<p class="caption">
Figure 8.36: Term-plots for additive model for reading scores.
</p>
</div>
<p>This model provides little evidence against the null hypothesis that IQ is not
linearly related to reading score for all students (<span class="math inline">\(t_{41} = 1.34\)</span>,
p-value = 0.188), adjusted for dyslexia status, but strong evidence against the
null hypothesis of no difference in the true <span class="math inline">\(y\)</span>-intercepts (<span class="math inline">\(t_{41} = -6.88\)</span>,
p-value <span class="math inline">\(&lt;0.00001\)</span>) after adjusting for the verbal IQ score.</p>
<p>Since the IQ term has a large p-value, we could drop it from the
model – leaving a model that only includes the grouping variable:</p>
<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb833-1"><a href="chapter8.html#cb833-1" aria-hidden="true" tabindex="-1"></a>dys_modelR2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(score <span class="sc">~</span> dys, <span class="at">data =</span> dyslexic3)</span>
<span id="cb833-2"><a href="chapter8.html#cb833-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(dys_modelR2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ dys, data = dyslexic3)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.25818 -0.04510  0.02514  0.09520  0.09694 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  0.90480    0.02117  42.737   &lt;2e-16
## dysyes      -0.29892    0.03222  -9.278    1e-11
## 
## Residual standard error: 0.1059 on 42 degrees of freedom
## Multiple R-squared:  0.6721, Adjusted R-squared:  0.6643 
## F-statistic: 86.08 on 1 and 42 DF,  p-value: 1e-11</code></pre>

<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb835-1"><a href="chapter8.html#cb835-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(dys_modelR2, <span class="at">residuals =</span> T), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-37"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-37-1.png" alt="Term-plot for dyslexia status only model for reading scores." width="75%" />
<p class="caption">
Figure 8.37: Term-plot for dyslexia status only model for reading scores.
</p>
</div>
<p>These results, including the term-plot in Figure <a href="chapter8.html#fig:Figure8-37">8.37</a>, suggest
a difference in the mean reading scores between the two groups and maybe that is
all these data really say… This is the logical outcome if we decide that the
interaction is not important <em>in this data set</em>. In general, if the interaction
is dropped, the interaction model can be reduced to considering an additive
model with the categorical and quantitative predictor variables.
  Either or both of those
variables could also be considered for removal, usually starting with the
variable with the larger p-value, leaving a string of ever-simpler models
possible if large p-values are continually encountered<a href="#fn155" class="footnote-ref" id="fnref155"><sup>155</sup></a>.</p>
<p>It is useful to note that the last model has returned us to the first
model we encountered in Chapter <a href="chapter2.html#chapter2">2</a> where we were just comparing
the means for two groups.
However, the researchers probably were not seeking to make the discovery that
dyslexic students have a tougher time than non-dyslexic students on a reading
test but sometimes that is all that the data support. The key part of this
sequence of decisions was how much evidence you think a p-value of 0.06
contains…</p>
<div style="page-break-after: always;"></div>
<p>For more than two categories in a categorical variable, the model
contains more indicators to keep track of but uses the same ideas. We have to
deal with modifying the intercept and slope coefficients for <strong>every</strong>
deviation group so the task is onerous but relatively repetitive.
 The general model is:</p>
<p><span class="math display">\[\begin{array}{rl}
y_i = \beta_0 &amp;+ \beta_1x_i +\beta_2I_{\text{Level }2,i}+\beta_3I_{\text{Level }3,i}
+\cdots+\beta_JI_{\text{Level }J,i} \\
&amp;+\beta_{J+1}I_{\text{Level }2,i}\:x_i+\beta_{J+2}I_{\text{Level }3,i}\:x_i
+\cdots+\beta_{2J-1}I_{\text{Level }J,i}\:x_i +\varepsilon_i.\ 
\end{array}\]</span></p>
<p>Specific to the audible tolerance/headache data that had four groups. The model
with an interaction present is</p>
<p><span class="math display">\[\begin{array}{rl}
\text{du2}_i = \beta_0 &amp; + \beta_1\cdot\text{du1}_i + \beta_2I_{T1,i} +
\beta_3I_{T2,i} + \beta_4I_{\text{T3},i} \\
&amp;+ \beta_5I_{T1,i}\cdot\text{du1}_i + \beta_6I_{T2,i}\cdot\text{du1}_i
+ \beta_7I_{\text{T3},i}\cdot\text{du1}_i+\varepsilon_i.\ 
\end{array}\]</span></p>
<p>Based on the following output, the estimated general regression model is</p>
<p><span class="math display">\[\begin{array}{rl}
\widehat{\text{du2}}_i = 0.241 &amp;+ 0.839\cdot\text{du1}_i + 1.091I_{T1,i} + 0.855I_{T2,i} +0.775I_{T3,i} \\
&amp; - 0.106I_{T1,i}\cdot\text{du1}_i - 0.040I_{T2,i}\cdot\text{du1}_i
+ 0.093I_{T3,i}\cdot\text{du1}_i.\ 
\end{array}\]</span></p>
<p>Then we could work out the specific equation for <strong>each group</strong> with
replacing their indicator variable in two places with 1s and the rest of
the indicators with 0. For example, for the <em>T1</em> group:</p>
<p><span class="math display">\[\begin{array}{rll}
\widehat{\text{du2}}_i &amp; = 0.241 &amp;+ 0.839\cdot\text{du1}_i + 1.091\cdot1 + 0.855\cdot0 +0.775\cdot0 \\
&amp;&amp;- 0.106\cdot1\cdot\text{du1}_i - 0.040\cdot0\cdot\text{du1}_i
+ 0.093\cdot0\cdot\text{du1}_i \\
\widehat{\text{du2}}_i&amp; = 0.241&amp;+0.839\cdot\text{du1}_i + 1.091 - 0.106\cdot\text{du1}_i \\
\widehat{\text{du2}}_i&amp; = 1.332 &amp;+ 0.733\cdot\text{du1}_i.\ 
\end{array}\]</span></p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-38"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-38-1.png" alt="Term-plot for decibel tolerance interaction model with partial residuals (version 1)." width="75%" />
<p class="caption">
Figure 8.38: Term-plot for decibel tolerance interaction model with partial residuals (version 1).
</p>
</div>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb836-1"><a href="chapter8.html#cb836-1" aria-hidden="true" tabindex="-1"></a>head2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(du2 <span class="sc">~</span> du1 <span class="sc">*</span> treatment, <span class="at">data =</span> Headache)</span>
<span id="cb836-2"><a href="chapter8.html#cb836-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(head2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = du2 ~ du1 * treatment, data = Headache)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -6.8072 -1.0969 -0.3285  0.8192 10.6039 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      0.24073    0.68331   0.352    0.725
## du1              0.83923    0.10289   8.157 1.93e-12
## treatmentT1      1.09084    0.95020   1.148    0.254
## treatmentT2      0.85524    1.14770   0.745    0.458
## treatmentT3      0.77471    0.97370   0.796    0.428
## du1:treatmentT1 -0.10604    0.14326  -0.740    0.461
## du1:treatmentT2 -0.03981    0.17658  -0.225    0.822
## du1:treatmentT3  0.09300    0.13590   0.684    0.496
## 
## Residual standard error: 2.148 on 90 degrees of freedom
## Multiple R-squared:  0.7573, Adjusted R-squared:  0.7384 
## F-statistic: 40.12 on 7 and 90 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Or we can let the term-plots (Figures <a href="chapter8.html#fig:Figure8-38">8.38</a> and
<a href="chapter8.html#fig:Figure8-39">8.39</a>) show us all four different simplified models. Here we
can see that all the slopes “look” to be pretty similar. When the interaction
model is fit and the results “look” like the additive model, there is a good
chance that we will be able to avoid all this complication and just use the
additive model without missing anything interesting. 
There are two different options for displaying interaction models. Version 1
(Figure <a href="chapter8.html#fig:Figure8-38">8.38</a>) has a different panel for each level of the
categorical variable and Version 2 (Figure <a href="chapter8.html#fig:Figure8-39">8.39</a>) puts all the
lines on the same plot. In this case, neither version shows much of a difference
and Version 2 overlaps so much that you can’t see all the groups. In these
situations, it can be useful to make the term-plots twice, once with
<code>multiline = T</code> and once <code>multiline = F</code>, and then select the version that
captures the results best.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-39"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-39-1.png" alt="Term-plot for decibel tolerance interaction model (version 2). This plot is not printed in color because it is impossible to distinguish the four groups whether in color or black and white, although the lty = c(1:4) that provides four different line types does help a bit." width="75%" />
<p class="caption">
Figure 8.39: Term-plot for decibel tolerance interaction model (version 2). This plot is not printed in color because it is impossible to distinguish the four groups whether in color or black and white, although the <code>lty = c(1:4)</code> that provides four different line types does help a bit.
</p>
</div>
<div class="sourceCode" id="cb838"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb838-1"><a href="chapter8.html#cb838-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(head2, <span class="at">residuals =</span> T), <span class="at">grid =</span> T) <span class="co">#version 1</span></span>
<span id="cb838-2"><a href="chapter8.html#cb838-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(head2), <span class="at">multiline =</span> T, <span class="at">ci.style =</span> <span class="st">&quot;bands&quot;</span>, <span class="at">grid =</span> T, </span>
<span id="cb838-3"><a href="chapter8.html#cb838-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">lty =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>), <span class="at">lwd =</span> <span class="dv">2</span>) <span class="co">#version 2</span></span></code></pre></div>
<p>In situations with more than 2 levels, the <span class="math inline">\(t\)</span>-tests for the interaction
or changing <span class="math inline">\(y\)</span>-intercepts are not informative for deciding if you really need
different slopes or intercepts for all the groups. 
They only tell you if a specific group is potentially different from the
baseline group and the choice of the baseline is arbitrary. To assess whether we
really need to have varying slopes or intercepts with more than two groups we
need to develop <span class="math inline">\(F\)</span>-tests for the interaction part of the model.</p>
<!-- \newpage -->
</div>
<div id="section8-12" class="section level2" number="8.12">
<h2><span class="header-section-number">8.12</span> F-tests for MLR models with quantitative and categorical variables and interactions</h2>
<p>For models with multi-category <span class="math inline">\((J&gt;2)\)</span> categorical variables we need a method
for deciding if all the extra complexity present in the additive or interaction
models is necessary. We can appeal to model selection methods such as the
adjusted <strong><em>R</em></strong><sup>2</sup> that focus on balancing model fit and complexity but
interests often move to trying to decide if the differences are more extreme
than we would expect by chance if there were no group differences in intercepts
or slopes. Because of the multi-degree of freedom aspects of the use of indicator
variables (<span class="math inline">\(J-1\)</span> variables for a <span class="math inline">\(J\)</span> level categorical variable), we have to
develop tests that combine and assess information across multiple
“variables” – even though these indicators all pertain to a single original
categorical variable.  ANOVA <span class="math inline">\(F\)</span>-tests did exactly
this sort of thing in the One and Two-Way ANOVA models and can do that for us
here. There are two models that we perform tests in – the additive and the
interaction models.  
We start with a discussion of the tests in an interaction setting since that
provides us the <strong>first test to consider</strong> in most situations to assess
evidence of whether the extra complexity of varying slopes is really needed. If
we don’t “need” the varying slopes or if the plot really does have lines for the
groups that look relatively parallel, we can fit the additive model and either
assess evidence of the need for different intercepts or for the quantitative
predictor – either is a reasonable next step. 
Basically this establishes a set of <strong><em>nested models</em></strong> (each model is a reduced
version of another more complicated model higher in the tree of models and we
can move down the tree by setting a set of slope coefficients to 0) displayed in
Figure <a href="chapter8.html#fig:Figure8-40">8.40</a>. This is based on the assumption that we would
proceed through the model, dropping terms if the p-values are large (“not
significant” in the diagram) to arrive at a final model. </p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-40"></span>
<img src="chapter8_files/nestedModelTree_medium.png" alt="Diagram of models to consider in an interaction model. “Sig.” means a small p-value for that term and “not sig.” means a large one – with apologies for using the “s”-word here." width="75%" />
<p class="caption">
Figure 8.40: Diagram of models to consider in an interaction model. “Sig.” means a small p-value for that term and “not sig.” means a large one – with apologies for using the “s”-word here.
</p>
</div>
<p>If the initial interaction test suggests the interaction is important,
then no further refinement should be considered and that model should be
explored (this was the same protocol suggested in the 2-WAY ANOVA situation, the
other place where we considered interactions).  If the
interaction is not deemed important based on the test, then the model should be
re-fit using both variables in an additive model.  In that
additive model, both variables can be assessed conditional on the other one. If
both have small p-values, then that is the final model and should be explored
further. If either the categorical or quantitative variable have large p-values,
then they can be dropped from the model and the model re-fit with only one
variable in it, usually starting with dropping the component with the largest
p-value if both are not “small.” Note that if there is only a categorical
variable remaining, then we would call that linear model a One-Way ANOVA
(quantitative response and <span class="math inline">\(J\)</span> group categorical explanatory) and if the only
remaining variable is quantitative, then a SLR model is being fit. If that final
variable has a large p-value in either model, it can be removed and all that is
left to describe the responses is a mean-only model. Otherwise the single
variable model is the final model. Usually we will not have to delve deeply into
this tree of models and might stop earlier in the tree if that fully addresses
our research question, but it is good to consider the potential paths that an
analysis could involve before it is started if model refinement is being
considered.</p>
<p>To perform the first test (after checking that assumptions are not
problematic, of course), we can apply the <code>Anova</code> function from the <code>car</code>
package to an interaction model<a href="#fn156" class="footnote-ref" id="fnref156"><sup>156</sup></a>.
 It will provide three tests, one for each variable by
themselves, which are not too interesting, and then the interaction test. This
will result in an <span class="math inline">\(F\)</span>-statistic that, if the assumptions are true, will follow
an <span class="math inline">\(F(J-1, n-2J)\)</span>-distribution under the null hypothesis. This tests the
hypotheses:</p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{H_0:}\)</span> <strong>The slope for <span class="math inline">\(\boldsymbol{x}\)</span> is the same for all
<span class="math inline">\(\boldsymbol{J}\)</span> groups in the population vs</strong></p></li>
<li><p><span class="math inline">\(\boldsymbol{H_A:}\)</span> <strong>The slope for <span class="math inline">\(\boldsymbol{x}\)</span> in at least one group
differs from the others in the population.</strong></p></li>
</ul>
<p>This test is also legitimate in the case of a two-level categorical variable
<span class="math inline">\((J = 2)\)</span> and then follows an <span class="math inline">\(F(1, n-4)\)</span>-distribution under the null
hypothesis. With <span class="math inline">\(J = 2\)</span>, the p-value from this test matches the results for the
<span class="math inline">\(t\)</span>-test <span class="math inline">\((t_{n-4})\)</span> for the single slope-changing coefficient in the model
summary output. The noise tolerance study, introduced in Section
<a href="chapter8.html#section8-10">8.10</a>, provides a situation for exploring the results in
detail.</p>
<p>With the <span class="math inline">\(J = 4\)</span> level categorical variable (<em>Treatment</em>), the model for
the second noise tolerance measurement (<em>du2</em>) as a function of the interaction
between <em>Treatment</em> and initial noise tolerance (<em>du1</em>) is</p>
<p><span class="math display">\[\begin{array}{rl}
\text{du2}_i = \beta_0 &amp;+ \beta_1\cdot\text{du1}_i + \beta_2I_{T1,i} +
\beta_3I_{T2,i} + \beta_4I_{T3,i} \\
&amp;+ \beta_5I_{T1,i}\cdot\text{du1}_i + \beta_6I_{T2,i}\cdot\text{du1}_i
+ \beta_7I_{T3,i}\cdot\text{du1}_i+\varepsilon_i.
\end{array}\]</span></p>
<p>We can re-write the previous hypotheses in one of two more specific ways:</p>
<ul>
<li><p><span class="math inline">\(H_0:\)</span> The slope for <em>du1</em> is the same for all four <em>Treatment</em> groups in the
population OR</p></li>
<li><p><span class="math inline">\(H_0: \beta_5 = \beta_6 = \beta_7 = 0\)</span></p>
<ul>
<li>This defines a null hypothesis that all the deviation coefficients for
getting different slopes for the different treatments are 0 in the
population.</li>
</ul></li>
<li><p><span class="math inline">\(H_A:\)</span> The slope for <em>du1</em> is NOT the same for all four <em>Treatment</em> groups in
the population (at least one group has a different slope) OR</p></li>
<li><p><span class="math inline">\(H_A:\)</span> At least one of <span class="math inline">\(\beta_5,\beta_6,\beta_7\)</span> is different from 0 in the
population.</p>
<ul>
<li>The alternative states that at least one of the deviation coefficients
for getting different slopes for the different <em>Treatments</em> is not 0 in the
population.</li>
</ul></li>
</ul>
<p>In this situation, the results for the test of these hypotheses is in the row
labeled <code>du1:treatment</code> in the <code>Anova</code> output. The ANOVA table below shows
a test statistic of <span class="math inline">\(F = 0.768\)</span> with the <em>numerator df</em> of 3, coming from <span class="math inline">\(J-1\)</span>,
and the <em>denominator df</em> of 90, coming from <span class="math inline">\(n-2J = 98-2*4 = 90\)</span> and also provided
in the <code>Residuals</code> row in the table, leading to an <span class="math inline">\(F(3, 90)\)</span>-distribution
for the test statistic under the null hypothesis.

The p-value from this
distribution is 0.515, showing little to no evidence against
the null hypothesis, so does not suggest that the slope coefficient for <em>du1</em> in explaining <em>du2</em> is different for
at least one of the <em>Treatment</em> groups in the population.</p>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="chapter8.html#cb839-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(head2)</span></code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: du2
##                Sum Sq Df  F value Pr(&gt;F)
## du1           1197.78  1 259.5908 &lt;2e-16
## treatment       23.90  3   1.7265 0.1672
## du1:treatment   10.63  3   0.7679 0.5150
## Residuals      415.27 90</code></pre>
<p>Without evidence to support using an interaction, we should consider both the
quantitative and categorical variables in an additive model. The ANOVA table
for the additive model contains two interesting tests.


One test is for the
quantitative variable discussed previously. The other is for the categorical
variable, assessing whether different <span class="math inline">\(y\)</span>-intercepts are needed. The additive
model here is</p>
<p><span class="math display">\[\text{du2}_i = \beta_0 + \beta_1\cdot\text{du1}_i + \beta_2I_{T1,i} +
\beta_3I_{T2,i} + \beta_4I_{T3,i} +\varepsilon_i.\ \]</span></p>
<p>The hypotheses assessed in the ANOVA test for treatment are:</p>
<ul>
<li><p><span class="math inline">\(H_0:\)</span> The <span class="math inline">\(y\)</span>-intercept for the model with <em>du1</em> is the same for all four
<em>Treatment</em> groups in the population OR</p></li>
<li><p><span class="math inline">\(H_0: \beta_2 = \beta_3 = \beta_4 = 0\)</span></p>
<ul>
<li>This defines a null hypothesis that all the deviation coefficients for
getting different <span class="math inline">\(y\)</span>-intercepts for the different <em>Treatments</em> are 0 in
the population.</li>
</ul></li>
<li><p><span class="math inline">\(H_A:\)</span> The <span class="math inline">\(y\)</span>-intercepts for the model with <em>du1</em> is NOT the same for all four
<em>Treatment</em> groups in the population (at least one group has a different
<span class="math inline">\(y\)</span>-intercept) OR</p></li>
<li><p><span class="math inline">\(H_A:\)</span> At least one of <span class="math inline">\(\beta_2,\beta_3,\beta_4\)</span> is different from 0 in the
population.</p>
<ul>
<li>The alternative states that at least one of the deviation coefficients
for getting different <span class="math inline">\(y\)</span>-intercepts for the different <em>Treatments</em> is not 0
in the population.</li>
</ul></li>
</ul>
<p>The <span class="math inline">\(F\)</span>-test for the categorical variable in an additive model follows
<span class="math inline">\(F(J-1, n-J-1)\)</span>-distribution under the null hypothesis. 
 For this example, the test statistic for <em>Treatment</em> follows
an <span class="math inline">\(F(3, 93)\)</span>-distribution under the null hypothesis. The observed test
statistic has a value of 1.74, generating a p-value of 0.164. So we would find
weak evidence against the null hypothesis and so does not suggest some
difference in <span class="math inline">\(y\)</span>-intercepts between the <em>treatment</em> groups, in a model
with <em>du1</em>, in the population. We could interpret this in the fashion we used
initially in MLR by stating this result as: there is little evidence against the
null hypothesis of no difference in the mean <em>du2</em> for the <em>Treatment</em> groups
after controlling for <em>du1</em> so we would conclude that there is possibly no
difference between the groups controlled for <em>du1</em>.</p>
<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb841-1"><a href="chapter8.html#cb841-1" aria-hidden="true" tabindex="-1"></a>head1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(du2 <span class="sc">~</span> du1 <span class="sc">+</span> treatment, <span class="at">data =</span> Headache)</span>
<span id="cb841-2"><a href="chapter8.html#cb841-2" aria-hidden="true" tabindex="-1"></a><span class="fu">Anova</span>(head1)</span></code></pre></div>
<pre><code>## Anova Table (Type II tests)
## 
## Response: du2
##           Sum Sq Df  F value Pr(&gt;F)
## du1       1197.8  1 261.5491 &lt;2e-16
## treatment   23.9  3   1.7395 0.1643
## Residuals  425.9 93</code></pre>
<p>In the same ANOVA table, there is a test for the <em>du1</em> model component.
This tests <span class="math inline">\(H_0: \beta_1 = 0\)</span> vs <span class="math inline">\(H_A: \beta_1\ne 0\)</span> in a model with different
<span class="math inline">\(y\)</span>-intercepts for the different treatment groups. If we remove this term from
the model, all we are left with is different <span class="math inline">\(y\)</span>-intercepts for the groups. A
model just with different <span class="math inline">\(y\)</span>-intercepts is typically called a One-Way ANOVA
model. Here, there it appears that the quantitative variable is needed in the
model after controlling for the different <span class="math inline">\(y\)</span>-intercepts for different
treatments since it has a small p-value (<span class="math inline">\(F\)</span>(1,93) = 261.55 or <span class="math inline">\(t\)</span>(93) = 16.172,
p-value&lt;0.0001). Note that this interpretation retains the conditional wording
regardless of whether the other variable had a small p-value or it did not. If
you want an unconditional interpretation for a variable, then you will need to
refit the model without the other variable(s) after deciding that they are not
important.</p>
</div>
<div id="section8-13" class="section level2" number="8.13">
<h2><span class="header-section-number">8.13</span> AICs for model selection</h2>
<p>There are a variety of techniques for selecting among a set of potential models
or refining an initially fit MLR model. Hypothesis testing can be used (in the
case where we have nested models either by adding or deleting a single term at
a time) or comparisons of adjusted <strong><em>R</em></strong><sup>2</sup> across different potential models
(which is valid for nested or non-nested model comparisons).
 Diagnostics should play a role in the models
considered and in selecting among models that might appear to be similar on a
model comparison criterion. In this section, a new model selection method is
introduced that has stronger theoretical underpinnings, a slightly more
interpretable scale, and, often, better performance in picking an optimal<a href="#fn157" class="footnote-ref" id="fnref157"><sup>157</sup></a>
model than the <strong><em>adjusted</em></strong> <strong><em>R</em></strong><sup>2</sup>. The measure is called the <strong><em>AIC</em></strong>
(Akaike’s An Information Criterion<a href="#fn158" class="footnote-ref" id="fnref158"><sup>158</sup></a>, <span class="citation">(<a href="#ref-Akaike1974" role="doc-biblioref">Akaike 1974</a>)</span>). It is extremely
popular, but sometimes misused, in some fields such as Ecology and has been
applied in almost every other potential application area where statistical
models can be compared. <span class="citation"><a href="#ref-Burnham2002" role="doc-biblioref">Burnham and Anderson</a> (<a href="#ref-Burnham2002" role="doc-biblioref">2002</a>)</span> have been responsible for popularizing the
use of AIC for model selection, especially in Ecology. The <strong>AIC is an estimate
of the distance (or discrepancy or divergence) between a candidate model and the
true model, on a log-scale</strong>, based on a measure called the Kullback-Leibler
divergence. The models that are closer (have a smaller distance) to the truth
are better and we can compare how close two models are to the truth, picking the
one that has a smaller distance (smaller AIC) as better. The AIC includes a
component that is on the log-scale, so negative values are possible and you
should not be disturbed if you are comparing large magnitude negative
numbers – just pick the model with the smallest AIC score.</p>
<p>The AIC is optimized (smallest) for a model that contains the optimal
balance of simplicity of the model with quality of fit to the observations.
Scientists are driven to different degrees by what is called the <strong><em>principle
of parsimony</em></strong>: that <strong>simpler explanations (models) are better if everything
else is equal or even close to equal</strong>. In this case, it would
mean that if two models are similarly good on AIC, then select the simpler of
the two models since it is more likely to be correct in general than the more
complicated model. The AIC is calculated as <span class="math inline">\(AIC = -2log(Likelihood)+2m\)</span>, where
the <strong><em>Likelihood</em></strong> provides a measure of fit of the model (we let R
calculate it for us) and gets smaller for better fitting models and
<span class="math inline">\(m\)</span> = (number of estimated <span class="math inline">\(\beta\text{&#39;s}+1\)</span>). The value <span class="math inline">\(m\)</span> is called the
<em>model degrees of freedom</em> for AIC calculations and relates to how many total
parameters are estimated.  Note that it is a
different measure of <em>degrees of freedom</em> than used in ANOVA <span class="math inline">\(F\)</span>-tests. The main
things to understand about the formula for the AIC is that as <span class="math inline">\(m\)</span> increases, the
AIC will go up and that as the fit improves, the <em>likelihood</em> will increase (so
-2<em>log-likelihood</em> will get smaller)<a href="#fn159" class="footnote-ref" id="fnref159"><sup>159</sup></a>.</p>
<p>There are some facets of this discussion to keep in mind when comparing
models. More complicated models always fit better (we saw this for the
<strong><em>R</em></strong><sup>2</sup> measure, as the proportion of variation explained always goes
up if more “stuff” is put into the model even if the “stuff” isn’t useful). The
AIC resembles the adjusted <strong><em>R</em></strong><sup>2</sup> in that it incorporates the count
of the number of parameters estimated. This allows the AIC to make sure that
enough extra variability is explained in the responses to justify making the
model more complicated (increasing <span class="math inline">\(m\)</span>). The optimal model on AIC has to balance
adding complexity and increasing quality of the fit. Since this measure
provides an estimate of the distance or discrepancy to the “true model,” the
model with the smallest value “wins” – it is top-ranked on the AIC. Note that
the <strong>top-ranked AIC model</strong> will often <strong>not be the best fitting</strong> model
since the best fitting model is always the most complicated model considered.
The top AIC model is the one that is estimated to be closest to the truth,
where the truth is still unknown…</p>
<p>To help with interpreting the scale of AICs, they are often reported in
a table sorted from smallest to largest values with the AIC and the “delta AIC”
or, simply, <span class="math inline">\(\Delta\text{AIC}\)</span> reported. The</p>
<p><span class="math display">\[\Delta\text{AIC} = \text{AIC}_{\text{model}} - \text{AIC}_{\text{topModel}}\]</span></p>
<p>and so provides a value of 0 for the top-ranked AIC model and a measure of how
much worse on the AIC scale the other models are. A rule of thumb is that a 2
unit difference on AICs <span class="math inline">\((\Delta\text{AIC} = 2)\)</span> is moderate evidence of a
difference in the models and more than 4 units <span class="math inline">\((\Delta\text{AIC}&gt;4)\)</span> is strong
evidence of a difference. This is more based on experience than a distinct reason
or theoretical result but seems to provide reasonable results in most situations.
Often researchers will consider any models within 2 AIC units of the top model
<span class="math inline">\((\Delta\text{AIC}&lt;2)\)</span> as indistinguishable on
AICs and so either select the simplest model of the choices or report all the
models with similar “support,” allowing the reader to explore the suite of
similarly supported potential models. It is important to remember that if you
search across too many models, even with the AIC to support your model
comparisons, you might find a spuriously top model. Individual results that are
found by exploring many tests or models have higher chances to be <strong><em>spurious</em></strong>
and results found in this manner are difficult to <strong><em>replicate</em></strong> when
someone repeats a similar study.
For these reasons, there is a set of general recommendations that have been
developed for using AICs:</p>
<ul>
<li><p>Consider a suite of models (often pre-specified and based on prior research in
the area of interest) and find the models with the top (in other words,
smallest) AIC results.</p>
<ul>
<li>The suite of candidate models need to contain at least some good models.
Selecting the best of a set of BAD models only puts you at the top of
$%#%-mountain, which is not necessarily a good thing.</li>
</ul></li>
<li><p>Report a table with the models considered, sorted from smallest to largest
AICs (<span class="math inline">\(\Delta\text{AICs}\)</span> from smaller to larger) that includes a count of
number of parameters estimated<a href="#fn160" class="footnote-ref" id="fnref160"><sup>160</sup></a>, the
AICs, and <span class="math inline">\(\Delta\text{AICs}\)</span>.</p>
<ul>
<li>Remember to incorporate the mean-only model in the model selection results.
This allows you to compare the top model to one that does not contain any
predictors.</li>
</ul></li>
<li><p>Interpret the top model or top models if a few are close on the AIC-scale to
the top model.</p></li>
<li><p><strong>DO NOT REPORT P-VALUES OR CALL TERMS “SIGNIFICANT” when models were selected
using AICs.</strong> </p>
<ul>
<li>Hypothesis testing and AIC model selection are not compatible philosophies
and testing in models selected by AICs invalidates the tests as they have
inflated Type I error rates.


The AIC results are your “evidence” – you don’t need anything else. If you
wanted to report p-values, use them to select your model.</li>
</ul></li>
<li><p>You can describe variables as “important” or “useful” and report confidence
intervals to aid in interpretation of the terms in the selected model(s)
but need to avoid performing hypothesis tests with the confidence intervals.</p></li>
<li><p>Remember that the selected model is not the “true” model – it is only the
best model <em>according to AIC</em> among the set of models <em>you provided</em>.</p></li>
<li><p>AICs assume that the model is
specified correctly up to possibly comparing different predictor variables.
Perform diagnostic checks on your initial model and the top model and do not
trust AICs when assumptions are clearly violated (p-values are similarly not
valid in that situation). </p></li>
</ul>
<p>When working with AICs, there are two options. Fit the models of
interest and then run the <code>AIC</code> function on each model. This can be tedious,
especially when we have many possible models to consider. We can make
it easy to fit all the potential candidate models that are implied by a
complicated starting model by using the <code>dredge</code> function from the <code>MuMIn</code>
package <span class="citation">(<a href="#ref-R-MuMIn" role="doc-biblioref">Barton 2020</a>)</span>.  The name (dredge) actually
speaks to what <strong><em>fitting all possible models</em></strong> really engages – what is
called <strong><em>data dredging</em></strong>. The term is meant to refer to considering way too
many models for your data set, probably finding something good from the process,
but maybe identifying something spurious since you looked at so many models.
Note that if you take a hypothesis testing approach where you plan to remove any
terms with large p-values in this same situation, you are really considering all
possible models as well because you could have removed some or all model
components.  Methods that consider all possible models
are probably best used in exploratory analyses where you do not
know if any or all terms should be important. If you have more specific
research questions, then you probably should try to focus on comparisons of models
that help you directly answer those questions, either with AIC or p-value methods.</p>
<p>The <code>dredge</code> function provides an automated method of assessing all possible
simpler models based on an initial (full) model. It generates a table of AIC
results, <span class="math inline">\(\Delta\text{AICs}\)</span>, and also shows when various predictors are in or
out of the model for all reduced models possible from an initial model. For
quantitative predictors, the estimated slope is reported when that predictor is
in the model. For categorical variables and interactions with them, it just
puts a “+” in the table to let you know that the term is in the models. Note
that you must run the <code>options(na.action = "na.fail")</code> code to get <code>dredge</code>
to work<a href="#fn161" class="footnote-ref" id="fnref161"><sup>161</sup></a>.</p>
<p>To explore the AICs and compare their results to the adjusted <strong><em>R</em></strong><sup>2</sup>
that we used before for model selection, we can revisit the <em>Snow Depth</em> data set
with related results found in Section <a href="chapter8.html#section8-4">8.4</a> and
Table <a href="chapter8.html#tab:Table8-1">8.1</a>. In that situation we were considering a “full” model
that included <em>Elevation</em>, <em>Min.Temp</em>, and <em>Max.Temp</em> as potential predictor
variables after removing two influential points. 
 And we considered all possible reduced models from that
“full”<a href="#fn162" class="footnote-ref" id="fnref162"><sup>162</sup></a> model. Note
that the <code>dredge</code> output adds one more model that adjusted <strong><em>R</em></strong><sup>2</sup>
can’t consider – the mean-only model that contains no predictor variables. In
the following output it is the last model in the output (worst ranked on AIC).
Including the mean-only model in these results helps us “prove” that there is
support for having something in the model, but only if there is better support for
other models than this simplest possible model.</p>
<p>In reading <code>dredge</code> output<a href="#fn163" class="footnote-ref" id="fnref163"><sup>163</sup></a> as it is constructed
here, the models are sorted by top to bottom AIC values (smallest AIC to
largest). The column <code>delta</code> is for the <span class="math inline">\(\Delta\text{AICs}\)</span> and shows a 0 for
the first row, which is the top-ranked AIC model. Here it is for the model with
<em>Elevation</em> and <em>Max.Temp</em> but not including <em>Min.Temp</em>. This was also the top
ranked model from adjusted <strong><em>R</em></strong><sup>2</sup>, which is reproduced in the <code>adjRsq</code>
column. The <code>AIC</code> is calculated using the previous formula based on the <code>df</code>
and <code>logLik</code> columns. The <code>df</code> is also a useful column for comparing models
as it helps you see how complex each model is. For example, the top model used
up 4 <em>model df</em> (three <span class="math inline">\(\beta\text{&#39;s}\)</span> and the residual error variance) and the
most complex model that included four predictor variables used up 5 <em>model df</em>.</p>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb843-1"><a href="chapter8.html#cb843-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb843-2"><a href="chapter8.html#cb843-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">na.action =</span> <span class="st">&quot;na.fail&quot;</span>) <span class="co">#Must run this code once to use dredge</span></span>
<span id="cb843-3"><a href="chapter8.html#cb843-3" aria-hidden="true" tabindex="-1"></a>snotel2R <span class="ot">&lt;-</span> snotel_s <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">22</span>))</span>
<span id="cb843-4"><a href="chapter8.html#cb843-4" aria-hidden="true" tabindex="-1"></a>m6 <span class="ot">&lt;-</span> <span class="fu">lm</span>(Snow.Depth <span class="sc">~</span> Elevation <span class="sc">+</span> Min.Temp <span class="sc">+</span> Max.Temp, <span class="at">data =</span> snotel2R)</span>
<span id="cb843-5"><a href="chapter8.html#cb843-5" aria-hidden="true" tabindex="-1"></a><span class="fu">dredge</span>(m6, <span class="at">rank =</span> <span class="st">&quot;AIC&quot;</span>, <span class="at">extra =</span> <span class="fu">c</span>(<span class="st">&quot;R^2&quot;</span>, <span class="at">adjRsq =</span> <span class="cf">function</span>(x) <span class="fu">summary</span>(x)<span class="sc">$</span>adj.r.squared))</span></code></pre></div>
<pre><code>## Global model call: lm(formula = Snow.Depth ~ Elevation + Min.Temp + Max.Temp, data = snotel2R)
## ---
## Model selection table 
##     (Int)     Elv Max.Tmp Min.Tmp    R^2 adjRsq df   logLik   AIC delta weight
## 4 -167.50 0.02408  1.2530         0.8495 0.8344  4  -80.855 169.7  0.00  0.568
## 8 -213.30 0.02686  1.2430  0.9843 0.8535 0.8304  5  -80.541 171.1  1.37  0.286
## 2  -80.41 0.01791                 0.8087 0.7996  3  -83.611 173.2  3.51  0.098
## 6 -130.70 0.02098          1.0660 0.8134 0.7948  4  -83.322 174.6  4.93  0.048
## 5  179.60                 -5.0090 0.6283 0.6106  3  -91.249 188.5 18.79  0.000
## 7  178.60         -0.2687 -4.6240 0.6308 0.5939  4  -91.170 190.3 20.63  0.000
## 3  119.50         -2.1800         0.4131 0.3852  3  -96.500 199.0 29.29  0.000
## 1   40.21                         0.0000 0.0000  2 -102.630 209.3 39.55  0.000
## Models ranked by AIC(x)</code></pre>
<p>You can use the table of results from <code>dredge</code> to find information to
compare the estimated models. There are two models that are clearly favored over
the others with <span class="math inline">\(\Delta\text{AICs}\)</span> for the model with <em>Elevation</em> and
<em>Max.Temp</em> of 0 and for the model with all three predictors of 1.37. The
<span class="math inline">\(\Delta\text{AIC}\)</span> for the third ranked model (contains just <em>Elevation</em>) is
3.51 suggesting clear support for the top model over this because of a
difference of 3.51 AIC units to the truth. The difference between the second and
third ranked models also provides relatively strong support for the more complex
model over the model with just <em>Elevation</em>. And the mean-only model had a
<span class="math inline">\(\Delta\text{AIC}\)</span> of nearly 40 – suggesting extremely strong evidence for the
top model versus using no predictors. So we have pretty clear support for models
that include the <em>Elevation</em> and <em>Max.Temp</em> variables (in both top models) and
some support for also including the <em>Min.Temp</em>, but the top model did not
require its inclusion. It is also possible to think about the AICs as a result
on a number line from “closest to the truth” to “farthest” for the suite of
models considered, as shown in Figure <a href="chapter8.html#fig:Figure8-41">8.41</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-41"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-41-1.png" alt="Display of AIC results on a number line with models indicated by their number in the dredge output. Note that the actual truth is unknown but further left in the plot corresponds to the models that are estimated to be closer to the truth and so there is stronger evidence for those models versus the others." width="75%" />
<p class="caption">
Figure 8.41: Display of AIC results on a number line with models indicated by their number in the <code>dredge</code> output. Note that the actual truth is unknown but further left in the plot corresponds to the models that are estimated to be closer to the truth and so there is stronger evidence for those models versus the others.
</p>
</div>
<p>We could add further explorations of the term-plots and confidence
intervals for the slopes from the top or, here, possibly top two models. We
would not spend any time with p-values since we already used the AIC to assess
evidence related to the model components and they are invalid if we model
select prior to reporting them. We can quickly compare the slopes for variables
that are shared in the two models since they are both quantitative variables
using the output. It is interesting that the <em>Elevation</em> and <em>Max.Temp</em> slopes
change little with the inclusion of <em>Min.Temp</em> in moving from the top to second
ranked model (0.02408 to 0.0286 and 1.253 to 1.243).</p>
<p>This was an observational study and so we can’t consider causal
inferences here as discussed previously. Generally, the use of AICs does not
preclude making causal statements but if you have randomized assignment of
levels of an explanatory variable, it is more philosophically consistent to use
hypothesis testing methods in that setting. If you went to the effort to impose
the levels of a treatment on the subjects, it also makes sense to see if the
differences created are beyond what you might expect by chance if the treatment
didn’t matter.</p>
<!-- \newpage -->
</div>
<div id="section8-14" class="section level2" number="8.14">
<h2><span class="header-section-number">8.14</span> Case study: Forced expiratory volume model selection using AICs</h2>
<p>Researchers were interested in studying the effects of smoking by children on
their lung development by measuring the forced expiratory volume (<em>FEV</em>,
measured in Liters) in a representative sample of children (<span class="math inline">\(n = 654\)</span>) between
the ages of 3 and 19; this data set is available in the <code>FEV</code> data set in the
<code>coneproj</code> package (<span class="citation"><a href="#ref-R-coneproj" role="doc-biblioref">M. C. Meyer and Liao</a> (<a href="#ref-R-coneproj" role="doc-biblioref">2021</a>)</span>, <span class="citation"><a href="#ref-Liao2014" role="doc-biblioref">Liao and Meyer</a> (<a href="#ref-Liao2014" role="doc-biblioref">2014</a>)</span>). 
Measurements on the <em>age</em> (in years) and <em>height</em> (in inches) as well as the
<em>sex</em> and <em>smoking status</em> of the children were made. We would expect both the
<em>age</em> and <em>height</em> to have positive relationships with <em>FEV</em> (lung capacity) and
that smoking might decrease the lung capacity but also that older children would
be more likely to smoke. So the <em>height</em> and <em>age</em> might be <strong><em>confounded</em></strong>
with smoking status and smoking might diminish lung development for older
kids – resulting in a potential interaction between <em>age</em> and <em>smoking</em>. The
<em>sex</em> of the child might also matter and should be considered or at
least controlled for since the response is a size-based measure. This creates
the potential for including up to four variables (<em>age</em>, <em>height</em>, <em>sex</em>, and
<em>smoking status</em>) and possibly the interaction between <em>age</em> and <em>smoking status</em>.
Initial explorations suggested that modeling the log-FEV would be more successful
than trying to model the responses on the original scale.
Figure <a href="chapter8.html#fig:Figure8-42">8.42</a> shows the suggestion of different slopes for the
smokers than non-smokers and that there aren’t very many smokers under 9 years
old in the data set.</p>
<p>So we will start with a model that contains an <em>age</em> by <em>smoking</em> interaction
and include <em>height</em> and <em>sex</em> as additive terms. We are not sure if any of
these model components will be needed, so the simplest candidate model will be
to remove all the predictors and just have a mean-only model (<code>FEV ~ 1</code>). In
between the mean-only and most complicated model are many different options
where we can drop the interaction or drop the additive terms or drop the terms
involved in the interaction if we don’t need the interaction.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-42"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-42-1.png" alt="Scatterplot of log(FEV) vs Age by smoking status, with both combined (top) and faceted (bottom) versions." width="75%" />
<p class="caption">
Figure 8.42: Scatterplot of log(FEV) vs Age by smoking status, with both combined (top) and faceted (bottom) versions.
</p>
</div>
<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb845-1"><a href="chapter8.html#cb845-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(coneproj)</span>
<span id="cb845-2"><a href="chapter8.html#cb845-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(FEV)</span>
<span id="cb845-3"><a href="chapter8.html#cb845-3" aria-hidden="true" tabindex="-1"></a>FEV <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(FEV)</span>
<span id="cb845-4"><a href="chapter8.html#cb845-4" aria-hidden="true" tabindex="-1"></a>FEV <span class="ot">&lt;-</span> FEV <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">sex =</span> <span class="fu">factor</span>(sex), <span class="co">#Make sex and smoke factors, log.FEV</span></span>
<span id="cb845-5"><a href="chapter8.html#cb845-5" aria-hidden="true" tabindex="-1"></a>                      <span class="at">smoke =</span> <span class="fu">factor</span>(smoke),</span>
<span id="cb845-6"><a href="chapter8.html#cb845-6" aria-hidden="true" tabindex="-1"></a>                      <span class="at">log.FEV =</span> <span class="fu">log</span>(FEV)</span>
<span id="cb845-7"><a href="chapter8.html#cb845-7" aria-hidden="true" tabindex="-1"></a>                      )</span>
<span id="cb845-8"><a href="chapter8.html#cb845-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb845-9"><a href="chapter8.html#cb845-9" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(FEV<span class="sc">$</span>sex) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Female&quot;</span>,<span class="st">&quot;Male&quot;</span>) <span class="co">#Make sex labels explicit</span></span>
<span id="cb845-10"><a href="chapter8.html#cb845-10" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(FEV<span class="sc">$</span>smoke) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Nonsmoker&quot;</span>,<span class="st">&quot;Smoker&quot;</span>) <span class="co">#Make smoking status labels explicit</span></span></code></pre></div>
<div style="page-break-after: always;"></div>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="chapter8.html#cb846-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> FEV <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> log.FEV, <span class="at">color =</span> smoke, <span class="at">shape =</span> smoke)) <span class="sc">+</span></span>
<span id="cb846-2"><a href="chapter8.html#cb846-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb846-3"><a href="chapter8.html#cb846-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb846-4"><a href="chapter8.html#cb846-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb846-5"><a href="chapter8.html#cb846-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb846-6"><a href="chapter8.html#cb846-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Plot of log(FEV) vs Age of children by smoking  status&quot;</span>,</span>
<span id="cb846-7"><a href="chapter8.html#cb846-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;log(FEV)&quot;</span>) </span>
<span id="cb846-8"><a href="chapter8.html#cb846-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-9"><a href="chapter8.html#cb846-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-10"><a href="chapter8.html#cb846-10" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> FEV <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">y =</span> log.FEV, <span class="at">color =</span> smoke, <span class="at">shape =</span> smoke)) <span class="sc">+</span></span>
<span id="cb846-11"><a href="chapter8.html#cb846-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb846-12"><a href="chapter8.html#cb846-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb846-13"><a href="chapter8.html#cb846-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb846-14"><a href="chapter8.html#cb846-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb846-15"><a href="chapter8.html#cb846-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Plot of log(FEV) vs Age of children by smoking  status&quot;</span>,</span>
<span id="cb846-16"><a href="chapter8.html#cb846-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;log(FEV)&quot;</span>) <span class="sc">+</span></span>
<span id="cb846-17"><a href="chapter8.html#cb846-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="at">cols =</span> <span class="fu">vars</span>(smoke))</span>
<span id="cb846-18"><a href="chapter8.html#cb846-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb846-19"><a href="chapter8.html#cb846-19" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>To get the needed results, start with the <strong><em>full model</em></strong> – the most
complicated model you want to consider. It is good to check assumptions before
considering reducing the model as they rarely get better in simpler models and
the <strong>AIC is only appropriate to use if the model assumptions are not clearly
violated</strong>. As suggested above, our “fullish” model for the <em>log(FEV)</em> values is
specified as <code>log(FEV) ~ height + age * smoke + sex</code>.</p>

<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="chapter8.html#cb847-1" aria-hidden="true" tabindex="-1"></a>fm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.FEV <span class="sc">~</span> height <span class="sc">+</span> age <span class="sc">*</span> smoke <span class="sc">+</span> sex, <span class="at">data =</span> FEV)</span>
<span id="cb847-2"><a href="chapter8.html#cb847-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fm1)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log.FEV ~ height + age * smoke + sex, data = FEV)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.62926 -0.08783  0.01136  0.09658  0.40751 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)     -1.919494   0.080571 -23.824  &lt; 2e-16
## height           0.042066   0.001759  23.911  &lt; 2e-16
## age              0.025368   0.003642   6.966 8.03e-12
## smokeSmoker      0.107884   0.113646   0.949  0.34282
## sexMale          0.030871   0.011764   2.624  0.00889
## age:smokeSmoker -0.011666   0.008465  -1.378  0.16863
## 
## Residual standard error: 0.1454 on 648 degrees of freedom
## Multiple R-squared:  0.8112, Adjusted R-squared:  0.8097 
## F-statistic: 556.8 on 5 and 648 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb849-1"><a href="chapter8.html#cb849-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>))</span>
<span id="cb849-2"><a href="chapter8.html#cb849-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fm1, <span class="at">sub.caption =</span> <span class="st">&quot;Diagnostics for full FEV model&quot;</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-43"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-43-1.png" alt="Diagnostics for the log(FEV) model that includes height, sex, and an interaction between age and smoking status (the full model)." width="75%" />
<p class="caption">
Figure 8.43: Diagnostics for the log(FEV) model that includes height, sex, and an interaction between age and smoking status (the full model).
</p>
</div>
<p>The diagnostic plots suggest that there are a few outlying points
(Figure <a href="chapter8.html#fig:Figure8-43">8.43</a>) but they are not influential and there is no
indication of violations of the constant variance assumption. There is a slight
left skew with a long left tail to cause a very minor concern with the normality
assumption but not enough to be concerned about our inferences from this model.
If we select a different model(s), we would want to check its diagnostics and
make sure that the results do not look noticeably worse than these do.</p>

<div class="sourceCode" id="cb850"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb850-1"><a href="chapter8.html#cb850-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(fm1, <span class="at">residuals =</span> T), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-44"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-44-1.png" alt="Term-plots for the log(FEV) model that includes height, sex, and an interaction between age and smoking status (the full model), with partial residuals." width="75%" />
<p class="caption">
Figure 8.44: Term-plots for the log(FEV) model that includes height, sex, and an interaction between age and smoking status (the full model), with partial residuals.
</p>
</div>
<p>Figure <a href="chapter8.html#fig:Figure8-44">8.44</a> provides our first term-plot with multiple
predictors and an interaction. Each term is interpreted using our “conditional”
language for any of the other two panels. So we could explore the impacts of
height on log-fev after controlling for sex as well as age, smoking status, and
the age by smoking interaction. This mirrors how we would interpret any of the
coefficients or confidence intervals from this full model (we are not doing
hypothesis tests here).</p>
<p>The <code>AIC</code> function can be used to generate the AIC values for a
single or set  of candidate models. It will also provide
the model degrees of freedom used for each model if run the function on multiple
models. For example, suppose that the want to compare <code>fm1</code> to a model
without the interaction term in the model, called <code>fm1R</code>. You need to fit both
models and then apply the <code>AIC</code> function to them with commas between the model
names:</p>
<!-- \newpage -->
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb851-1"><a href="chapter8.html#cb851-1" aria-hidden="true" tabindex="-1"></a>fm1R <span class="ot">&lt;-</span> <span class="fu">lm</span>(log.FEV <span class="sc">~</span> height <span class="sc">+</span> age <span class="sc">+</span> smoke <span class="sc">+</span> sex, <span class="at">data =</span> FEV)</span>
<span id="cb851-2"><a href="chapter8.html#cb851-2" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(fm1, fm1R)</span></code></pre></div>
<pre><code>##      df       AIC
## fm1   7 -658.5178
## fm1R  6 -658.6037</code></pre>
<p>These results tells us that the <code>fm1R</code> model (the one without the interaction)
is better (more negative) on the AIC by 0.09 AIC units. Note that this model
does not “fit” as well as the full model, it is just the top AIC model – the
AIC results suggest that it is slightly closer to the truth than the more
complicated model but with such a small difference there is similar support and
little evidence of a difference between the two models. This provides only an
assessment of the difference between including or excluding the interaction
between <em>age</em> and <em>smoking</em> in a model with two other predictors. We are
probably also interested in whether the other terms are needed in the model.
The full suite of results from dredge provide model comparisons that help us to
assess the presence/absence of each model component including the interaction.</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="chapter8.html#cb853-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">na.action =</span> <span class="st">&quot;na.fail&quot;</span>) <span class="co">#Must run this code once to use dredge</span></span>
<span id="cb853-2"><a href="chapter8.html#cb853-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dredge</span>(fm1, <span class="at">rank =</span> <span class="st">&quot;AIC&quot;</span>, </span>
<span id="cb853-3"><a href="chapter8.html#cb853-3" aria-hidden="true" tabindex="-1"></a>       <span class="at">extra =</span> <span class="fu">c</span>(<span class="st">&quot;R^2&quot;</span>, <span class="at">adjRsq =</span> <span class="cf">function</span>(x) <span class="fu">summary</span>(x)<span class="sc">$</span>adj.r.squared))</span></code></pre></div>
<pre><code>## Global model call: lm(formula = log.FEV ~ height + age * smoke + sex, data = FEV)
## ---
## Model selection table 
##        (Int)     age     hgh sex smk age:smk     R^2  adjRsq df   logLik    AIC   delta weight
## 16 -1.944000 0.02339 0.04280   +   +         0.81060 0.80950  6  335.302 -658.6    0.00  0.414
## 32 -1.919000 0.02537 0.04207   +   +       + 0.81120 0.80970  7  336.259 -658.5    0.09  0.397
## 8  -1.940000 0.02120 0.04299   +             0.80920 0.80830  5  332.865 -655.7    2.87  0.099
## 12 -1.974000 0.02231 0.04371       +         0.80880 0.80790  5  332.163 -654.3    4.28  0.049
## 28 -1.955000 0.02388 0.04315       +       + 0.80920 0.80800  6  332.802 -653.6    5.00  0.034
## 4  -1.971000 0.01982 0.04399                 0.80710 0.80650  4  329.262 -650.5    8.08  0.007
## 7  -2.265000         0.05185   +             0.79640 0.79580  4  311.594 -615.2   43.42  0.000
## 3  -2.271000         0.05212                 0.79560 0.79530  3  310.322 -614.6   43.96  0.000
## 15 -2.267000         0.05190   +   +         0.79640 0.79550  5  311.602 -613.2   45.40  0.000
## 11 -2.277000         0.05222       +         0.79560 0.79500  4  310.378 -612.8   45.85  0.000
## 30 -0.067780 0.09493           +   +       + 0.64460 0.64240  6  129.430 -246.9  411.74  0.000
## 26 -0.026590 0.09596               +       + 0.62360 0.62190  5  110.667 -211.3  447.27  0.000
## 14 -0.015820 0.08963           +   +         0.62110 0.61930  5  108.465 -206.9  451.67  0.000
## 6   0.004991 0.08660           +             0.61750 0.61630  4  105.363 -202.7  455.88  0.000
## 10  0.022940 0.09077               +         0.60120 0.60000  4   91.790 -175.6  483.02  0.000
## 2   0.050600 0.08708                         0.59580 0.59520  3   87.342 -168.7  489.92  0.000
## 13  0.822000                   +   +         0.09535 0.09257  4 -176.092  360.2 1018.79  0.000
## 9   0.888400                       +         0.05975 0.05831  3 -188.712  383.4 1042.03  0.000
## 5   0.857400                   +             0.02878 0.02729  3 -199.310  404.6 1063.22  0.000
## 1   0.915400                                 0.00000 0.00000  2 -208.859  421.7 1080.32  0.000
## Models ranked by AIC(x)</code></pre>
<p>There is a lot of information in the output and some of the needed information
in the second set of rows, so we will try to point out some useful features to
consider. The left columns describe the models being estimated. For example, the
first row of results is for a model with an intercept (<code>Int</code>), <em>age</em> (<code>age</code>)
, <em>height</em> (<code>hgh</code>), <em>sex</em> (<code>sex</code>), and <em>smoking</em>(<code>smk</code>). For <em>sex</em> and
<em>smoking</em>, there are “<code>+</code>”s in the output row when they are included in that
model but no coefficient since they are categorical variables. There is no
interaction between <em>age</em> and <em>smoking</em> in the top ranked model. The top AIC
model has an <span class="math inline">\(\boldsymbol{R}^2 = 0.8106\)</span>, adjusted <strong><em>R</em></strong><sup>2</sup> of 0.8095,
<em>model df</em> = 6 (from an intercept, four slopes, and the residual variance),
log-likelihood (<code>logLik</code>) = 335.302, an AIC = -658.6 and <span class="math inline">\(\Delta\text{AIC}\)</span> of 0.00.
The next best model adds the interaction between <em>age</em> and <em>smoking</em>, resulting
in increases in the <strong><em>R</em></strong><sup>2</sup>, adjusted <strong><em>R</em></strong><sup>2</sup>, and
<em>model df</em>, but increasing the AIC by 0.09 units <span class="math inline">\((\Delta\text{AIC} = 0.09)\)</span>.
This suggests that these two models are essentially equivalent on the AIC because
the difference is so small and this comparison was discussed previously. The
simpler model is a little bit better on AIC so you could focus on it or on the
slightly more complicated model – but you should probably note that the
evidence is equivocal for these two models.</p>
<p>The comparison to other potential models shows the strength of evidence in
support of all the other model components. The intercept-only model is again the
last in the list with the least support on AICs with a <span class="math inline">\(\Delta\text{AIC}\)</span>
of 1080.32, suggesting it is not worth considering in comparison with the top
model. <strong>Comparing the mean-only model to our favorite model on AICs is a bit
like the overall <span class="math inline">\(\boldsymbol{F}\)</span>-test we considered in Section</strong>
<a href="chapter8.html#section8-7">8.7</a> <strong>because it compares a model with no predictors to a
complicated model.</strong> Each model with just one predictor included is available
in the table as well, with the top single predictor model based on <em>height</em>
having a <span class="math inline">\(\Delta\text{AIC}\)</span> of 43.96. So we certainly need to
pursue something more complicated than SLR based with such strong evidence for
the more complex models versus the single predictor models at over 40 AIC units
different. Closer to the top model is the third-ranked model that includes
<em>age</em>, <em>height</em>, and <em>sex</em>. It has a <span class="math inline">\(\Delta\text{AIC}\)</span> of 2.87 so we would say
that these results present marginal support for the top two models over this
model. It is the simplest model of the top three but not close enough to be
considered in detail.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-45"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-45-1.png" alt="Display of AIC results on a number line with models indicated by their number in the dredge output. In more complex models, the dredge model numbers are just labels and not a meaningful numeration of the models being considered (there are 20 models considered here but labels go up to 32). Panel (a) presents results for all the models and panel (b) focuses just on the top 10 models so some differences in those models can be explored. Note that the spacing of the vertical grid lines in panel (a) are 10 AIC units and in (b) they are 1 AIC unit apart." width="75%" />
<p class="caption">
Figure 8.45: Display of AIC results on a number line with models indicated by their number in the <code>dredge</code> output. In more complex models, the <code>dredge</code> model numbers are just labels and not a meaningful numeration of the models being considered (there are 20 models considered here but labels go up to 32). Panel (a) presents results for all the models and panel (b) focuses just on the top 10 models so some differences in those models can be explored. Note that the spacing of the vertical grid lines in panel (a) are 10 AIC units and in (b) they are 1 AIC unit apart.
</p>
</div>
<p>The dredge results also provides the opportunity to compare the model
selection results from the adjusted <strong><em>R</em></strong><sup>2</sup> compared to the AIC. The AIC
favors the model without an interaction between <em>age</em> and <em>smoking</em> whereas the
adjusted <em>R</em><sup>2</sup> favors the most complicated model considered here
that included an <em>age</em> and <em>smoking</em> interaction. The AIC provides units that are
more interpretable than adjusted <em>R</em><sup>2</sup> even though the
scale for the AIC is a bit mysterious as <strong>distances from the unknown true
model</strong> with possibly negative distances.</p>
<p>The top AIC model (and possibly the other similar models) can then be
explored in more detail. You should not then focus on hypothesis testing in this
model. Hypothesis testing so permeates the use of statistics that even after
using AICs many researchers are pressured to report p-values for model
components.  Some of this could be confusion caused when
people first learned these statistical methods because when we teach you
statistics we show you how to use various methods, one after another, and forget
to mention that you should not use <strong>every</strong> method we taught you in <strong>every</strong>
analysis. Confidence intervals and term-plots are useful for describing the
different model components and making inferences for the estimated sizes of
differences in the population. These results should not be used for deciding if
terms are “significant” when the models (and their components) have already been
selected using measures like the AIC or adjusted <em>R</em><sup>2</sup>. But you can discuss the
estimated model components to go with how you arrived at having them in the model.</p>
<p>In this situation, the top model is estimated to be</p>
<p><span class="math display">\[\log(\widehat{\text{FEV}})_i = -1.94 + 0.043\cdot\text{Height}_i+ 0.0234\cdot\text{Age}_i
-0.046I_{\text{Smoker},i}+0.0293I_{\text{Male},i}\]</span></p>
<p>based on the estimated coefficients provided below. Using these results and the
term-plots (Figure <a href="chapter8.html#fig:Figure8-46">8.46</a>) we see that in this model there are
positive slopes for <em>Age</em> and <em>Height</em> on <em>log-FEV</em>, a negative coefficient for
<em>smoking</em> (<em>Smoker</em>), and a positive coefficient for <em>sex</em> (<em>Males</em>). There is
some multicollinearity impacting the estimates for <em>height</em> and <em>age</em> based on
having VIFs near 3 but these are not extreme issues. We could go further with
interpretations such as for the <em>age</em> term: For a 1 year increase in <em>age</em>, we
estimate, on average, a 0.0234 log-liter increase in <em>FEV</em>, after controlling
for the <em>height</em>, <em>smoking status</em>, and <em>sex</em> of the children. We can even
interpret this on the original scale since this was a <em>log(y)</em> response model
using the same techniques as in Section <a href="chapter7.html#section7-6">7.6</a>. If we exponentiate
the slope coefficient of the quantitative variable, <span class="math inline">\(\exp(0.0234) = 1.0237\)</span>. This
provides the interpretation on the original <em>FEV</em> scale, for a 1 year increase
in <em>age</em>, we estimate a 2.4% increase in the median <em>FEV</em>, after controlling for
the <em>height</em>, <em>smoking status</em>, and <em>sex</em> of the children. <strong>The only difference
from Section</strong> <a href="chapter7.html#section7-6">7.6</a> <strong>when working with a log(y) model now is that
we have to note that the model used to generate the slope coefficient had other
components and so this estimate is after adjusting for them.</strong></p>

<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="chapter8.html#cb855-1" aria-hidden="true" tabindex="-1"></a>fm1R<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)      height         age smokeSmoker     sexMale 
## -1.94399818  0.04279579  0.02338721 -0.04606754  0.02931936</code></pre>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="chapter8.html#cb857-1" aria-hidden="true" tabindex="-1"></a><span class="fu">vif</span>(fm1R)</span></code></pre></div>
<pre><code>##   height      age    smoke      sex 
## 2.829728 3.019010 1.209564 1.060228</code></pre>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="chapter8.html#cb859-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(fm1R)</span></code></pre></div>
<pre><code>##                    2.5 %       97.5 %
## (Intercept) -2.098414941 -1.789581413
## height       0.039498923  0.046092655
## age          0.016812109  0.029962319
## smokeSmoker -0.087127344 -0.005007728
## sexMale      0.006308481  0.052330236</code></pre>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb861-1"><a href="chapter8.html#cb861-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">allEffects</span>(fm1R), <span class="at">grid =</span> T)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Figure8-46"></span>
<img src="08-multipleLinearRegression_files/figure-html/Figure8-46-1.png" alt="Term-plots for the top AIC model for log(FEV) that includes height, age, smoking status, and sex in the model." width="75%" />
<p class="caption">
Figure 8.46: Term-plots for the top AIC model for log(FEV) that includes height, age, smoking status, and sex in the model.
</p>
</div>
<div style="page-break-after: always;"></div>
<p>Like any statistical method, the AIC works better with larger sample
sizes and when assumptions are not clearly violated. It also will detect
important variables in models more easily when the effects of the predictor
variables are strong. Along with the AIC results, it is good to report the
coefficients for your top estimated model(s), confidence intervals for the
coefficients and/or term-plots, and <em>R</em><sup>2</sup>. This provides a useful summary of
the reasons for selecting the model(s), information on the importance of the
terms within the model, and a measure of the variability explained by the model.
The <em>R</em><sup>2</sup> is not used to select the model, but after selection can be a nice
summary of model quality. For <code>fm1R</code> , the <span class="math inline">\(R^2 = 0.8106\)</span> suggesting that the
selected model explains 81% of the variation in log-<em>FEV</em> values.
</p>
<p>The AICs are a preferred modeling strategy in some fields such as
Ecology. As with this and many other
methods discussed in this book, it is sometimes as easy to find journal
articles with mistakes in using statistical methods as it is to find papers
doing it correctly. After completing this material, you have the potential to
have the knowledge and experience of two statistics classes and now are better
trained than some researchers that frequently use these methods. This set of tools
can be easily mis-applied. Try to make sure that you are thinking carefully
through your problem before jumping to the statistical results. Make a graph
first, think carefully about your study design and variables collected and what
your models of interest might be, what assumptions might be violated based on
the data collection story, and then start fitting models. Then check your
assumptions and only proceed on with any inference if the conditions are
not clearly violated. The AIC provides an alternative method for selecting among
different potential models and they do not need to be nested (a requirement of
hypothesis testing methods used to sequentially simplify models). The automated
consideration of all possible models in the <code>dredge</code> function should not be
considered in all situations but can be useful in a preliminary model exploration
study where no clear knowledge exists about useful models to consider. Where
some knowledge exists of possible models of interest <em>a priori</em>, fit those
models and use the AIC function to get AICs to compare. Reporting the summary of
AIC results beyond just reporting the top model(s) that were selected for
focused exploration provides the evidence to support that selection – not
p-values!</p>
</div>
<div id="section8-15" class="section level2" number="8.15">
<h2><span class="header-section-number">8.15</span> Chapter summary</h2>
<p>This chapter explored the most complicated models we’re
going to explore. MLR models can incorporate features of SLR and ANOVAs. The
MLR’s used in this chapter highlight the flexibility of the linear modeling
framework to move from two-sample mean models to multi-predictor models with
interactions of categorical and quantitative variables. It is useful to use the
pertinent names for the simpler models, but at this point we could have called
everything we are doing <strong><em>fitting linear models</em></strong>. The power of the linear
model involves being able to add multiple predictor variables to the
model and handle categorical predictors using indicator variables.
 All this power comes with some responsibility in that you need
to know what you are trying to fit and how to interpret the results provided.
We introduced each scenario working from simple to the most complicated version
of the models, trying to motivate when you would encounter them, and the
specific details of the interpretations of each type of model. In
Chapter <a href="chapter9.html#chapter9">9</a>, case studies are used to review the different methods
discussed with reminders of how to identify and interpret the particular
methods used.</p>
<p>When you have to make modeling decisions, you should remember the main
priorities in modeling. First, you need to find a model that can address
research question(s) of interest. Second, find a model that is trustworthy by
assessing the assumptions in the model relative to your data set.
Third, report the logic and evidence that was used to identify and support the
model. All too often, researchers present only a final model with little
information on how they arrived at it. You should be reporting the reasons for
decisions made and the evidence supporting them, whether that is using p-values
or some other model selection criterion. For example, if you were
considering an interaction model and the interaction was dropped and an additive
model is re-fit and interpreted, the evidence related to the interaction test
should still be reported. Similarly, if a larger MLR is considered and some
variables are removed, the evidence (reason) for those removals should be
provided. Because of multicollinearity in models, you should never remove more
than one quantitative predictor at a time or else you could remove two variables
that are important but were “hiding” when both were included in the model.</p>
<!-- \newpage -->
</div>
<div id="section8-16" class="section level2" number="8.16">
<h2><span class="header-section-number">8.16</span> Summary of important R code</h2>
<p>There is very little “new” R code in this chapter since all these methods were
either used in the ANOVA or SLR chapters. The models are more complicated but
are built off of methods from previous chapters. In this code, <code>y</code> is a
response variable, <code>x1</code>, <code>x2</code>, …, <code>xK</code> are quantitative
explanatory variables, <code>groupfactor</code> is a factor variable and the data are
in <code>DATASETNAME</code>.</p>
<ul>
<li><p><strong><font color='red'>DATASETNAME</font> %&gt;% ggplot(mapping = aes(x = <font color='red'>x</font>, y = <font color='red'>y</font>)) +<br />
geom_point() +<br />
geom_smooth(method = “lm”)</strong></p>
<ul>
<li><p>Provides a scatter plot with a regression line.
</p></li>
<li><p>Add <strong>+ geom_smooth()</strong> to add a smoothing line to help detect
nonlinear relationships.
</p></li>
<li><p>Add <strong>color = <font color='red'>groupfactor</font></strong> to aesthetic to color
points and lines based on a grouping variable.</p></li>
<li><p>Add <strong>+ facet_grid(cols = vars(<font color='red'>groupfactor</font>))</strong> to
facet by groups. </p></li>
</ul></li>
<li><p><strong><font color='red'>MODELNAME</font> <code>&lt;-</code> lm(<font color='red'>y</font> ~
<font color='red'>x1 + x2 +…+ xK</font>, data = <font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li>Estimates an MLR model using least squares with <span class="math inline">\(K\)</span> quantitative
predictors.
</li>
</ul></li>
<li><p><strong><font color='red'>MODELNAME</font> <code>&lt;-</code> lm(<font color='red'>y</font> ~
<font color='red'>x1 * groupfactor</font>, data = <font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li>Estimates an interaction model between a quantitative and categorical
variable, providing different slopes and intercepts for each group.</li>
</ul></li>
<li><p><strong><font color='red'>MODELNAME</font> <code>&lt;-</code> lm(<font color='red'>y</font> ~
<font color='red'>x1 + groupfactor</font>, data = <font color='red'>DATASETNAME</font>)</strong></p>
<ul>
<li>Estimates an additive model with a quantitative and categorical
variable, providing different intercepts for each group.</li>
</ul></li>
<li><p><strong>summary(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li>Provides parameter estimates, overall <span class="math inline">\(F\)</span>-test, <strong><em>R</em></strong><sup>2</sup>,
and adjusted <strong><em>R</em></strong><sup>2</sup>.
</li>
</ul></li>
<li><p><strong>par(mfrow = c(2, 2)); plot(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li>Provides four regression diagnostic plots in one plot.</li>
</ul></li>
<li><p><strong>confint(<font color='red'>MODELNAME</font>, level = 0.95)</strong></p>
<ul>
<li><p>Provides 95% confidence intervals for the regression model coefficients.</p></li>
<li><p>Change <code>level</code> if you want other confidence levels.
</p></li>
</ul></li>
<li><p><strong>plot(allEffects(<font color='red'>MODELNAME</font>))</strong></p>
<ul>
<li><p>Requires the <code>effects</code> package.</p></li>
<li><p>Provides a plot of the estimated regression lines with 95% confidence
interval for the mean.
</p></li>
</ul></li>
<li><p><strong>vif(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li><p>Requires the <code>car</code> package.</p></li>
<li><p>Provides VIFs for an MLR model. Only use in additive models – not
meaningful for models with interactions present.
</p></li>
</ul></li>
<li><p><strong>predict(<font color='red'>MODELNAME</font>, se.fit = T)</strong></p>
<ul>
<li>Provides fitted values for all observed <span class="math inline">\(x\text{&#39;s}\)</span> with SEs for the
mean.
</li>
</ul></li>
<li><p><strong>predict(<font color='red'>MODELNAME</font>, newdata = tibble(<font color='red'>x1</font>
= <font color='red'>X1_NEW</font>, <font color='red'>x2</font> = <font color='red'>X2_NEW</font>,
<font color='red'>…</font>, <font color='red'>xK</font> = <font color='red'>XK_NEW</font>,
interval = “confidence”)</strong></p>
<ul>
<li>Provides fitted value for specific values of the quantitative predictors
with CI for the mean.</li>
</ul></li>
<li><p><strong>predict(<font color='red'>MODELNAME</font>, newdata = tibble(<font color='red'>x1</font>
= <font color='red'>X1_NEW</font>, <font color='red'>x2</font> = <font color='red'>X2_NEW</font>,
<font color='red'>…</font>, <font color='red'>xK</font> = <font color='red'>XK_NEW</font>,
interval = “prediction”)</strong></p>
<ul>
<li>Provides fitted value for specific values of the quantitative predictors
with PI for a new observation.</li>
</ul></li>
<li><p><strong>Anova(<font color='red'>MODELNAME</font>)</strong></p>
<ul>
<li><p>Requires the <code>car</code> package.</p></li>
<li><p>Use to generate ANOVA tables and <span class="math inline">\(F\)</span>-tests useful when categorical
variables are included in either the additive or interaction models.
</p></li>
</ul></li>
<li><p><strong>AIC(<font color='red'>MODELNAME_1</font>, <font color='red'>MODELNAME_2</font>)</strong></p>
<ul>
<li>Use to get AIC results for two candidate models called <code>MODELNAME_1</code>
and <code>MODELNAME_2</code>.
</li>
</ul></li>
<li><p><strong>options(na.action = “na.fail”)<br />
dredge(<font color='red'>FULL_MODELNAME</font>, rank = “AIC”)</strong></p>
<ul>
<li><p>Requires the <code>MuMIn</code> package.</p></li>
<li><p>Provides AIC and delta AIC results for all possible simpler models given
a full model called <code>FULL_MODELNAME</code>.
</p></li>
</ul></li>
</ul>
<!-- \newpage -->
</div>
<div id="section8-17" class="section level2" number="8.17">
<h2><span class="header-section-number">8.17</span> Practice problems</h2>
<p>8.1. <strong>Treadmill data analysis</strong> The original research goal for the treadmill
data set used for practice problems in the last two chapters was to
replace the costly treadmill oxygen test with a cheap to find running time
measurement but there were actually quite a few variables measured when the
run time was found – maybe we can replace the treadmill test result with a
combined prediction built using a few variables using the MLR techniques. The
following code will get us re-started in this situation.</p>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb862-1"><a href="chapter8.html#cb862-1" aria-hidden="true" tabindex="-1"></a>treadmill <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;http://www.math.montana.edu/courses/s217/documents/treadmill.csv&quot;</span>)</span>
<span id="cb862-2"><a href="chapter8.html#cb862-2" aria-hidden="true" tabindex="-1"></a>tm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(TreadMillOx <span class="sc">~</span> RunTime, <span class="at">data =</span> treadmill)</span></code></pre></div>
<p>8.1.1. Fit the MLR that also includes the running pulse (<code>RunPulse</code>), the
resting pulse (<code>RestPulse</code>), body weight (<code>BodyWeight</code>), and Age (<code>Age</code>)
of the subjects. Report and interpret the <em>R</em><sup>2</sup> for
this model.</p>
<p>8.1.2. Compare the <em>R</em><sup>2</sup> and the adjusted <em>R</em><sup>2</sup> to the results for the SLR model
that just had <code>RunTime</code> in the model. What do these results suggest?</p>
<p>8.1.3. Interpret the estimated <code>RunTime</code> slope coefficients from the SLR model
and this MLR model. Explain the differences in the estimates.</p>
<p>8.1.4. Find the VIFs for this model and discuss whether there is an issue with
multicollinearity noted in these results.</p>
<p>8.1.5. Report the value for the overall <span class="math inline">\(F\)</span>-test for the MLR model and interpret
the result.</p>
<p>8.1.6. Drop the variable with the largest p-value in the MLR model and re-fit
it. Compare the resulting <strong><em>R</em></strong><sup>2</sup> and adjusted <strong><em>R</em></strong><sup>2</sup>
values to the others found previously.</p>
<p>8.1.7. Use the <code>dredge</code> function as follows to consider some other potential
reduced models and report the top two models according to adjusted
<strong><em>R</em></strong><sup>2</sup> values. What model had the highest <strong><em>R</em></strong><sup>2</sup>?
Also discuss and compare the model selection results provided by the delta AICs
here.</p>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb863-1"><a href="chapter8.html#cb863-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb863-2"><a href="chapter8.html#cb863-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">na.action =</span> <span class="st">&quot;na.fail&quot;</span>) <span class="co">#Must run this code once to use dredge</span></span>
<span id="cb863-3"><a href="chapter8.html#cb863-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dredge</span>(MODELNAMEFORFULLMODEL, <span class="at">rank =</span> <span class="st">&quot;AIC&quot;</span>, </span>
<span id="cb863-4"><a href="chapter8.html#cb863-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">extra =</span> <span class="fu">c</span>(<span class="st">&quot;R^2&quot;</span>, <span class="at">adjRsq =</span> <span class="cf">function</span>(x) <span class="fu">summary</span>(x)<span class="sc">$</span>adj.r.squared))</span></code></pre></div>
<p>8.1.8. For one of the models, interpret the <em>Age</em> slope coefficient. Remember that
only male subjects between 38 and 57 participated in this study. Discuss how
this might have impacted the results found as compared to a more general
population that could have been sampled from.</p>
<p>8.1.9. The following code creates a new three-level variable grouping the ages
into low, middle, and high for those observed. The scatterplot lets you
explore whether the relationship between treadmill oxygen and run time might
differ across the age groups.</p>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb864-1"><a href="chapter8.html#cb864-1" aria-hidden="true" tabindex="-1"></a>treadmill <span class="ot">&lt;-</span> treadmill <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">Ageb =</span> <span class="fu">factor</span>(<span class="fu">cut</span>(Age, <span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">37</span>, <span class="fl">44.5</span>, <span class="fl">50.5</span>, <span class="dv">58</span>))))</span>
<span id="cb864-2"><a href="chapter8.html#cb864-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(treadmill<span class="sc">$</span>Ageb)</span>
<span id="cb864-3"><a href="chapter8.html#cb864-3" aria-hidden="true" tabindex="-1"></a>treadmill <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> RunTime, <span class="at">y =</span> TreadMillOx, <span class="at">color =</span> Ageb, <span class="at">shape =</span> Ageb)) <span class="sc">+</span> </span>
<span id="cb864-4"><a href="chapter8.html#cb864-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb864-5"><a href="chapter8.html#cb864-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb864-6"><a href="chapter8.html#cb864-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb864-7"><a href="chapter8.html#cb864-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_viridis_d</span>(<span class="at">end =</span> <span class="fl">0.8</span>) <span class="sc">+</span> </span>
<span id="cb864-8"><a href="chapter8.html#cb864-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="at">rows =</span> <span class="fu">vars</span>(Ageb))</span></code></pre></div>
<p>Based on the plot, do the lines look approximately parallel or not?</p>
<p>8.1.10. Fit the MLR that contains a <code>RunTime</code> by <code>Ageb</code> interaction – do not
include any other variables. Compare the <strong><em>R</em></strong><sup>2</sup> and adjusted
<strong><em>R</em></strong><sup>2</sup> results to previous models.</p>
<p>8.1.11. Find and report the results for the <span class="math inline">\(F\)</span>-test that assesses evidence
relative to the need for different slope coefficients.</p>
<p>8.1.12. Write out the overall estimated model. What level was R using as
baseline? Write out the simplified model for two of the age levels. Make an effects plot and discuss how it matches the simplified models you generated.</p>
<p>8.1.13. Fit the additive model with <code>RunTime</code> and predict the mean treadmill
oxygen values for subjects with run times of 11 minutes in each of the three
<code>Ageb</code> groups.</p>
<p>8.1.14. Find the <span class="math inline">\(F\)</span>-test results for the binned age variable in the additive
model. Report and interpret those results.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Akaike1974" class="csl-entry">
Akaike, Hirotugu. 1974. <span>“A New Look at the Statistical Model Identification.”</span> <em>IEEE Transactions on Automatic Control</em> 19: 716–23.
</div>
<div id="ref-R-MuMIn" class="csl-entry">
Barton, Kamil. 2020. <em>MuMIn: Multi-Model Inference</em>. <a href="https://CRAN.R-project.org/package=MuMIn">https://CRAN.R-project.org/package=MuMIn</a>.
</div>
<div id="ref-Burnham2002" class="csl-entry">
Burnham, Kenneth P., and David R. Anderson. 2002. <em>Model Selection and Multimodel Inference</em>. NY: Springer.
</div>
<div id="ref-R-openintro" class="csl-entry">
Çetinkaya-Rundel, Mine, David Diez, Andrew Bray, Albert Y. Kim, Ben Baumer, Chester Ismay, Nick Paterno, and Christopher Barr. 2021. <em>Openintro: Data Sets and Supplemental Functions from OpenIntro Textbooks and Labs</em>. <a href="https://CRAN.R-project.org/package=openintro">https://CRAN.R-project.org/package=openintro</a>.
</div>
<div id="ref-DeVeaux2011" class="csl-entry">
De Veaux, Richard D., Paul F. Velleman, and David E. Bock. 2011. <em>Stats: Data and Models, 3rd Edition</em>. Pearson.
</div>
<div id="ref-Fox2003" class="csl-entry">
Fox, John. 2003. <span>“Effect Displays in <span>R</span> for Generalised Linear Models.”</span> <em>Journal of Statistical Software</em> 8 (15): 1–27. <a href="http://www.jstatsoft.org/v08/i15/">http://www.jstatsoft.org/v08/i15/</a>.
</div>
<div id="ref-R-heplots" class="csl-entry">
Fox, John, and Michael Friendly. 2021. <em>Heplots: Visualizing Hypothesis Tests in Multivariate Linear Models</em>. <a href="http://friendly.github.io/heplots/">http://friendly.github.io/heplots/</a>.
</div>
<div id="ref-R-carData" class="csl-entry">
Fox, John, Sanford Weisberg, and Brad Price. 2020. <em>carData: Companion to Applied Regression Data Sets</em>. <a href="https://CRAN.R-project.org/package=carData">https://CRAN.R-project.org/package=carData</a>.
</div>
<div id="ref-R-viridis" class="csl-entry">
Garnier, Simon. 2021. <em>Viridis: Colorblind-Friendly Color Maps for r</em>. <a href="https://CRAN.R-project.org/package=viridis">https://CRAN.R-project.org/package=viridis</a>.
</div>
<div id="ref-Liao2014" class="csl-entry">
Liao, Xiyue, and Mary C. Meyer. 2014. <span>“Coneproj: An <span>R</span> Package for the Primal or Dual Cone Projections with Routines for Constrained Regression.”</span> <em>Journal of Statistical Software</em> 61 (12): 1–22. <a href="http://www.jstatsoft.org/v61/i12/">http://www.jstatsoft.org/v61/i12/</a>.
</div>
<div id="ref-R-smdata" class="csl-entry">
Merkle, Ed, and Michael Smithson. 2018. <em>Smdata: Data to Accompany Smithson &amp; Merkle, 2013</em>. <a href="https://CRAN.R-project.org/package=smdata">https://CRAN.R-project.org/package=smdata</a>.
</div>
<div id="ref-R-coneproj" class="csl-entry">
Meyer, Mary C., and Xiyue Liao. 2021. <em>Coneproj: Primal or Dual Cone Projections with Routines for Constrained Regression</em>. <a href="https://CRAN.R-project.org/package=coneproj">https://CRAN.R-project.org/package=coneproj</a>.
</div>
<div id="ref-Ramsey2012" class="csl-entry">
Ramsey, Fred, and Daniel Schafer. 2012. <em>The Statistical Sleuth: A Course in Methods of Data Analysis</em>. Cengage Learning. <a href="https://books.google.com/books?id=eSlLjA9TwkUC">https://books.google.com/books?id=eSlLjA9TwkUC</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="131">
<li id="fn131"><p>If you take advanced applied mathematics courses, you can learn
more about the algorithms being used by <code>lm</code>.
Everyone else only cares
about the algorithms when they don’t work – which is usually due to the
user’s inputs in these models not the algorithm itself.<a href="chapter8.html#fnref131" class="footnote-back">↩︎</a></p></li>
<li id="fn132"><p>Sometimes the <code>effects</code> plots
ignores the edge explanatory observations with the
default display. Always check the original variable summaries when considering
the range of observed values. By turning on the “partial residuals” with SLR models, the plots show the original observations along with the fitted values and 95% confidence interval band. In more complex models, these displays with residuals are more complicated but can be used to assess linearity with each predictor in the model after accounting for other variables.<a href="chapter8.html#fnref132" class="footnote-back">↩︎</a></p></li>
<li id="fn133"><p>We used this same notation in the fitting the additive Two-Way
ANOVA and this is also additive in terms of these variables. Interaction
models are discussed later in the chapter.<a href="chapter8.html#fnref133" class="footnote-back">↩︎</a></p></li>
<li id="fn134"><p>I have
not given you a formula for calculating partial residuals. We will
leave that for more advanced material.<a href="chapter8.html#fnref134" class="footnote-back">↩︎</a></p></li>
<li id="fn135"><p>Imagine
showing up to a ski area expecting a 40 inch base and there only being
11 inches. I’m sure ski areas are always more accurate than this model in their
reporting of amounts of snow on the ground…<a href="chapter8.html#fnref135" class="footnote-back">↩︎</a></p></li>
<li id="fn136"><p>The site name is redacted to protect
the innocence of the reader. More information on this site, located in
Beaverhead County in Montana, is available at
<a href="http://www.wcc.nrcs.usda.gov/nwcc/site?sitenum=355&amp;state=mt" class="uri">http://www.wcc.nrcs.usda.gov/nwcc/site?sitenum=355&amp;state=mt</a>.<a href="chapter8.html#fnref136" class="footnote-back">↩︎</a></p></li>
<li id="fn137"><p>Term-plots
with additive factor variables use the weighted (based on percentage of the
responses in each category) average of their predicted mean responses across
their levels but we don’t have any factor variables in the MLR models, yet.<a href="chapter8.html#fnref137" class="footnote-back">↩︎</a></p></li>
<li id="fn138"><p>This also applies to the additive
two-way ANOVA model.<a href="chapter8.html#fnref138" class="footnote-back">↩︎</a></p></li>
<li id="fn139"><p>The <code>seq</code> function has syntax of
<code>seq(from = startingpoint, to = endingpoint,  length.out = #ofvalues_between_start_and_end)</code> and the <code>rep</code> function has
syntax of <code>rep(numbertorepeat, #oftimes).</code><a href="chapter8.html#fnref139" class="footnote-back">↩︎</a></p></li>
<li id="fn140"><p>Also
see Section <a href="chapter8.html#section8-13">8.13</a> for another method of picking among different
models.<a href="chapter8.html#fnref140" class="footnote-back">↩︎</a></p></li>
<li id="fn141"><p>This section was inspired by a
similar section from <span class="citation"><a href="#ref-DeVeaux2011" role="doc-biblioref">De Veaux, Velleman, and Bock</a> (<a href="#ref-DeVeaux2011" role="doc-biblioref">2011</a>)</span>.<a href="chapter8.html#fnref141" class="footnote-back">↩︎</a></p></li>
<li id="fn142"><p>There are some social
science models where the model is fit with the mean subtracted from each
predictor so all have mean 0 and the precision of the <span class="math inline">\(y\)</span>-intercept is
interesting. In some cases both the response and predictor variables are “standardized” to have means of 0 and standard deviations of 1. The interpretations of coefficients then relates to changes in standard deviations around the means. These coefficients are called “standardized betas.”  But even in these models where the <span class="math inline">\(x\)</span>-values of 0 are of interest, the test for the <span class="math inline">\(y\)</span>-intercept being 0 is
rarely of interest.<a href="chapter8.html#fnref142" class="footnote-back">↩︎</a></p></li>
<li id="fn143"><p>The variables were renamed to better interface with R code and our book formatting using the <code>rename</code> function.<a href="chapter8.html#fnref143" class="footnote-back">↩︎</a></p></li>
<li id="fn144"><p>The answer is no – it should be converted to a factor variable prior to plotting so it can be displayed correctly by <code>ggpairs</code>, but was intentionally left this way so you could see what happens when numerically coded categorical variables are not carefully handled in R.<a href="chapter8.html#fnref144" class="footnote-back">↩︎</a></p></li>
<li id="fn145"><p>Either
someone had a weighted GPA with bonus points, or more likely here, there
was a coding error in the data set since only one observation was over 4.0 in
the GPA data. Either way, we could remove it and note that our inferences for
HSGPA do not extend above 4.0.<a href="chapter8.html#fnref145" class="footnote-back">↩︎</a></p></li>
<li id="fn146"><p>When there
are just two predictors, the VIFs have to be the same since the
proportion of information shared is the same in both directions. With
more than two predictors, each variable can have a different VIF
value.<a href="chapter8.html#fnref146" class="footnote-back">↩︎</a></p></li>
<li id="fn147"><p>We
are actually making an educated guess about what these codes mean. Other
similar data sets used 1 for males but the documentation on these data is a bit
sparse. We proceed with a small potential that the conclusions regarding
differences in gender are in the wrong direction.<a href="chapter8.html#fnref147" class="footnote-back">↩︎</a></p></li>
<li id="fn148"><p>Some people also call them <strong><em>dummy variables</em></strong> to reflect that they are stand-ins for dealing with the categorical information. But it seems like a harsh anthropomorphism so I prefer “indicators.”<a href="chapter8.html#fnref148" class="footnote-back">↩︎</a></p></li>
<li id="fn149"><p>This is true for
additive uses of indicator variables. In Section <a href="chapter8.html#section8-11">8.11</a>, we
consider interactions between quantitative and categorical variables which has
the effect of changing slopes and intercepts. The simplification ideas to
produce estimated equations for each group are used there but we have to account
for changing slopes by group too.<a href="chapter8.html#fnref149" class="footnote-back">↩︎</a></p></li>
<li id="fn150"><p>Models like this with a categorical
variable and quantitative variable are often called <em>ANCOVA</em> or <em>analysis of
covariance</em> models but really are just versions of our linear models we’ve been
using throughout this material.<a href="chapter8.html#fnref150" class="footnote-back">↩︎</a></p></li>
<li id="fn151"><p>The
<code>scale_color_viridis_d(end = 0.85, option = "inferno")</code> code makes the plot
in a suite of four colors from the <code>viridis</code> package <span class="citation">(<a href="#ref-R-viridis" role="doc-biblioref">Garnier 2021</a>)</span> that attempt
to be color-blind friendly.<a href="chapter8.html#fnref151" class="footnote-back">↩︎</a></p></li>
<li id="fn152"><p>The strength of this recommendation drops when you have many predictors as you can’t do this for every variable, but the concern remains about an assumption of no interaction whenever you fit models without them. In more complex situations, think about variables that are most likely to interact in their impacts on the response based on the situation being studied and try to explore those.<a href="chapter8.html#fnref152" class="footnote-back">↩︎</a></p></li>
<li id="fn153"><p>Standardizing quantitative predictor variables is popular in social sciences, often where the response variable is also standardized. In those situations, they generate what are called “standardized betas” (<a href="https://en.wikipedia.org/wiki/Standardized_coefficient" class="uri">https://en.wikipedia.org/wiki/Standardized_coefficient</a>) that estimate the change in SDs in the response for a 1 SD increase in the explanatory variable.<a href="chapter8.html#fnref153" class="footnote-back">↩︎</a></p></li>
<li id="fn154"><p>There is a way to test for a difference in the two lines
at a particular <span class="math inline">\(x\)</span> value but it is beyond the scope of this material.<a href="chapter8.html#fnref154" class="footnote-back">↩︎</a></p></li>
<li id="fn155"><p>This is an example of
what is called “step down” testing for model refinement which is a commonly
used technique for arriving at a final model to describe response variables.
Note that each step in the process should be reported, not just the final model
that only has variables with small p-values remaining in it.<a href="chapter8.html#fnref155" class="footnote-back">↩︎</a></p></li>
<li id="fn156"><p>We could also use the <code>anova</code> function to do
this but using <code>Anova</code> throughout this material provides the answers we want
in the additive model and it has no impact for the only test of interest in the
interaction model since the interaction is the last component in the model.<a href="chapter8.html#fnref156" class="footnote-back">↩︎</a></p></li>
<li id="fn157"><p>In
most situations, it would be crazy to assume that the true model for a process
has been obtained so we can never pick the “correct” model. In fact, we won’t
even know if we are picking a “good” model, but just the best from a set of the
candidate models on a criterion. But we can study the general performance of
methods using simulations where we know the true model and the AIC has some
useful properties in identifying the correct model when it is in the candidate
set of models. No such similar theory exists for the adjusted <strong><em>R</em></strong><sup>2</sup>.<a href="chapter8.html#fnref157" class="footnote-back">↩︎</a></p></li>
<li id="fn158"><p>Most people now call this Akaike’s
(pronounced <strong>ah-kah-ee-kay</strong>) Information Criterion, but he used the
AIC nomenclature to mean An Information Criterion – he was not so vain as to
name the method after himself in the original paper that proposed it. But it is
now common to use “A” for his last name.<a href="chapter8.html#fnref158" class="footnote-back">↩︎</a></p></li>
<li id="fn159"><p>More details on these components of the
methods will be left for more advanced material – we will focus on an
introduction to using the AIC measure here.<a href="chapter8.html#fnref159" class="footnote-back">↩︎</a></p></li>
<li id="fn160"><p>Although sometimes excluded, the count of
parameters should include counting the residual variance as a parameter.<a href="chapter8.html#fnref160" class="footnote-back">↩︎</a></p></li>
<li id="fn161"><p>It makes it impossible to fit models with any missing values in the data
set and this prevents you from making incorrect comparisons of AICs to models
with different observations.<a href="chapter8.html#fnref161" class="footnote-back">↩︎</a></p></li>
<li id="fn162"><p>We put quotes on “full” or sometimes call it the “fullish” model because
we could always add more to the model, like interactions or other explanatory
variables. So we rarely have a completely full model but
we do have our “most complicated that we are considering” model.<a href="chapter8.html#fnref162" class="footnote-back">↩︎</a></p></li>
<li id="fn163"><p>The options in <code>extra = ...</code> are to get
extra information displayed that you do not necessarily need. You can simply run
<code>dredge(m6, rank = "AIC")</code> to get just the AIC results.<a href="chapter8.html#fnref163" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter7.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapter9.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Greenwood_Book.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
